{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9892de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450620000.0, '40.6720753', '-73.9113364']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "grid_size = 5\n",
    "chunk_amount = 85555\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.coordinates = data\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        \n",
    "        #split into 500 chunks using numpy\n",
    "        self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "        #process each chunk and merge it back into one dataframe\n",
    "        self.grids = []\n",
    "        grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "        grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "        grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "        grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "        for i in range(len(self.coordinates)-1):\n",
    "            grid = np.zeros((grid_size, grid_size))\n",
    "            for index, row in self.coordinates[i].iterrows():\n",
    "                coordinates = row['latitude'], row['longitude']\n",
    "                for j in range(grid_size):\n",
    "                    for k in range(grid_size):\n",
    "                        lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                        lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                        long_lower = grid_lower_long + k * grid_long_step\n",
    "                        long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                        if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                            grid[j][k] += 1\n",
    "                            break\n",
    "            self.grids.append(grid/chunk_size)\n",
    "        self.grids = np.array(self.grids)\n",
    "        self.transform = transform      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        grid = self.grids[idx]\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "\n",
    "        max_index = np.argmax(grid)\n",
    "        max_index = np.array(max_index)\n",
    "        return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "accident_dataset = AccidentDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f366a4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accident_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55240\\1389412538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create new array with 60% of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accident_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.6 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# define the class for multilinear regression\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(grid_size ** 2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, grid_size ** 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# define the class for multilinear regression\n",
    "# building the model object\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network().to(device)\n",
    "if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "    model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "    print(f\"Loaded model from model{grid_size}.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# define the training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print('pred ', pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    print(\"Testing model\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, also_correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print('y ', y)\n",
    "            #print('predition', pred.argmax(1))\n",
    "\n",
    "            #check if prediction is correct\n",
    "            predictions = torch.topk(pred, 2, dim=1).indices\n",
    "            #is_correct = (pred.argmax(1) == y or pred.argmax(1) == max_value)\n",
    "\n",
    "            for i in range (len(predictions)):\n",
    "                if y[i] in predictions[i]:\n",
    "                    if y[i] == pred.argmax(1)[i]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        also_correct += 1\n",
    "\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            #print(correct)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "    print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "    correct += also_correct\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "epochs = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "model.eval()\n",
    "edge_correct = 0\n",
    "for i in range (grid_size ** 2):\n",
    "    randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "    #randomnumber = 86903\n",
    "    #print(randomnumber)\n",
    "    #x, y = test_dataset[randomnumber][0], test_dataset[randomnumber][1]\n",
    "    edge = np.zeros(grid_size ** 2)\n",
    "    edge[i] = 1\n",
    "    x, y = torch.tensor(edge).float(), i\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.to(device))\n",
    "        #print(pred)\n",
    "        predicted, actual = pred.topk(grid_size), y\n",
    "        max_value = pred.max(0)[0]\n",
    "        index = []\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted.values[i].item() >= 0.8 * max_value:\n",
    "                index.append(predicted.indices[i].item())\n",
    "        part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "        part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "        part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "        part4 = f'{max_value}'.ljust(10, ' ')\n",
    "        print(part1, part2, part3, part4)\n",
    "        #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "        edge_correct += actual in index\n",
    "print('------------------------------------------')\n",
    "edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "print(edgestr1, edgestr2, edgestr3)\n",
    "#print(f\"Edge correct: {edge_correct}  size: {25}  edge correct/size: {edge_correct/25}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d3e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1563434100.0, '40.74743', '-73.925476']\n",
      "Grid size: 15\n",
      "21132\n",
      "14089\n",
      "35221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.337509  [   64/21132]\n",
      "loss: 3.834184  [ 6464/21132]\n",
      "loss: 3.448705  [12864/21132]\n",
      "loss: 3.555053  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3479  size: 14089  main correct/size: 0.24693022925686706\n",
      "Also correct: 3309  size: 14089  also correct/size: 0.23486407835900347\n",
      "Test Error: Accuracy: 48.2%, Avg loss: 3.472051\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.327186  [   64/21132]\n",
      "loss: 3.824769  [ 6464/21132]\n",
      "loss: 3.446289  [12864/21132]\n",
      "loss: 3.552595  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3479  size: 14089  main correct/size: 0.24693022925686706\n",
      "Also correct: 3309  size: 14089  also correct/size: 0.23486407835900347\n",
      "Test Error: Accuracy: 48.2%, Avg loss: 3.470333\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.326187  [   64/21132]\n",
      "loss: 3.821580  [ 6464/21132]\n",
      "loss: 3.444584  [12864/21132]\n",
      "loss: 3.550344  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3479  size: 14089  main correct/size: 0.24693022925686706\n",
      "Also correct: 3309  size: 14089  also correct/size: 0.23486407835900347\n",
      "Test Error: Accuracy: 48.2%, Avg loss: 3.468490\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.324834  [   64/21132]\n",
      "loss: 3.819142  [ 6464/21132]\n",
      "loss: 3.442623  [12864/21132]\n",
      "loss: 3.548077  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3479  size: 14089  main correct/size: 0.24693022925686706\n",
      "Also correct: 3309  size: 14089  also correct/size: 0.23486407835900347\n",
      "Test Error: Accuracy: 48.2%, Avg loss: 3.466447\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.323129  [   64/21132]\n",
      "loss: 3.816878  [ 6464/21132]\n",
      "loss: 3.440315  [12864/21132]\n",
      "loss: 3.545593  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3479  size: 14089  main correct/size: 0.24693022925686706\n",
      "Also correct: 3309  size: 14089  also correct/size: 0.23486407835900347\n",
      "Test Error: Accuracy: 48.2%, Avg loss: 3.464140\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  6.704768180847168\n",
      "Predicted: [125, 110] Actual: 1  False  6.651898384094238\n",
      "Predicted: [125, 110] Actual: 2  False  6.720151424407959\n",
      "Predicted: [125, 110] Actual: 3  False  6.7434821128845215\n",
      "Predicted: [125, 110] Actual: 4  False  6.815199375152588\n",
      "Predicted: [125, 110] Actual: 5  False  6.652035236358643\n",
      "Predicted: [125, 110] Actual: 6  False  6.868016242980957\n",
      "Predicted: [125, 110] Actual: 7  False  6.854582786560059\n",
      "Predicted: [125, 110] Actual: 8  False  6.800682067871094\n",
      "Predicted: [125, 110] Actual: 9  False  6.849112510681152\n",
      "Predicted: [125, 110] Actual: 10 False  6.797898292541504\n",
      "Predicted: [125, 110] Actual: 11 False  6.666359901428223\n",
      "Predicted: [125, 110] Actual: 12 False  6.909638404846191\n",
      "Predicted: [125, 110] Actual: 13 False  6.563925266265869\n",
      "Predicted: [125, 110] Actual: 14 False  6.601185321807861\n",
      "Predicted: [125, 110] Actual: 15 False  6.788680076599121\n",
      "Predicted: [125, 110] Actual: 16 False  6.757319927215576\n",
      "Predicted: [125, 110] Actual: 17 False  6.606171607971191\n",
      "Predicted: [125, 110] Actual: 18 False  6.738837242126465\n",
      "Predicted: [125, 110] Actual: 19 False  6.881086349487305\n",
      "Predicted: [125, 110] Actual: 20 False  6.799600601196289\n",
      "Predicted: [125, 110] Actual: 21 False  6.848371505737305\n",
      "Predicted: [125, 110] Actual: 22 False  6.920891761779785\n",
      "Predicted: [125, 110] Actual: 23 False  6.778250217437744\n",
      "Predicted: [125, 110] Actual: 24 False  6.7150750160217285\n",
      "Predicted: [125, 110] Actual: 25 False  6.774257659912109\n",
      "Predicted: [125, 110] Actual: 26 False  6.670899868011475\n",
      "Predicted: [125, 110] Actual: 27 False  6.6639909744262695\n",
      "Predicted: [125, 110] Actual: 28 False  6.800680160522461\n",
      "Predicted: [125, 110] Actual: 29 False  6.811067581176758\n",
      "Predicted: [125, 110] Actual: 30 False  6.833798408508301\n",
      "Predicted: [125, 110] Actual: 31 False  6.87039852142334\n",
      "Predicted: [125, 110] Actual: 32 False  6.714909553527832\n",
      "Predicted: [125, 110] Actual: 33 False  6.839199542999268\n",
      "Predicted: [125, 110] Actual: 34 False  6.666685104370117\n",
      "Predicted: [125, 110] Actual: 35 False  6.623858451843262\n",
      "Predicted: [125, 110] Actual: 36 False  6.7931647300720215\n",
      "Predicted: [125, 110] Actual: 37 False  6.890961647033691\n",
      "Predicted: [125, 110] Actual: 38 False  6.789529800415039\n",
      "Predicted: [125, 110] Actual: 39 False  6.613239288330078\n",
      "Predicted: [125, 110] Actual: 40 False  6.746357440948486\n",
      "Predicted: [125, 110] Actual: 41 False  6.911320686340332\n",
      "Predicted: [125, 110] Actual: 42 False  6.7696213722229\n",
      "Predicted: [125, 110] Actual: 43 False  6.912742614746094\n",
      "Predicted: [125, 110] Actual: 44 False  6.696042060852051\n",
      "Predicted: [125, 110] Actual: 45 False  6.832673072814941\n",
      "Predicted: [125, 110] Actual: 46 False  6.869516849517822\n",
      "Predicted: [125, 110] Actual: 47 False  6.638730525970459\n",
      "Predicted: [125, 110] Actual: 48 False  6.742198944091797\n",
      "Predicted: [125, 110] Actual: 49 False  6.979983329772949\n",
      "Predicted: [125, 110] Actual: 50 False  6.842501640319824\n",
      "Predicted: [125, 110] Actual: 51 False  6.720561504364014\n",
      "Predicted: [125, 110] Actual: 52 False  6.697781562805176\n",
      "Predicted: [125, 110] Actual: 53 False  6.666329383850098\n",
      "Predicted: [125, 110] Actual: 54 False  6.936804294586182\n",
      "Predicted: [125, 110] Actual: 55 False  6.706492900848389\n",
      "Predicted: [125, 110] Actual: 56 False  6.770496845245361\n",
      "Predicted: [125, 110] Actual: 57 False  6.741912364959717\n",
      "Predicted: [125, 110] Actual: 58 False  6.824957370758057\n",
      "Predicted: [125, 110] Actual: 59 False  6.707606315612793\n",
      "Predicted: [125, 110] Actual: 60 False  6.750984191894531\n",
      "Predicted: [125, 110] Actual: 61 False  6.748215675354004\n",
      "Predicted: [125, 110] Actual: 62 False  6.775550842285156\n",
      "Predicted: [125, 110] Actual: 63 False  6.855842590332031\n",
      "Predicted: [125, 110] Actual: 64 False  6.642333030700684\n",
      "Predicted: [125, 110] Actual: 65 False  6.81040096282959\n",
      "Predicted: [125, 110] Actual: 66 False  6.714450836181641\n",
      "Predicted: [125, 110] Actual: 67 False  6.821076393127441\n",
      "Predicted: [125, 110] Actual: 68 False  6.7832770347595215\n",
      "Predicted: [125, 110] Actual: 69 False  6.680668830871582\n",
      "Predicted: [125, 110] Actual: 70 False  6.816220283508301\n",
      "Predicted: [125, 110] Actual: 71 False  6.888012409210205\n",
      "Predicted: [125, 110] Actual: 72 False  6.704282760620117\n",
      "Predicted: [125, 110] Actual: 73 False  6.782841205596924\n",
      "Predicted: [125, 110] Actual: 74 False  6.633294582366943\n",
      "Predicted: [125, 110] Actual: 75 False  6.5931243896484375\n",
      "Predicted: [125, 110] Actual: 76 False  6.799442291259766\n",
      "Predicted: [125, 110] Actual: 77 False  6.577631950378418\n",
      "Predicted: [125, 110] Actual: 78 False  6.726249694824219\n",
      "Predicted: [125, 110] Actual: 79 False  6.672760963439941\n",
      "Predicted: [125, 110] Actual: 80 False  6.6972150802612305\n",
      "Predicted: [125, 110] Actual: 81 False  6.784605026245117\n",
      "Predicted: [125, 110] Actual: 82 False  6.829368591308594\n",
      "Predicted: [125, 110] Actual: 83 False  6.765717506408691\n",
      "Predicted: [125, 110] Actual: 84 False  6.601415634155273\n",
      "Predicted: [125, 110] Actual: 85 False  6.625449180603027\n",
      "Predicted: [125, 110] Actual: 86 False  6.785919189453125\n",
      "Predicted: [125, 110] Actual: 87 False  6.67318868637085\n",
      "Predicted: [125, 110] Actual: 88 False  6.631330490112305\n",
      "Predicted: [125, 110] Actual: 89 False  6.804194450378418\n",
      "Predicted: [125, 110] Actual: 90 False  6.7151384353637695\n",
      "Predicted: [125, 110] Actual: 91 False  6.757455825805664\n",
      "Predicted: [125, 110] Actual: 92 False  6.660111427307129\n",
      "Predicted: [125, 110] Actual: 93 False  6.784231662750244\n",
      "Predicted: [125, 110] Actual: 94 False  6.699373245239258\n",
      "Predicted: [125, 110] Actual: 95 False  6.877493858337402\n",
      "Predicted: [125, 110] Actual: 96 False  6.792120933532715\n",
      "Predicted: [125, 110] Actual: 97 False  6.516547203063965\n",
      "Predicted: [125, 110] Actual: 98 False  6.7125139236450195\n",
      "Predicted: [125, 110] Actual: 99 False  6.6400628089904785\n",
      "Predicted: [125, 110] Actual: 100 False  6.889285087585449\n",
      "Predicted: [125, 110] Actual: 101 False  6.667822360992432\n",
      "Predicted: [125, 110] Actual: 102 False  6.8279523849487305\n",
      "Predicted: [125, 110] Actual: 103 False  6.660773277282715\n",
      "Predicted: [125, 110] Actual: 104 False  6.819816589355469\n",
      "Predicted: [125, 110] Actual: 105 False  6.771958351135254\n",
      "Predicted: [125, 110] Actual: 106 False  6.64612340927124\n",
      "Predicted: [125, 110] Actual: 107 False  6.783936500549316\n",
      "Predicted: [125, 110] Actual: 108 False  6.524203300476074\n",
      "Predicted: [125, 110] Actual: 109 False  6.735805034637451\n",
      "Predicted: [125, 110] Actual: 110 True   6.971153259277344\n",
      "Predicted: [125, 110] Actual: 111 False  6.748163223266602\n",
      "Predicted: [125, 110] Actual: 112 False  6.895811080932617\n",
      "Predicted: [125, 110] Actual: 113 False  6.726014137268066\n",
      "Predicted: [125, 110] Actual: 114 False  6.814981937408447\n",
      "Predicted: [125, 110] Actual: 115 False  6.695159912109375\n",
      "Predicted: [125, 110] Actual: 116 False  6.91413688659668\n",
      "Predicted: [125, 110] Actual: 117 False  6.682358741760254\n",
      "Predicted: [125, 110] Actual: 118 False  6.681748390197754\n",
      "Predicted: [125, 110] Actual: 119 False  6.73681640625\n",
      "Predicted: [125, 110] Actual: 120 False  6.817356109619141\n",
      "Predicted: [125, 110] Actual: 121 False  6.81696081161499\n",
      "Predicted: [125, 110] Actual: 122 False  6.518763065338135\n",
      "Predicted: [125, 110] Actual: 123 False  6.73944091796875\n",
      "Predicted: [125, 110] Actual: 124 False  6.785838603973389\n",
      "Predicted: [125]   Actual: 125 True   10.829992294311523\n",
      "Predicted: [125, 110] Actual: 126 False  6.5716328620910645\n",
      "Predicted: [125, 110] Actual: 127 False  6.781301021575928\n",
      "Predicted: [125, 110] Actual: 128 False  6.817015171051025\n",
      "Predicted: [125, 110] Actual: 129 False  6.861843585968018\n",
      "Predicted: [125, 110] Actual: 130 False  6.743076801300049\n",
      "Predicted: [125, 110] Actual: 131 False  6.713286876678467\n",
      "Predicted: [125, 110] Actual: 132 False  6.793251037597656\n",
      "Predicted: [125, 110] Actual: 133 False  6.836012363433838\n",
      "Predicted: [125, 110] Actual: 134 False  6.690789699554443\n",
      "Predicted: [125, 110] Actual: 135 False  6.755826473236084\n",
      "Predicted: [125, 110] Actual: 136 False  6.849279403686523\n",
      "Predicted: [125, 110] Actual: 137 False  6.892735004425049\n",
      "Predicted: [125, 110] Actual: 138 False  6.944300651550293\n",
      "Predicted: [125, 110] Actual: 139 False  6.729070663452148\n",
      "Predicted: [125, 110] Actual: 140 False  6.758572101593018\n",
      "Predicted: [125, 110] Actual: 141 False  7.0053815841674805\n",
      "Predicted: [125, 110] Actual: 142 False  6.5940351486206055\n",
      "Predicted: [125, 110] Actual: 143 False  6.693655014038086\n",
      "Predicted: [125, 110] Actual: 144 False  6.671348571777344\n",
      "Predicted: [125, 110] Actual: 145 False  6.673423767089844\n",
      "Predicted: [125, 110] Actual: 146 False  7.087246894836426\n",
      "Predicted: [125, 110] Actual: 147 False  6.982476234436035\n",
      "Predicted: [125, 110] Actual: 148 False  6.550031661987305\n",
      "Predicted: [125, 110] Actual: 149 False  6.75788688659668\n",
      "Predicted: [125, 110] Actual: 150 False  6.760031700134277\n",
      "Predicted: [125, 110] Actual: 151 False  6.688948154449463\n",
      "Predicted: [125, 110] Actual: 152 False  6.9418230056762695\n",
      "Predicted: [125, 110] Actual: 153 False  6.8096022605896\n",
      "Predicted: [125, 110] Actual: 154 False  6.696205139160156\n",
      "Predicted: [125, 110] Actual: 155 False  6.74596643447876\n",
      "Predicted: [125, 110] Actual: 156 False  6.743776321411133\n",
      "Predicted: [125, 110] Actual: 157 False  6.733668327331543\n",
      "Predicted: [125, 110] Actual: 158 False  6.609028339385986\n",
      "Predicted: [125, 110] Actual: 159 False  6.705794811248779\n",
      "Predicted: [125, 110] Actual: 160 False  6.747227668762207\n",
      "Predicted: [125, 110] Actual: 161 False  6.802760124206543\n",
      "Predicted: [125, 110] Actual: 162 False  6.779607772827148\n",
      "Predicted: [125, 110] Actual: 163 False  6.809626579284668\n",
      "Predicted: [125, 110] Actual: 164 False  6.714752197265625\n",
      "Predicted: [125, 110] Actual: 165 False  6.836197376251221\n",
      "Predicted: [125, 110] Actual: 166 False  6.78978967666626\n",
      "Predicted: [125, 110] Actual: 167 False  6.796533107757568\n",
      "Predicted: [125, 110] Actual: 168 False  6.995805740356445\n",
      "Predicted: [125, 110] Actual: 169 False  6.747650146484375\n",
      "Predicted: [125, 110] Actual: 170 False  6.711009979248047\n",
      "Predicted: [125, 110] Actual: 171 False  6.595678329467773\n",
      "Predicted: [125, 110] Actual: 172 False  6.809526443481445\n",
      "Predicted: [125, 110] Actual: 173 False  6.738126754760742\n",
      "Predicted: [125, 110] Actual: 174 False  6.722671985626221\n",
      "Predicted: [125, 110] Actual: 175 False  6.753302574157715\n",
      "Predicted: [125, 110] Actual: 176 False  6.781676292419434\n",
      "Predicted: [125, 110] Actual: 177 False  6.570444107055664\n",
      "Predicted: [125, 110] Actual: 178 False  6.655916213989258\n",
      "Predicted: [125, 110] Actual: 179 False  6.888313293457031\n",
      "Predicted: [125, 110] Actual: 180 False  6.8445000648498535\n",
      "Predicted: [125, 110] Actual: 181 False  6.647353172302246\n",
      "Predicted: [125, 110] Actual: 182 False  6.673717498779297\n",
      "Predicted: [125, 110] Actual: 183 False  6.694974899291992\n",
      "Predicted: [125, 110] Actual: 184 False  6.534736633300781\n",
      "Predicted: [125, 110] Actual: 185 False  6.672593116760254\n",
      "Predicted: [125, 110] Actual: 186 False  6.882713317871094\n",
      "Predicted: [125, 110] Actual: 187 False  6.949318885803223\n",
      "Predicted: [125, 110] Actual: 188 False  6.969429969787598\n",
      "Predicted: [125, 110] Actual: 189 False  6.689597129821777\n",
      "Predicted: [125, 110] Actual: 190 False  6.9536027908325195\n",
      "Predicted: [125, 110] Actual: 191 False  6.869668483734131\n",
      "Predicted: [125, 110] Actual: 192 False  6.544951438903809\n",
      "Predicted: [125, 110] Actual: 193 False  6.777152061462402\n",
      "Predicted: [125, 110] Actual: 194 False  6.593247413635254\n",
      "Predicted: [125, 110] Actual: 195 False  6.752469062805176\n",
      "Predicted: [125, 110] Actual: 196 False  6.870674133300781\n",
      "Predicted: [125, 110] Actual: 197 False  6.915103912353516\n",
      "Predicted: [125, 110] Actual: 198 False  6.844986915588379\n",
      "Predicted: [125, 110] Actual: 199 False  6.806849002838135\n",
      "Predicted: [125, 110] Actual: 200 False  6.570511817932129\n",
      "Predicted: [125, 110] Actual: 201 False  6.7779717445373535\n",
      "Predicted: [125, 110] Actual: 202 False  6.7307538986206055\n",
      "Predicted: [125, 110] Actual: 203 False  6.605349540710449\n",
      "Predicted: [125, 110] Actual: 204 False  6.778348922729492\n",
      "Predicted: [125, 110] Actual: 205 False  6.783591270446777\n",
      "Predicted: [125, 110] Actual: 206 False  6.731360912322998\n",
      "Predicted: [125, 110] Actual: 207 False  6.805276870727539\n",
      "Predicted: [125, 110] Actual: 208 False  6.845852375030518\n",
      "Predicted: [125, 110] Actual: 209 False  6.766345500946045\n",
      "Predicted: [125, 110] Actual: 210 False  6.8143534660339355\n",
      "Predicted: [125, 110] Actual: 211 False  6.695151329040527\n",
      "Predicted: [125, 110] Actual: 212 False  6.812355995178223\n",
      "Predicted: [125, 110] Actual: 213 False  6.728655815124512\n",
      "Predicted: [125, 110] Actual: 214 False  6.767265319824219\n",
      "Predicted: [125, 110] Actual: 215 False  6.677822113037109\n",
      "Predicted: [125, 110] Actual: 216 False  6.767735481262207\n",
      "Predicted: [125, 110] Actual: 217 False  6.839803695678711\n",
      "Predicted: [125, 110] Actual: 218 False  6.787197113037109\n",
      "Predicted: [125, 110] Actual: 219 False  6.78411340713501\n",
      "Predicted: [125, 110] Actual: 220 False  6.791249752044678\n",
      "Predicted: [125, 110] Actual: 221 False  6.753994941711426\n",
      "Predicted: [125, 110] Actual: 222 False  6.643556594848633\n",
      "Predicted: [125, 110] Actual: 223 False  6.716650009155273\n",
      "Predicted: [125, 110] Actual: 224 False  6.789441108703613\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "21132\n",
      "14089\n",
      "35221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.579005  [   64/21132]\n",
      "loss: 3.734404  [ 6464/21132]\n",
      "loss: 3.640140  [12864/21132]\n",
      "loss: 3.226647  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3434  size: 14089  main correct/size: 0.24373624813684436\n",
      "Also correct: 3423  size: 14089  also correct/size: 0.24295549719639434\n",
      "Test Error: Accuracy: 48.7%, Avg loss: 3.461722\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.588298  [   64/21132]\n",
      "loss: 3.729395  [ 6464/21132]\n",
      "loss: 3.641651  [12864/21132]\n",
      "loss: 3.223508  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3434  size: 14089  main correct/size: 0.24373624813684436\n",
      "Also correct: 3423  size: 14089  also correct/size: 0.24295549719639434\n",
      "Test Error: Accuracy: 48.7%, Avg loss: 3.458986\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.588384  [   64/21132]\n",
      "loss: 3.725913  [ 6464/21132]\n",
      "loss: 3.640513  [12864/21132]\n",
      "loss: 3.219770  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3434  size: 14089  main correct/size: 0.24373624813684436\n",
      "Also correct: 3423  size: 14089  also correct/size: 0.24295549719639434\n",
      "Test Error: Accuracy: 48.7%, Avg loss: 3.455608\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.586635  [   64/21132]\n",
      "loss: 3.721678  [ 6464/21132]\n",
      "loss: 3.637647  [12864/21132]\n",
      "loss: 3.215342  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3434  size: 14089  main correct/size: 0.24373624813684436\n",
      "Also correct: 3423  size: 14089  also correct/size: 0.24295549719639434\n",
      "Test Error: Accuracy: 48.7%, Avg loss: 3.451583\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.583817  [   64/21132]\n",
      "loss: 3.716698  [ 6464/21132]\n",
      "loss: 3.633410  [12864/21132]\n",
      "loss: 3.210140  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3434  size: 14089  main correct/size: 0.24373624813684436\n",
      "Also correct: 3423  size: 14089  also correct/size: 0.24295549719639434\n",
      "Test Error: Accuracy: 48.7%, Avg loss: 3.446803\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  6.591415882110596\n",
      "Predicted: [125, 110] Actual: 1  False  6.5069146156311035\n",
      "Predicted: [125, 110] Actual: 2  False  6.567967891693115\n",
      "Predicted: [125, 110] Actual: 3  False  6.640251636505127\n",
      "Predicted: [125, 110] Actual: 4  False  6.728967189788818\n",
      "Predicted: [125, 110] Actual: 5  False  6.536924839019775\n",
      "Predicted: [125, 110] Actual: 6  False  6.763696193695068\n",
      "Predicted: [125, 110] Actual: 7  False  6.746283054351807\n",
      "Predicted: [125, 110] Actual: 8  False  6.691619396209717\n",
      "Predicted: [125, 110] Actual: 9  False  6.750850677490234\n",
      "Predicted: [125, 110] Actual: 10 False  6.657111167907715\n",
      "Predicted: [125, 110] Actual: 11 False  6.524221897125244\n",
      "Predicted: [125, 110] Actual: 12 False  6.814040660858154\n",
      "Predicted: [125, 110] Actual: 13 False  6.402258396148682\n",
      "Predicted: [125, 110] Actual: 14 False  6.45786190032959\n",
      "Predicted: [125, 110] Actual: 15 False  6.679009914398193\n",
      "Predicted: [125, 110] Actual: 16 False  6.620564937591553\n",
      "Predicted: [125, 110] Actual: 17 False  6.45303201675415\n",
      "Predicted: [125, 110] Actual: 18 False  6.6478590965271\n",
      "Predicted: [125, 110] Actual: 19 False  6.796311855316162\n",
      "Predicted: [125, 110] Actual: 20 False  6.684372901916504\n",
      "Predicted: [125, 110] Actual: 21 False  6.751617908477783\n",
      "Predicted: [125, 110] Actual: 22 False  6.868159294128418\n",
      "Predicted: [125, 110] Actual: 23 False  6.67133092880249\n",
      "Predicted: [125, 110] Actual: 24 False  6.646695613861084\n",
      "Predicted: [125, 110] Actual: 25 False  6.655533790588379\n",
      "Predicted: [125, 110] Actual: 26 False  6.536808967590332\n",
      "Predicted: [125, 110] Actual: 27 False  6.529995918273926\n",
      "Predicted: [125, 110] Actual: 28 False  6.664942741394043\n",
      "Predicted: [125, 110] Actual: 29 False  6.705261707305908\n",
      "Predicted: [125, 110] Actual: 30 False  6.752776622772217\n",
      "Predicted: [125, 110] Actual: 31 False  6.793464183807373\n",
      "Predicted: [125, 110] Actual: 32 False  6.583033084869385\n",
      "Predicted: [125, 110] Actual: 33 False  6.714263439178467\n",
      "Predicted: [125, 110] Actual: 34 False  6.513577938079834\n",
      "Predicted: [125, 110] Actual: 35 False  6.463561058044434\n",
      "Predicted: [125, 110] Actual: 36 False  6.669270992279053\n",
      "Predicted: [125, 110] Actual: 37 False  6.80502462387085\n",
      "Predicted: [125, 110] Actual: 38 False  6.662199020385742\n",
      "Predicted: [125, 110] Actual: 39 False  6.441459655761719\n",
      "Predicted: [125, 110] Actual: 40 False  6.62727689743042\n",
      "Predicted: [125, 110] Actual: 41 False  6.8219990730285645\n",
      "Predicted: [125, 110] Actual: 42 False  6.657561779022217\n",
      "Predicted: [125, 110] Actual: 43 False  6.84337854385376\n",
      "Predicted: [125, 110] Actual: 44 False  6.557851314544678\n",
      "Predicted: [125, 110] Actual: 45 False  6.7365403175354\n",
      "Predicted: [125, 110] Actual: 46 False  6.787298202514648\n",
      "Predicted: [125, 110] Actual: 47 False  6.474576473236084\n",
      "Predicted: [125, 110] Actual: 48 False  6.634722709655762\n",
      "Predicted: [125, 110] Actual: 49 False  6.88746976852417\n",
      "Predicted: [125, 110] Actual: 50 False  6.719484329223633\n",
      "Predicted: [125, 110] Actual: 51 False  6.583338737487793\n",
      "Predicted: [125, 110] Actual: 52 False  6.547206878662109\n",
      "Predicted: [125, 110] Actual: 53 False  6.510380744934082\n",
      "Predicted: [125, 110] Actual: 54 False  6.876938343048096\n",
      "Predicted: [125, 110] Actual: 55 False  6.59602165222168\n",
      "Predicted: [125, 110] Actual: 56 False  6.673720359802246\n",
      "Predicted: [125, 110] Actual: 57 False  6.630459308624268\n",
      "Predicted: [125, 110] Actual: 58 False  6.768057823181152\n",
      "Predicted: [125, 110] Actual: 59 False  6.614891529083252\n",
      "Predicted: [125, 110] Actual: 60 False  6.661205291748047\n",
      "Predicted: [125, 110] Actual: 61 False  6.613064289093018\n",
      "Predicted: [125, 110] Actual: 62 False  6.663692474365234\n",
      "Predicted: [125, 110] Actual: 63 False  6.774820804595947\n",
      "Predicted: [125, 110] Actual: 64 False  6.485335350036621\n",
      "Predicted: [125, 110] Actual: 65 False  6.65705680847168\n",
      "Predicted: [125, 110] Actual: 66 False  6.557734489440918\n",
      "Predicted: [125, 110] Actual: 67 False  6.64922571182251\n",
      "Predicted: [125, 110] Actual: 68 False  6.638279438018799\n",
      "Predicted: [125, 110] Actual: 69 False  6.544947624206543\n",
      "Predicted: [125, 110] Actual: 70 False  6.7012505531311035\n",
      "Predicted: [125, 110] Actual: 71 False  6.812657356262207\n",
      "Predicted: [125, 110] Actual: 72 False  6.566514492034912\n",
      "Predicted: [125, 110] Actual: 73 False  6.659369945526123\n",
      "Predicted: [125, 110] Actual: 74 False  6.483047962188721\n",
      "Predicted: [125, 110] Actual: 75 False  6.429615020751953\n",
      "Predicted: [125, 110] Actual: 76 False  6.70509672164917\n",
      "Predicted: [125, 110] Actual: 77 False  6.4521050453186035\n",
      "Predicted: [125, 110] Actual: 78 False  6.598150730133057\n",
      "Predicted: [125, 110] Actual: 79 False  6.502902507781982\n",
      "Predicted: [125, 110] Actual: 80 False  6.526946544647217\n",
      "Predicted: [125, 110] Actual: 81 False  6.633975028991699\n",
      "Predicted: [125, 110] Actual: 82 False  6.708529949188232\n",
      "Predicted: [125, 110] Actual: 83 False  6.616730213165283\n",
      "Predicted: [125, 110] Actual: 84 False  6.438692092895508\n",
      "Predicted: [125, 110] Actual: 85 False  6.464217185974121\n",
      "Predicted: [125, 110] Actual: 86 False  6.6623406410217285\n",
      "Predicted: [125, 110] Actual: 87 False  6.487288475036621\n",
      "Predicted: [125, 110] Actual: 88 False  6.494527339935303\n",
      "Predicted: [125, 110] Actual: 89 False  6.700894832611084\n",
      "Predicted: [125, 110] Actual: 90 False  6.600595951080322\n",
      "Predicted: [125, 110] Actual: 91 False  6.656145095825195\n",
      "Predicted: [125, 110] Actual: 92 False  6.531919002532959\n",
      "Predicted: [125, 110] Actual: 93 False  6.657386302947998\n",
      "Predicted: [125, 110] Actual: 94 False  6.602427959442139\n",
      "Predicted: [125, 110] Actual: 95 False  6.73795747756958\n",
      "Predicted: [125, 110] Actual: 96 False  6.610281467437744\n",
      "Predicted: [125, 110] Actual: 97 False  6.319207191467285\n",
      "Predicted: [125, 110] Actual: 98 False  6.583740234375\n",
      "Predicted: [125, 110] Actual: 99 False  6.507572650909424\n",
      "Predicted: [125, 110] Actual: 100 False  6.761820316314697\n",
      "Predicted: [125, 110] Actual: 101 False  6.4816131591796875\n",
      "Predicted: [125, 110] Actual: 102 False  6.743699550628662\n",
      "Predicted: [125, 110] Actual: 103 False  6.51062536239624\n",
      "Predicted: [125, 110] Actual: 104 False  6.673936367034912\n",
      "Predicted: [125, 110] Actual: 105 False  6.675220012664795\n",
      "Predicted: [125, 110] Actual: 106 False  6.512156963348389\n",
      "Predicted: [125, 110] Actual: 107 False  6.656031608581543\n",
      "Predicted: [125, 110] Actual: 108 False  6.390538215637207\n",
      "Predicted: [125, 110] Actual: 109 False  6.590240001678467\n",
      "Predicted: [125, 110] Actual: 110 True   6.7106451988220215\n",
      "Predicted: [125, 110] Actual: 111 False  6.609752655029297\n",
      "Predicted: [125, 110] Actual: 112 False  6.80327844619751\n",
      "Predicted: [125, 110] Actual: 113 False  6.6026930809021\n",
      "Predicted: [125, 110] Actual: 114 False  6.702233791351318\n",
      "Predicted: [125, 110] Actual: 115 False  6.559772968292236\n",
      "Predicted: [125, 110] Actual: 116 False  6.836595058441162\n",
      "Predicted: [125, 110] Actual: 117 False  6.541592597961426\n",
      "Predicted: [125, 110] Actual: 118 False  6.550175189971924\n",
      "Predicted: [125, 110] Actual: 119 False  6.597840785980225\n",
      "Predicted: [125, 110] Actual: 120 False  6.696301460266113\n",
      "Predicted: [125, 110] Actual: 121 False  6.720855236053467\n",
      "Predicted: [125, 110] Actual: 122 False  6.345303058624268\n",
      "Predicted: [125, 110] Actual: 123 False  6.614232063293457\n",
      "Predicted: [125, 110] Actual: 124 False  6.681016445159912\n",
      "Predicted: [125]   Actual: 125 True   12.539668083190918\n",
      "Predicted: [125, 110] Actual: 126 False  6.39260721206665\n",
      "Predicted: [125, 110] Actual: 127 False  6.646903991699219\n",
      "Predicted: [125, 110] Actual: 128 False  6.686140537261963\n",
      "Predicted: [125, 110] Actual: 129 False  6.743132591247559\n",
      "Predicted: [125, 110] Actual: 130 False  6.584834098815918\n",
      "Predicted: [125, 110] Actual: 131 False  6.582851886749268\n",
      "Predicted: [125, 110] Actual: 132 False  6.7019829750061035\n",
      "Predicted: [125, 110] Actual: 133 False  6.7505784034729\n",
      "Predicted: [125, 110] Actual: 134 False  6.545290470123291\n",
      "Predicted: [125, 110] Actual: 135 False  6.643478870391846\n",
      "Predicted: [125, 110] Actual: 136 False  6.717959880828857\n",
      "Predicted: [125, 110] Actual: 137 False  6.861091136932373\n",
      "Predicted: [125, 110] Actual: 138 False  6.897881031036377\n",
      "Predicted: [125, 110] Actual: 139 False  6.629441738128662\n",
      "Predicted: [125, 110] Actual: 140 False  6.583269119262695\n",
      "Predicted: [125, 110] Actual: 141 False  6.939825057983398\n",
      "Predicted: [125, 110] Actual: 142 False  6.44443941116333\n",
      "Predicted: [125, 110] Actual: 143 False  6.552098751068115\n",
      "Predicted: [125, 110] Actual: 144 False  6.544103145599365\n",
      "Predicted: [125, 110] Actual: 145 False  6.522093296051025\n",
      "Predicted: [125, 110] Actual: 146 False  7.0117034912109375\n",
      "Predicted: [125, 110] Actual: 147 False  6.891017436981201\n",
      "Predicted: [125, 110] Actual: 148 False  6.35026741027832\n",
      "Predicted: [125, 110] Actual: 149 False  6.6363654136657715\n",
      "Predicted: [125, 110] Actual: 150 False  6.649848937988281\n",
      "Predicted: [125, 110] Actual: 151 False  6.528892993927002\n",
      "Predicted: [125, 110] Actual: 152 False  6.857210636138916\n",
      "Predicted: [125, 110] Actual: 153 False  6.687537670135498\n",
      "Predicted: [125, 110] Actual: 154 False  6.555121898651123\n",
      "Predicted: [125, 110] Actual: 155 False  6.639892101287842\n",
      "Predicted: [125, 110] Actual: 156 False  6.583169460296631\n",
      "Predicted: [125, 110] Actual: 157 False  6.585387229919434\n",
      "Predicted: [125, 110] Actual: 158 False  6.451491832733154\n",
      "Predicted: [125, 110] Actual: 159 False  6.565037250518799\n",
      "Predicted: [125, 110] Actual: 160 False  6.649775505065918\n",
      "Predicted: [125, 110] Actual: 161 False  6.701614856719971\n",
      "Predicted: [125, 110] Actual: 162 False  6.691731929779053\n",
      "Predicted: [125, 110] Actual: 163 False  6.722705364227295\n",
      "Predicted: [125, 110] Actual: 164 False  6.5854902267456055\n",
      "Predicted: [125, 110] Actual: 165 False  6.748775005340576\n",
      "Predicted: [125, 110] Actual: 166 False  6.6989874839782715\n",
      "Predicted: [125, 110] Actual: 167 False  6.703197956085205\n",
      "Predicted: [125, 110] Actual: 168 False  6.961503028869629\n",
      "Predicted: [125, 110] Actual: 169 False  6.619507312774658\n",
      "Predicted: [125, 110] Actual: 170 False  6.566518783569336\n",
      "Predicted: [125, 110] Actual: 171 False  6.4401421546936035\n",
      "Predicted: [125, 110] Actual: 172 False  6.660359859466553\n",
      "Predicted: [125, 110] Actual: 173 False  6.607435703277588\n",
      "Predicted: [125, 110] Actual: 174 False  6.572619438171387\n",
      "Predicted: [125, 110] Actual: 175 False  6.6070170402526855\n",
      "Predicted: [125, 110] Actual: 176 False  6.647829055786133\n",
      "Predicted: [125, 110] Actual: 177 False  6.437489032745361\n",
      "Predicted: [125, 110] Actual: 178 False  6.510429382324219\n",
      "Predicted: [125, 110] Actual: 179 False  6.788564205169678\n",
      "Predicted: [125, 110] Actual: 180 False  6.752025604248047\n",
      "Predicted: [125, 110] Actual: 181 False  6.5017409324646\n",
      "Predicted: [125, 110] Actual: 182 False  6.5449676513671875\n",
      "Predicted: [125, 110] Actual: 183 False  6.59721040725708\n",
      "Predicted: [125, 110] Actual: 184 False  6.372668743133545\n",
      "Predicted: [125, 110] Actual: 185 False  6.565249919891357\n",
      "Predicted: [125, 110] Actual: 186 False  6.796667575836182\n",
      "Predicted: [125, 110] Actual: 187 False  6.880313396453857\n",
      "Predicted: [125, 110] Actual: 188 False  6.87921667098999\n",
      "Predicted: [125, 110] Actual: 189 False  6.541179656982422\n",
      "Predicted: [125, 110] Actual: 190 False  6.8934645652771\n",
      "Predicted: [125, 110] Actual: 191 False  6.816170692443848\n",
      "Predicted: [125, 110] Actual: 192 False  6.381242275238037\n",
      "Predicted: [125, 110] Actual: 193 False  6.70051383972168\n",
      "Predicted: [125, 110] Actual: 194 False  6.439850330352783\n",
      "Predicted: [125, 110] Actual: 195 False  6.621817111968994\n",
      "Predicted: [125, 110] Actual: 196 False  6.7946648597717285\n",
      "Predicted: [125, 110] Actual: 197 False  6.852129936218262\n",
      "Predicted: [125, 110] Actual: 198 False  6.750942707061768\n",
      "Predicted: [125, 110] Actual: 199 False  6.705953121185303\n",
      "Predicted: [125, 110] Actual: 200 False  6.436033248901367\n",
      "Predicted: [125, 110] Actual: 201 False  6.6626152992248535\n",
      "Predicted: [125, 110] Actual: 202 False  6.57271671295166\n",
      "Predicted: [125, 110] Actual: 203 False  6.388565540313721\n",
      "Predicted: [125, 110] Actual: 204 False  6.651681423187256\n",
      "Predicted: [125, 110] Actual: 205 False  6.667285442352295\n",
      "Predicted: [125, 110] Actual: 206 False  6.6582465171813965\n",
      "Predicted: [125, 110] Actual: 207 False  6.692404270172119\n",
      "Predicted: [125, 110] Actual: 208 False  6.765864849090576\n",
      "Predicted: [125, 110] Actual: 209 False  6.636692523956299\n",
      "Predicted: [125, 110] Actual: 210 False  6.71739387512207\n",
      "Predicted: [125, 110] Actual: 211 False  6.565366744995117\n",
      "Predicted: [125, 110] Actual: 212 False  6.708329677581787\n",
      "Predicted: [125, 110] Actual: 213 False  6.6320343017578125\n",
      "Predicted: [125, 110] Actual: 214 False  6.648874282836914\n",
      "Predicted: [125, 110] Actual: 215 False  6.551270484924316\n",
      "Predicted: [125, 110] Actual: 216 False  6.653716564178467\n",
      "Predicted: [125, 110] Actual: 217 False  6.7661519050598145\n",
      "Predicted: [125, 110] Actual: 218 False  6.67943000793457\n",
      "Predicted: [125, 110] Actual: 219 False  6.6661696434021\n",
      "Predicted: [125, 110] Actual: 220 False  6.671938896179199\n",
      "Predicted: [125, 110] Actual: 221 False  6.661194324493408\n",
      "Predicted: [125, 110] Actual: 222 False  6.510665416717529\n",
      "Predicted: [125, 110] Actual: 223 False  6.531935214996338\n",
      "Predicted: [125, 110] Actual: 224 False  6.693106651306152\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "21132\n",
      "14089\n",
      "35221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.633150  [   64/21132]\n",
      "loss: 3.513925  [ 6464/21132]\n",
      "loss: 3.479568  [12864/21132]\n",
      "loss: 3.963499  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3465  size: 14089  main correct/size: 0.24593654624174888\n",
      "Also correct: 3408  size: 14089  also correct/size: 0.24189083682305346\n",
      "Test Error: Accuracy: 48.8%, Avg loss: 3.434619\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.653952  [   64/21132]\n",
      "loss: 3.506191  [ 6464/21132]\n",
      "loss: 3.474597  [12864/21132]\n",
      "loss: 3.954934  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3465  size: 14089  main correct/size: 0.24593654624174888\n",
      "Also correct: 3408  size: 14089  also correct/size: 0.24189083682305346\n",
      "Test Error: Accuracy: 48.8%, Avg loss: 3.428140\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.648024  [   64/21132]\n",
      "loss: 3.498865  [ 6464/21132]\n",
      "loss: 3.468871  [12864/21132]\n",
      "loss: 3.946974  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3465  size: 14089  main correct/size: 0.24593654624174888\n",
      "Also correct: 3408  size: 14089  also correct/size: 0.24189083682305346\n",
      "Test Error: Accuracy: 48.8%, Avg loss: 3.420170\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.639618  [   64/21132]\n",
      "loss: 3.490106  [ 6464/21132]\n",
      "loss: 3.461984  [12864/21132]\n",
      "loss: 3.938126  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3465  size: 14089  main correct/size: 0.24593654624174888\n",
      "Also correct: 3408  size: 14089  also correct/size: 0.24189083682305346\n",
      "Test Error: Accuracy: 48.8%, Avg loss: 3.410587\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.629459  [   64/21132]\n",
      "loss: 3.479643  [ 6464/21132]\n",
      "loss: 3.453785  [12864/21132]\n",
      "loss: 3.927922  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3465  size: 14089  main correct/size: 0.24593654624174888\n",
      "Also correct: 3408  size: 14089  also correct/size: 0.24189083682305346\n",
      "Test Error: Accuracy: 48.8%, Avg loss: 3.399188\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  6.390450477600098\n",
      "Predicted: [125, 110] Actual: 1  False  6.258792877197266\n",
      "Predicted: [125, 110] Actual: 2  False  6.303740501403809\n",
      "Predicted: [125, 110] Actual: 3  False  6.478559494018555\n",
      "Predicted: [125, 110] Actual: 4  False  6.589797019958496\n",
      "Predicted: [125, 110] Actual: 5  False  6.340899467468262\n",
      "Predicted: [125, 110] Actual: 6  False  6.587574005126953\n",
      "Predicted: [125, 110] Actual: 7  False  6.576662540435791\n",
      "Predicted: [125, 110] Actual: 8  False  6.51580286026001\n",
      "Predicted: [125, 110] Actual: 9  False  6.598749160766602\n",
      "Predicted: [125, 110] Actual: 10 False  6.421140670776367\n",
      "Predicted: [125, 110] Actual: 11 False  6.275432586669922\n",
      "Predicted: [125, 110] Actual: 12 False  6.665862083435059\n",
      "Predicted: [125, 110] Actual: 13 False  6.126475811004639\n",
      "Predicted: [125, 110] Actual: 14 False  6.212689399719238\n",
      "Predicted: [125, 110] Actual: 15 False  6.4954118728637695\n",
      "Predicted: [125, 110] Actual: 16 False  6.404471397399902\n",
      "Predicted: [125, 110] Actual: 17 False  6.181392192840576\n",
      "Predicted: [125, 110] Actual: 18 False  6.5081400871276855\n",
      "Predicted: [125, 110] Actual: 19 False  6.6711931228637695\n",
      "Predicted: [125, 110] Actual: 20 False  6.492129802703857\n",
      "Predicted: [125, 110] Actual: 21 False  6.599230766296387\n",
      "Predicted: [125, 110] Actual: 22 False  6.805230140686035\n",
      "Predicted: [125, 110] Actual: 23 False  6.501560211181641\n",
      "Predicted: [125, 110] Actual: 24 False  6.558670520782471\n",
      "Predicted: [125, 110] Actual: 25 False  6.459176063537598\n",
      "Predicted: [125, 110] Actual: 26 False  6.329165935516357\n",
      "Predicted: [125, 110] Actual: 27 False  6.30122184753418\n",
      "Predicted: [125, 110] Actual: 28 False  6.457380294799805\n",
      "Predicted: [125, 110] Actual: 29 False  6.543481826782227\n",
      "Predicted: [125, 110] Actual: 30 False  6.634286880493164\n",
      "Predicted: [125, 110] Actual: 31 False  6.677066326141357\n",
      "Predicted: [125, 110] Actual: 32 False  6.358170032501221\n",
      "Predicted: [125, 110] Actual: 33 False  6.518531322479248\n",
      "Predicted: [125, 110] Actual: 34 False  6.248675346374512\n",
      "Predicted: [125, 110] Actual: 35 False  6.1682939529418945\n",
      "Predicted: [125, 110] Actual: 36 False  6.461360931396484\n",
      "Predicted: [125, 110] Actual: 37 False  6.680872917175293\n",
      "Predicted: [125, 110] Actual: 38 False  6.4638800621032715\n",
      "Predicted: [125, 110] Actual: 39 False  6.140820503234863\n",
      "Predicted: [125, 110] Actual: 40 False  6.4227752685546875\n",
      "Predicted: [125, 110] Actual: 41 False  6.702206611633301\n",
      "Predicted: [125, 110] Actual: 42 False  6.479784965515137\n",
      "Predicted: [125, 110] Actual: 43 False  6.738282203674316\n",
      "Predicted: [125, 110] Actual: 44 False  6.335195064544678\n",
      "Predicted: [125, 110] Actual: 45 False  6.581747055053711\n",
      "Predicted: [125, 110] Actual: 46 False  6.689436435699463\n",
      "Predicted: [125, 110] Actual: 47 False  6.183777809143066\n",
      "Predicted: [125, 110] Actual: 48 False  6.458552360534668\n",
      "Predicted: [125, 110] Actual: 49 False  6.7380452156066895\n",
      "Predicted: [125, 110] Actual: 50 False  6.541847229003906\n",
      "Predicted: [125, 110] Actual: 51 False  6.345307350158691\n",
      "Predicted: [125, 110] Actual: 52 False  6.275382041931152\n",
      "Predicted: [125, 110] Actual: 53 False  6.257325172424316\n",
      "Predicted: [125, 110] Actual: 54 False  6.806486129760742\n",
      "Predicted: [125, 110] Actual: 55 False  6.410795211791992\n",
      "Predicted: [125, 110] Actual: 56 False  6.522958755493164\n",
      "Predicted: [125, 110] Actual: 57 False  6.4490156173706055\n",
      "Predicted: [125, 110] Actual: 58 False  6.683568954467773\n",
      "Predicted: [125, 110] Actual: 59 False  6.4805474281311035\n",
      "Predicted: [125, 110] Actual: 60 False  6.514490127563477\n",
      "Predicted: [125, 110] Actual: 61 False  6.395008563995361\n",
      "Predicted: [125, 110] Actual: 62 False  6.490440845489502\n",
      "Predicted: [125, 110] Actual: 63 False  6.663107872009277\n",
      "Predicted: [125, 110] Actual: 64 False  6.221626281738281\n",
      "Predicted: [125, 110] Actual: 65 False  6.40118408203125\n",
      "Predicted: [125, 110] Actual: 66 False  6.251995086669922\n",
      "Predicted: [125, 110] Actual: 67 False  6.3185625076293945\n",
      "Predicted: [125, 110] Actual: 68 False  6.378802299499512\n",
      "Predicted: [125, 110] Actual: 69 False  6.300906181335449\n",
      "Predicted: [125, 110] Actual: 70 False  6.500170707702637\n",
      "Predicted: [125, 110] Actual: 71 False  6.7065534591674805\n",
      "Predicted: [125, 110] Actual: 72 False  6.348040580749512\n",
      "Predicted: [125, 110] Actual: 73 False  6.465481758117676\n",
      "Predicted: [125, 110] Actual: 74 False  6.239555358886719\n",
      "Predicted: [125, 110] Actual: 75 False  6.149379253387451\n",
      "Predicted: [125, 110] Actual: 76 False  6.55391263961792\n",
      "Predicted: [125, 110] Actual: 77 False  6.236618995666504\n",
      "Predicted: [125, 110] Actual: 78 False  6.387505531311035\n",
      "Predicted: [125, 110] Actual: 79 False  6.208288669586182\n",
      "Predicted: [125, 110] Actual: 80 False  6.183915138244629\n",
      "Predicted: [125, 110] Actual: 81 False  6.356579780578613\n",
      "Predicted: [125, 110] Actual: 82 False  6.463854789733887\n",
      "Predicted: [125, 110] Actual: 83 False  6.342952728271484\n",
      "Predicted: [125, 110] Actual: 84 False  6.15036678314209\n",
      "Predicted: [125, 110] Actual: 85 False  6.174603462219238\n",
      "Predicted: [125, 110] Actual: 86 False  6.458112716674805\n",
      "Predicted: [125, 110] Actual: 87 False  6.185983657836914\n",
      "Predicted: [125, 110] Actual: 88 False  6.238399982452393\n",
      "Predicted: [125, 110] Actual: 89 False  6.5651350021362305\n",
      "Predicted: [125, 110] Actual: 90 False  6.42888879776001\n",
      "Predicted: [125, 110] Actual: 91 False  6.498033046722412\n",
      "Predicted: [125, 110] Actual: 92 False  6.319375514984131\n",
      "Predicted: [125, 110] Actual: 93 False  6.454952239990234\n",
      "Predicted: [125, 110] Actual: 94 False  6.4350361824035645\n",
      "Predicted: [125, 110] Actual: 95 False  6.47592830657959\n",
      "Predicted: [125, 110] Actual: 96 False  6.269977569580078\n",
      "Predicted: [125, 110] Actual: 97 False  5.980002403259277\n",
      "Predicted: [125, 110] Actual: 98 False  6.360588073730469\n",
      "Predicted: [125, 110] Actual: 99 False  6.257299423217773\n",
      "Predicted: [125, 110] Actual: 100 False  6.542524337768555\n",
      "Predicted: [125, 110] Actual: 101 False  6.128945350646973\n",
      "Predicted: [125, 110] Actual: 102 False  6.5934834480285645\n",
      "Predicted: [125, 110] Actual: 103 False  6.255959987640381\n",
      "Predicted: [125, 110] Actual: 104 False  6.458213806152344\n",
      "Predicted: [125, 110] Actual: 105 False  6.52593994140625\n",
      "Predicted: [125, 110] Actual: 106 False  6.28007698059082\n",
      "Predicted: [125, 110] Actual: 107 False  6.455777168273926\n",
      "Predicted: [125, 110] Actual: 108 False  6.158448219299316\n",
      "Predicted: [125, 110] Actual: 109 False  6.319042205810547\n",
      "Predicted: [110, 125] Actual: 110 True   6.199368476867676\n",
      "Predicted: [125, 110] Actual: 111 False  6.370584487915039\n",
      "Predicted: [125, 110] Actual: 112 False  6.646243095397949\n",
      "Predicted: [125, 110] Actual: 113 False  6.383321285247803\n",
      "Predicted: [125, 110] Actual: 114 False  6.5116868019104\n",
      "Predicted: [125, 110] Actual: 115 False  6.323905944824219\n",
      "Predicted: [125, 110] Actual: 116 False  6.716808319091797\n",
      "Predicted: [125, 110] Actual: 117 False  6.293041229248047\n",
      "Predicted: [125, 110] Actual: 118 False  6.340559959411621\n",
      "Predicted: [125, 110] Actual: 119 False  6.365556716918945\n",
      "Predicted: [125, 110] Actual: 120 False  6.496626853942871\n",
      "Predicted: [125, 110] Actual: 121 False  6.562349796295166\n",
      "Predicted: [125, 110] Actual: 122 False  6.057854652404785\n",
      "Predicted: [125, 110] Actual: 123 False  6.414231300354004\n",
      "Predicted: [125, 110] Actual: 124 False  6.515024185180664\n",
      "Predicted: [125]   Actual: 125 True   16.559589385986328\n",
      "Predicted: [125, 110] Actual: 126 False  6.045871257781982\n",
      "Predicted: [125, 110] Actual: 127 False  6.397946834564209\n",
      "Predicted: [125, 110] Actual: 128 False  6.474181652069092\n",
      "Predicted: [125, 110] Actual: 129 False  6.554882049560547\n",
      "Predicted: [125, 110] Actual: 130 False  6.315013885498047\n",
      "Predicted: [125, 110] Actual: 131 False  6.3591628074646\n",
      "Predicted: [125, 110] Actual: 132 False  6.561561584472656\n",
      "Predicted: [125, 110] Actual: 133 False  6.6099748611450195\n",
      "Predicted: [125, 110] Actual: 134 False  6.294256210327148\n",
      "Predicted: [125, 110] Actual: 135 False  6.455949783325195\n",
      "Predicted: [125, 110] Actual: 136 False  6.497652053833008\n",
      "Predicted: [125, 110] Actual: 137 False  6.841200351715088\n",
      "Predicted: [125, 110] Actual: 138 False  6.845458030700684\n",
      "Predicted: [125, 110] Actual: 139 False  6.466869831085205\n",
      "Predicted: [125, 110] Actual: 140 False  6.294268608093262\n",
      "Predicted: [125, 110] Actual: 141 False  6.8129377365112305\n",
      "Predicted: [125, 110] Actual: 142 False  6.198245048522949\n",
      "Predicted: [125, 110] Actual: 143 False  6.323110580444336\n",
      "Predicted: [125, 110] Actual: 144 False  6.327156066894531\n",
      "Predicted: [125, 110] Actual: 145 False  6.275623321533203\n",
      "Predicted: [125, 110] Actual: 146 False  6.927727222442627\n",
      "Predicted: [125, 110] Actual: 147 False  6.766100883483887\n",
      "Predicted: [125, 110] Actual: 148 False  6.019380569458008\n",
      "Predicted: [125, 110] Actual: 149 False  6.44670295715332\n",
      "Predicted: [125, 110] Actual: 150 False  6.478549480438232\n",
      "Predicted: [125, 110] Actual: 151 False  6.258902549743652\n",
      "Predicted: [125, 110] Actual: 152 False  6.735809326171875\n",
      "Predicted: [125, 110] Actual: 153 False  6.512547969818115\n",
      "Predicted: [125, 110] Actual: 154 False  6.32926082611084\n",
      "Predicted: [125, 110] Actual: 155 False  6.460721969604492\n",
      "Predicted: [125, 110] Actual: 156 False  6.292146682739258\n",
      "Predicted: [125, 110] Actual: 157 False  6.32760763168335\n",
      "Predicted: [125, 110] Actual: 158 False  6.165202617645264\n",
      "Predicted: [125, 110] Actual: 159 False  6.318213939666748\n",
      "Predicted: [125, 110] Actual: 160 False  6.492273807525635\n",
      "Predicted: [125, 110] Actual: 161 False  6.536807060241699\n",
      "Predicted: [125, 110] Actual: 162 False  6.55137825012207\n",
      "Predicted: [125, 110] Actual: 163 False  6.582952499389648\n",
      "Predicted: [125, 110] Actual: 164 False  6.371313095092773\n",
      "Predicted: [125, 110] Actual: 165 False  6.625964641571045\n",
      "Predicted: [125, 110] Actual: 166 False  6.544952392578125\n",
      "Predicted: [125, 110] Actual: 167 False  6.5502824783325195\n",
      "Predicted: [125, 110] Actual: 168 False  6.942905426025391\n",
      "Predicted: [125, 110] Actual: 169 False  6.402776718139648\n",
      "Predicted: [125, 110] Actual: 170 False  6.333828449249268\n",
      "Predicted: [125, 110] Actual: 171 False  6.158026695251465\n",
      "Predicted: [125, 110] Actual: 172 False  6.42016077041626\n",
      "Predicted: [125, 110] Actual: 173 False  6.3636155128479\n",
      "Predicted: [125, 110] Actual: 174 False  6.3077545166015625\n",
      "Predicted: [125, 110] Actual: 175 False  6.368020057678223\n",
      "Predicted: [125, 110] Actual: 176 False  6.446699142456055\n",
      "Predicted: [125, 110] Actual: 177 False  6.231303691864014\n",
      "Predicted: [125, 110] Actual: 178 False  6.257515907287598\n",
      "Predicted: [125, 110] Actual: 179 False  6.628073692321777\n",
      "Predicted: [125, 110] Actual: 180 False  6.608290672302246\n",
      "Predicted: [125, 110] Actual: 181 False  6.2643537521362305\n",
      "Predicted: [125, 110] Actual: 182 False  6.336912155151367\n",
      "Predicted: [125, 110] Actual: 183 False  6.44686222076416\n",
      "Predicted: [125, 110] Actual: 184 False  6.081268310546875\n",
      "Predicted: [125, 110] Actual: 185 False  6.384372711181641\n",
      "Predicted: [125, 110] Actual: 186 False  6.675676345825195\n",
      "Predicted: [125, 110] Actual: 187 False  6.786501884460449\n",
      "Predicted: [125, 110] Actual: 188 False  6.743516445159912\n",
      "Predicted: [125, 110] Actual: 189 False  6.290904998779297\n",
      "Predicted: [125, 110] Actual: 190 False  6.822307109832764\n",
      "Predicted: [125, 110] Actual: 191 False  6.74797248840332\n",
      "Predicted: [125, 110] Actual: 192 False  6.089954376220703\n",
      "Predicted: [125, 110] Actual: 193 False  6.594422340393066\n",
      "Predicted: [125, 110] Actual: 194 False  6.172713756561279\n",
      "Predicted: [125, 110] Actual: 195 False  6.402541637420654\n",
      "Predicted: [125, 110] Actual: 196 False  6.684841156005859\n",
      "Predicted: [125, 110] Actual: 197 False  6.771966934204102\n",
      "Predicted: [125, 110] Actual: 198 False  6.612894058227539\n",
      "Predicted: [125, 110] Actual: 199 False  6.5515217781066895\n",
      "Predicted: [125, 110] Actual: 200 False  6.214171886444092\n",
      "Predicted: [125, 110] Actual: 201 False  6.483697891235352\n",
      "Predicted: [125, 110] Actual: 202 False  6.297564506530762\n",
      "Predicted: [125, 110] Actual: 203 False  6.017768859863281\n",
      "Predicted: [125, 110] Actual: 204 False  6.4492011070251465\n",
      "Predicted: [125, 110] Actual: 205 False  6.468529224395752\n",
      "Predicted: [125, 110] Actual: 206 False  6.54963493347168\n",
      "Predicted: [125, 110] Actual: 207 False  6.511229991912842\n",
      "Predicted: [125, 110] Actual: 208 False  6.656361103057861\n",
      "Predicted: [125, 110] Actual: 209 False  6.426640033721924\n",
      "Predicted: [125, 110] Actual: 210 False  6.561491966247559\n",
      "Predicted: [125, 110] Actual: 211 False  6.363774299621582\n",
      "Predicted: [125, 110] Actual: 212 False  6.537291526794434\n",
      "Predicted: [125, 110] Actual: 213 False  6.470374584197998\n",
      "Predicted: [125, 110] Actual: 214 False  6.460616111755371\n",
      "Predicted: [125, 110] Actual: 215 False  6.326706886291504\n",
      "Predicted: [125, 110] Actual: 216 False  6.473204612731934\n",
      "Predicted: [125, 110] Actual: 217 False  6.67342472076416\n",
      "Predicted: [125, 110] Actual: 218 False  6.500880241394043\n",
      "Predicted: [125, 110] Actual: 219 False  6.467887878417969\n",
      "Predicted: [125, 110] Actual: 220 False  6.4749956130981445\n",
      "Predicted: [125, 110] Actual: 221 False  6.51118278503418\n",
      "Predicted: [125, 110] Actual: 222 False  6.288825035095215\n",
      "Predicted: [125, 110] Actual: 223 False  6.216495990753174\n",
      "Predicted: [125, 110] Actual: 224 False  6.533058166503906\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "21132\n",
      "14089\n",
      "35221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.454294  [   64/21132]\n",
      "loss: 3.165860  [ 6464/21132]\n",
      "loss: 3.340539  [12864/21132]\n",
      "loss: 3.407583  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3501  size: 14089  main correct/size: 0.24849173113776704\n",
      "Also correct: 3336  size: 14089  also correct/size: 0.2367804670310171\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.389412\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.466130  [   64/21132]\n",
      "loss: 3.154099  [ 6464/21132]\n",
      "loss: 3.318511  [12864/21132]\n",
      "loss: 3.393108  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3501  size: 14089  main correct/size: 0.24849173113776704\n",
      "Also correct: 3336  size: 14089  also correct/size: 0.2367804670310171\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.374448\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.452661  [   64/21132]\n",
      "loss: 3.139840  [ 6464/21132]\n",
      "loss: 3.295796  [12864/21132]\n",
      "loss: 3.375719  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3502  size: 14089  main correct/size: 0.24856270849598977\n",
      "Also correct: 3335  size: 14089  also correct/size: 0.23670948967279437\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.357131\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.435332  [   64/21132]\n",
      "loss: 3.123397  [ 6464/21132]\n",
      "loss: 3.270410  [12864/21132]\n",
      "loss: 3.356240  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3620  size: 14089  main correct/size: 0.2569380367662716\n",
      "Also correct: 3217  size: 14089  also correct/size: 0.2283341614025126\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.337966\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.415896  [   64/21132]\n",
      "loss: 3.105072  [ 6464/21132]\n",
      "loss: 3.242902  [12864/21132]\n",
      "loss: 3.335431  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3636  size: 14089  main correct/size: 0.2580736744978352\n",
      "Also correct: 3201  size: 14089  also correct/size: 0.22719852367094898\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.317600\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  5.744288444519043\n",
      "Predicted: [110, 125] Actual: 1  False  5.682129859924316\n",
      "Predicted: [110, 125] Actual: 2  False  5.739513397216797\n",
      "Predicted: [125, 110] Actual: 3  False  5.881290435791016\n",
      "Predicted: [125, 110] Actual: 4  False  6.051492691040039\n",
      "Predicted: [125, 110] Actual: 5  False  5.697038650512695\n",
      "Predicted: [125, 110] Actual: 6  False  6.012607574462891\n",
      "Predicted: [125, 110] Actual: 7  False  6.032540321350098\n",
      "Predicted: [125, 110] Actual: 8  False  5.940526962280273\n",
      "Predicted: [125, 110] Actual: 9  False  6.060914039611816\n",
      "Predicted: [110, 125] Actual: 10 False  5.7975873947143555\n",
      "Predicted: [110, 125] Actual: 11 False  5.680570602416992\n",
      "Predicted: [125, 110] Actual: 12 False  6.132678985595703\n",
      "Predicted: [110, 125] Actual: 13 False  5.607639312744141\n",
      "Predicted: [110, 125] Actual: 14 False  5.612602710723877\n",
      "Predicted: [125, 110] Actual: 15 False  5.8622894287109375\n",
      "Predicted: [125, 110] Actual: 16 False  5.738361835479736\n",
      "Predicted: [110, 125] Actual: 17 False  5.6387739181518555\n",
      "Predicted: [125, 110] Actual: 18 False  6.007468223571777\n",
      "Predicted: [125, 110] Actual: 19 False  6.182016849517822\n",
      "Predicted: [125, 110] Actual: 20 False  5.861924648284912\n",
      "Predicted: [125, 110] Actual: 21 False  6.038219928741455\n",
      "Predicted: [125, 110] Actual: 22 False  6.415336608886719\n",
      "Predicted: [125, 110] Actual: 23 False  5.913527011871338\n",
      "Predicted: [125, 110] Actual: 24 False  6.133471488952637\n",
      "Predicted: [125, 110] Actual: 25 False  5.813291549682617\n",
      "Predicted: [125, 110] Actual: 26 False  5.681258201599121\n",
      "Predicted: [110, 125] Actual: 27 False  5.649152755737305\n",
      "Predicted: [125, 110] Actual: 28 False  5.821565628051758\n",
      "Predicted: [125, 110] Actual: 29 False  5.982979774475098\n",
      "Predicted: [125, 110] Actual: 30 False  6.136221408843994\n",
      "Predicted: [125, 110] Actual: 31 False  6.235844612121582\n",
      "Predicted: [125, 110] Actual: 32 False  5.672354221343994\n",
      "Predicted: [125, 110] Actual: 33 False  5.896976470947266\n",
      "Predicted: [110, 125] Actual: 34 False  5.696242809295654\n",
      "Predicted: [110, 125] Actual: 35 False  5.635570049285889\n",
      "Predicted: [125, 110] Actual: 36 False  5.778230667114258\n",
      "Predicted: [125, 110] Actual: 37 False  6.194550514221191\n",
      "Predicted: [125, 110] Actual: 38 False  5.844099044799805\n",
      "Predicted: [110, 125] Actual: 39 False  5.703644752502441\n",
      "Predicted: [125, 110] Actual: 40 False  5.7945170402526855\n",
      "Predicted: [125, 110] Actual: 41 False  6.212411880493164\n",
      "Predicted: [125, 110] Actual: 42 False  5.894430637359619\n",
      "Predicted: [125, 110] Actual: 43 False  6.287076950073242\n",
      "Predicted: [110, 125] Actual: 44 False  5.696791172027588\n",
      "Predicted: [125, 110] Actual: 45 False  6.04677677154541\n",
      "Predicted: [125, 110] Actual: 46 False  6.261867046356201\n",
      "Predicted: [110, 125] Actual: 47 False  5.664481163024902\n",
      "Predicted: [125, 110] Actual: 48 False  5.849928379058838\n",
      "Predicted: [125, 110] Actual: 49 False  6.147692680358887\n",
      "Predicted: [125, 110] Actual: 50 False  5.986618995666504\n",
      "Predicted: [110, 125] Actual: 51 False  5.698817729949951\n",
      "Predicted: [110, 125] Actual: 52 False  5.698032379150391\n",
      "Predicted: [110, 125] Actual: 53 False  5.687444686889648\n",
      "Predicted: [125, 110] Actual: 54 False  6.411989212036133\n",
      "Predicted: [125, 110] Actual: 55 False  5.779167175292969\n",
      "Predicted: [125, 110] Actual: 56 False  5.960578918457031\n",
      "Predicted: [125, 110] Actual: 57 False  5.854073524475098\n",
      "Predicted: [125, 110] Actual: 58 False  6.2667317390441895\n",
      "Predicted: [125, 110] Actual: 59 False  5.999679088592529\n",
      "Predicted: [125, 110] Actual: 60 False  5.95947790145874\n",
      "Predicted: [110, 125] Actual: 61 False  5.737821102142334\n",
      "Predicted: [125, 110] Actual: 62 False  5.892851829528809\n",
      "Predicted: [125, 110] Actual: 63 False  6.2207231521606445\n",
      "Predicted: [110, 125] Actual: 64 False  5.644338130950928\n",
      "Predicted: [110, 125] Actual: 65 False  5.803255558013916\n",
      "Predicted: [110, 125] Actual: 66 False  5.708082675933838\n",
      "Predicted: [110, 125] Actual: 67 False  5.848168849945068\n",
      "Predicted: [110, 125] Actual: 68 False  5.740314483642578\n",
      "Predicted: [110, 125] Actual: 69 False  5.649546146392822\n",
      "Predicted: [125, 110] Actual: 70 False  5.915568828582764\n",
      "Predicted: [125, 110] Actual: 71 False  6.255884170532227\n",
      "Predicted: [110, 125] Actual: 72 False  5.681281089782715\n",
      "Predicted: [125, 110] Actual: 73 False  5.8466081619262695\n",
      "Predicted: [110, 125] Actual: 74 False  5.669152736663818\n",
      "Predicted: [110, 125] Actual: 75 False  5.661019325256348\n",
      "Predicted: [125, 110] Actual: 76 False  5.999721050262451\n",
      "Predicted: [125, 110] Actual: 77 False  5.564265727996826\n",
      "Predicted: [125, 110] Actual: 78 False  5.724193572998047\n",
      "Predicted: [110, 125] Actual: 79 False  5.727582931518555\n",
      "Predicted: [110, 125] Actual: 80 False  5.761260509490967\n",
      "Predicted: [110, 125] Actual: 81 False  5.741494655609131\n",
      "Predicted: [110, 125] Actual: 82 False  5.773940086364746\n",
      "Predicted: [110, 125] Actual: 83 False  5.725374221801758\n",
      "Predicted: [110, 125] Actual: 84 False  5.616390228271484\n",
      "Predicted: [110, 125] Actual: 85 False  5.584419250488281\n",
      "Predicted: [125, 110] Actual: 86 False  5.748878479003906\n",
      "Predicted: [110, 125] Actual: 87 False  5.728907585144043\n",
      "Predicted: [110, 125] Actual: 88 False  5.601210117340088\n",
      "Predicted: [125, 110] Actual: 89 False  6.09473991394043\n",
      "Predicted: [125, 110] Actual: 90 False  5.856405258178711\n",
      "Predicted: [125, 110] Actual: 91 False  5.944867134094238\n",
      "Predicted: [110, 125] Actual: 92 False  5.639621257781982\n",
      "Predicted: [125, 110] Actual: 93 False  5.819495677947998\n",
      "Predicted: [125, 110] Actual: 94 False  5.796261787414551\n",
      "Predicted: [110, 125] Actual: 95 False  5.783536911010742\n",
      "Predicted: [110, 125] Actual: 96 False  5.862150192260742\n",
      "Predicted: [110, 125] Actual: 97 False  5.541263580322266\n",
      "Predicted: [110, 125] Actual: 98 False  5.668100833892822\n",
      "Predicted: [110, 125] Actual: 99 False  5.6119465827941895\n",
      "Predicted: [125, 110] Actual: 100 False  5.850113391876221\n",
      "Predicted: [110, 125] Actual: 101 False  5.722610950469971\n",
      "Predicted: [125, 110] Actual: 102 False  6.041189670562744\n",
      "Predicted: [110, 125] Actual: 103 False  5.6652116775512695\n",
      "Predicted: [110, 125] Actual: 104 False  5.815544605255127\n",
      "Predicted: [125, 110] Actual: 105 False  5.991703510284424\n",
      "Predicted: [110, 125] Actual: 106 False  5.621997833251953\n",
      "Predicted: [125, 110] Actual: 107 False  5.8111090660095215\n",
      "Predicted: [110, 125] Actual: 108 False  5.542513847351074\n",
      "Predicted: [110, 125] Actual: 109 False  5.654228210449219\n",
      "Predicted: [110, 82] Actual: 110 True   6.32942533493042\n",
      "Predicted: [110, 125] Actual: 111 False  5.665811538696289\n",
      "Predicted: [125, 110] Actual: 112 False  6.082637786865234\n",
      "Predicted: [125, 110] Actual: 113 False  5.701097011566162\n",
      "Predicted: [125, 110] Actual: 114 False  5.848459243774414\n",
      "Predicted: [110, 125] Actual: 115 False  5.629781723022461\n",
      "Predicted: [125, 110] Actual: 116 False  6.218266487121582\n",
      "Predicted: [110, 125] Actual: 117 False  5.619985103607178\n",
      "Predicted: [110, 125] Actual: 118 False  5.653095245361328\n",
      "Predicted: [110, 125] Actual: 119 False  5.763922214508057\n",
      "Predicted: [125, 110] Actual: 120 False  5.85186243057251\n",
      "Predicted: [125, 110] Actual: 121 False  6.005181312561035\n",
      "Predicted: [110, 125] Actual: 122 False  5.588015556335449\n",
      "Predicted: [125, 110] Actual: 123 False  5.797854423522949\n",
      "Predicted: [125, 110] Actual: 124 False  5.921295166015625\n",
      "Predicted: [125]   Actual: 125 True   26.070966720581055\n",
      "Predicted: [110, 125] Actual: 126 False  5.603357791900635\n",
      "Predicted: [110, 125] Actual: 127 False  5.7193450927734375\n",
      "Predicted: [125, 110] Actual: 128 False  5.79216194152832\n",
      "Predicted: [125, 110] Actual: 129 False  5.936710357666016\n",
      "Predicted: [110, 125] Actual: 130 False  5.753655433654785\n",
      "Predicted: [110, 125] Actual: 131 False  5.653566837310791\n",
      "Predicted: [125, 110] Actual: 132 False  6.029601097106934\n",
      "Predicted: [125, 110] Actual: 133 False  6.087453842163086\n",
      "Predicted: [110, 125] Actual: 134 False  5.675473690032959\n",
      "Predicted: [125, 110] Actual: 135 False  5.830865383148193\n",
      "Predicted: [110, 125] Actual: 136 False  5.847252368927002\n",
      "Predicted: [125, 110] Actual: 137 False  6.555182933807373\n",
      "Predicted: [125, 110] Actual: 138 False  6.487453460693359\n",
      "Predicted: [125, 110] Actual: 139 False  5.91787052154541\n",
      "Predicted: [110, 125] Actual: 140 False  5.809676170349121\n",
      "Predicted: [125, 110] Actual: 141 False  6.271327018737793\n",
      "Predicted: [110, 125] Actual: 142 False  5.578937530517578\n",
      "Predicted: [110, 125] Actual: 143 False  5.667577266693115\n",
      "Predicted: [125, 110] Actual: 144 False  5.66257905960083\n",
      "Predicted: [110, 125] Actual: 145 False  5.687282562255859\n",
      "Predicted: [125, 110] Actual: 146 False  6.508932113647461\n",
      "Predicted: [125, 110] Actual: 147 False  6.331065654754639\n",
      "Predicted: [110, 125] Actual: 148 False  5.687930583953857\n",
      "Predicted: [125, 110] Actual: 149 False  5.868776321411133\n",
      "Predicted: [125, 110] Actual: 150 False  5.916861057281494\n",
      "Predicted: [110, 125] Actual: 151 False  5.7626237869262695\n",
      "Predicted: [125, 110] Actual: 152 False  6.255341529846191\n",
      "Predicted: [125, 110] Actual: 153 False  5.954320430755615\n",
      "Predicted: [110, 125] Actual: 154 False  5.692070007324219\n",
      "Predicted: [125, 110] Actual: 155 False  5.862648963928223\n",
      "Predicted: [110, 125] Actual: 156 False  5.770429611206055\n",
      "Predicted: [110, 125] Actual: 157 False  5.652352333068848\n",
      "Predicted: [110, 125] Actual: 158 False  5.673761367797852\n",
      "Predicted: [110, 125] Actual: 159 False  5.721179008483887\n",
      "Predicted: [125, 110] Actual: 160 False  5.934144973754883\n",
      "Predicted: [125, 110] Actual: 161 False  5.994361877441406\n",
      "Predicted: [125, 110] Actual: 162 False  6.02546501159668\n",
      "Predicted: [125, 110] Actual: 163 False  6.0458550453186035\n",
      "Predicted: [110, 125] Actual: 164 False  5.7175798416137695\n",
      "Predicted: [125, 110] Actual: 165 False  6.147867202758789\n",
      "Predicted: [125, 110] Actual: 166 False  5.979484558105469\n",
      "Predicted: [125, 110] Actual: 167 False  6.030572891235352\n",
      "Predicted: [125, 110] Actual: 168 False  6.648879051208496\n",
      "Predicted: [125, 110] Actual: 169 False  5.738527774810791\n",
      "Predicted: [110, 125] Actual: 170 False  5.729903221130371\n",
      "Predicted: [110, 125] Actual: 171 False  5.576560974121094\n",
      "Predicted: [110, 125] Actual: 172 False  5.80759334564209\n",
      "Predicted: [110, 125] Actual: 173 False  5.665526866912842\n",
      "Predicted: [110, 125] Actual: 174 False  5.695488929748535\n",
      "Predicted: [110, 125] Actual: 175 False  5.761872291564941\n",
      "Predicted: [125, 110] Actual: 176 False  5.838881492614746\n",
      "Predicted: [125, 110] Actual: 177 False  5.588935375213623\n",
      "Predicted: [110, 125] Actual: 178 False  5.67667293548584\n",
      "Predicted: [125, 110] Actual: 179 False  6.092108249664307\n",
      "Predicted: [125, 110] Actual: 180 False  6.067840576171875\n",
      "Predicted: [110, 125] Actual: 181 False  5.664039611816406\n",
      "Predicted: [125, 110] Actual: 182 False  5.676589488983154\n",
      "Predicted: [125, 110] Actual: 183 False  5.881163597106934\n",
      "Predicted: [110, 125] Actual: 184 False  5.597634792327881\n",
      "Predicted: [125, 110] Actual: 185 False  5.750296592712402\n",
      "Predicted: [125, 110] Actual: 186 False  6.1924920082092285\n",
      "Predicted: [125, 110] Actual: 187 False  6.220852851867676\n",
      "Predicted: [125, 110] Actual: 188 False  6.219231605529785\n",
      "Predicted: [110, 125] Actual: 189 False  5.661456108093262\n",
      "Predicted: [125, 110] Actual: 190 False  6.437658309936523\n",
      "Predicted: [125, 110] Actual: 191 False  6.364101409912109\n",
      "Predicted: [110, 125] Actual: 192 False  5.614662170410156\n",
      "Predicted: [125, 110] Actual: 193 False  6.148819446563721\n",
      "Predicted: [110, 125] Actual: 194 False  5.638288497924805\n",
      "Predicted: [110, 125] Actual: 195 False  5.747249603271484\n",
      "Predicted: [125, 110] Actual: 196 False  6.240009307861328\n",
      "Predicted: [125, 110] Actual: 197 False  6.409265518188477\n",
      "Predicted: [125, 110] Actual: 198 False  6.127628326416016\n",
      "Predicted: [125, 110] Actual: 199 False  6.037786483764648\n",
      "Predicted: [110, 125] Actual: 200 False  5.562371730804443\n",
      "Predicted: [125, 110] Actual: 201 False  5.885354042053223\n",
      "Predicted: [110, 125] Actual: 202 False  5.756091594696045\n",
      "Predicted: [110, 125] Actual: 203 False  5.730658054351807\n",
      "Predicted: [125, 110] Actual: 204 False  5.8105974197387695\n",
      "Predicted: [125, 110] Actual: 205 False  5.7794365882873535\n",
      "Predicted: [125, 110] Actual: 206 False  6.09678840637207\n",
      "Predicted: [125, 110] Actual: 207 False  5.889703273773193\n",
      "Predicted: [125, 110] Actual: 208 False  6.211404800415039\n",
      "Predicted: [125, 110] Actual: 209 False  5.775176048278809\n",
      "Predicted: [125, 110] Actual: 210 False  6.004045009613037\n",
      "Predicted: [125, 110] Actual: 211 False  5.757486820220947\n",
      "Predicted: [125, 110] Actual: 212 False  5.951705455780029\n",
      "Predicted: [125, 110] Actual: 213 False  5.887989044189453\n",
      "Predicted: [125, 110] Actual: 214 False  5.849076271057129\n",
      "Predicted: [110, 125] Actual: 215 False  5.658071517944336\n",
      "Predicted: [125, 110] Actual: 216 False  5.880581378936768\n",
      "Predicted: [125, 110] Actual: 217 False  6.247204303741455\n",
      "Predicted: [125, 110] Actual: 218 False  5.901800632476807\n",
      "Predicted: [125, 110] Actual: 219 False  5.820420742034912\n",
      "Predicted: [125, 110] Actual: 220 False  5.871971130371094\n",
      "Predicted: [125, 110] Actual: 221 False  5.970142364501953\n",
      "Predicted: [125, 110] Actual: 222 False  5.635833263397217\n",
      "Predicted: [110, 125] Actual: 223 False  5.810557842254639\n",
      "Predicted: [125, 110] Actual: 224 False  5.959755897521973\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "21132\n",
      "14089\n",
      "35221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.347035  [   64/21132]\n",
      "loss: 3.278462  [ 6464/21132]\n",
      "loss: 3.249230  [12864/21132]\n",
      "loss: 3.145901  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3591  size: 14089  main correct/size: 0.25487969337781247\n",
      "Also correct: 3219  size: 14089  also correct/size: 0.22847611611895804\n",
      "Test Error: Accuracy: 48.3%, Avg loss: 3.292467\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.317091  [   64/21132]\n",
      "loss: 3.259085  [ 6464/21132]\n",
      "loss: 3.224285  [12864/21132]\n",
      "loss: 3.123997  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3654  size: 14089  main correct/size: 0.25935126694584426\n",
      "Also correct: 3156  size: 14089  also correct/size: 0.22400454255092625\n",
      "Test Error: Accuracy: 48.3%, Avg loss: 3.271301\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.296100  [   64/21132]\n",
      "loss: 3.241120  [ 6464/21132]\n",
      "loss: 3.200195  [12864/21132]\n",
      "loss: 3.101844  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3879  size: 14089  main correct/size: 0.27532117254595784\n",
      "Also correct: 2931  size: 14089  also correct/size: 0.2080346369508127\n",
      "Test Error: Accuracy: 48.3%, Avg loss: 3.250920\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.275524  [   64/21132]\n",
      "loss: 3.224043  [ 6464/21132]\n",
      "loss: 3.177591  [12864/21132]\n",
      "loss: 3.080662  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3886  size: 14089  main correct/size: 0.2758180140535169\n",
      "Also correct: 2928  size: 14089  also correct/size: 0.20782170487614451\n",
      "Test Error: Accuracy: 48.4%, Avg loss: 3.232124\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "21132\n",
      "Training model\n",
      "loss: 3.256033  [   64/21132]\n",
      "loss: 3.208500  [ 6464/21132]\n",
      "loss: 3.157113  [12864/21132]\n",
      "loss: 3.061121  [19264/21132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3888  size: 14089  main correct/size: 0.27595996876996237\n",
      "Also correct: 2952  size: 14089  also correct/size: 0.20952516147348996\n",
      "Test Error: Accuracy: 48.5%, Avg loss: 3.215268\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 66] Actual: 0  False  5.512311935424805\n",
      "Predicted: [110, 66] Actual: 1  False  5.546774387359619\n",
      "Predicted: [110, 66] Actual: 2  False  5.602880477905273\n",
      "Predicted: [110, 125] Actual: 3  False  5.485356330871582\n",
      "Predicted: [110, 125] Actual: 4  False  5.539445877075195\n",
      "Predicted: [110, 66] Actual: 5  False  5.4419097900390625\n",
      "Predicted: [110, 125] Actual: 6  False  5.664366722106934\n",
      "Predicted: [110, 125] Actual: 7  False  5.635650634765625\n",
      "Predicted: [110, 125] Actual: 8  False  5.569421768188477\n",
      "Predicted: [110, 125] Actual: 9  False  5.556621551513672\n",
      "Predicted: [110, 66] Actual: 10 False  5.652530670166016\n",
      "Predicted: [110, 66] Actual: 11 False  5.5432820320129395\n",
      "Predicted: [110, 125] Actual: 12 False  5.660091400146484\n",
      "Predicted: [110, 66] Actual: 13 False  5.478174209594727\n",
      "Predicted: [110, 66] Actual: 14 False  5.475590705871582\n",
      "Predicted: [110, 66] Actual: 15 False  5.538219451904297\n",
      "Predicted: [110, 66] Actual: 16 False  5.588839530944824\n",
      "Predicted: [110, 66] Actual: 17 False  5.504123210906982\n",
      "Predicted: [110, 125] Actual: 18 False  5.459657669067383\n",
      "Predicted: [110, 125] Actual: 19 False  5.586312294006348\n",
      "Predicted: [110, 66] Actual: 20 False  5.582091331481934\n",
      "Predicted: [110, 125] Actual: 21 False  5.5657429695129395\n",
      "Predicted: [125, 110] Actual: 22 False  5.884060859680176\n",
      "Predicted: [110, 125] Actual: 23 False  5.5558037757873535\n",
      "Predicted: [125, 110] Actual: 24 False  5.53827428817749\n",
      "Predicted: [110, 66] Actual: 25 False  5.582500457763672\n",
      "Predicted: [110, 66] Actual: 26 False  5.514914512634277\n",
      "Predicted: [110, 66] Actual: 27 False  5.50643253326416\n",
      "Predicted: [110, 66] Actual: 28 False  5.642566680908203\n",
      "Predicted: [110, 125] Actual: 29 False  5.557636260986328\n",
      "Predicted: [110, 125] Actual: 30 False  5.51486873626709\n",
      "Predicted: [110, 125] Actual: 31 False  5.536710262298584\n",
      "Predicted: [110, 66] Actual: 32 False  5.516550064086914\n",
      "Predicted: [110, 66] Actual: 33 False  5.648066520690918\n",
      "Predicted: [110, 66] Actual: 34 False  5.560729026794434\n",
      "Predicted: [110, 66] Actual: 35 False  5.50853157043457\n",
      "Predicted: [110, 66] Actual: 36 False  5.5669755935668945\n",
      "Predicted: [110, 125] Actual: 37 False  5.562778949737549\n",
      "Predicted: [110, 66] Actual: 38 False  5.615365028381348\n",
      "Predicted: [110, 66] Actual: 39 False  5.5754289627075195\n",
      "Predicted: [110, 66] Actual: 40 False  5.558077812194824\n",
      "Predicted: [110, 125] Actual: 41 False  5.630476951599121\n",
      "Predicted: [110, 66] Actual: 42 False  5.554891109466553\n",
      "Predicted: [125, 110] Actual: 43 False  5.668957233428955\n",
      "Predicted: [110, 66] Actual: 44 False  5.551990509033203\n",
      "Predicted: [110, 125] Actual: 45 False  5.562835693359375\n",
      "Predicted: [125, 110] Actual: 46 False  5.670854568481445\n",
      "Predicted: [110, 66] Actual: 47 False  5.532811641693115\n",
      "Predicted: [110, 125] Actual: 48 False  5.531373023986816\n",
      "Predicted: [110, 125] Actual: 49 False  5.641573905944824\n",
      "Predicted: [110, 125] Actual: 50 False  5.6035542488098145\n",
      "Predicted: [110, 66] Actual: 51 False  5.559856414794922\n",
      "Predicted: [110, 66] Actual: 52 False  5.563335418701172\n",
      "Predicted: [110, 66] Actual: 53 False  5.551491737365723\n",
      "Predicted: [125, 110] Actual: 54 False  5.870684623718262\n",
      "Predicted: [110, 66] Actual: 55 False  5.496289253234863\n",
      "Predicted: [110, 125] Actual: 56 False  5.490712642669678\n",
      "Predicted: [110, 125] Actual: 57 False  5.506712436676025\n",
      "Predicted: [125, 110] Actual: 58 False  5.672241687774658\n",
      "Predicted: [110, 125] Actual: 59 False  5.44159460067749\n",
      "Predicted: [110, 125] Actual: 60 False  5.457818031311035\n",
      "Predicted: [110, 66] Actual: 61 False  5.5931010246276855\n",
      "Predicted: [110, 66] Actual: 62 False  5.538061141967773\n",
      "Predicted: [125, 110] Actual: 63 False  5.579326152801514\n",
      "Predicted: [110, 66] Actual: 64 False  5.510008811950684\n",
      "Predicted: [110, 66] Actual: 65 False  5.657949924468994\n",
      "Predicted: [110, 66] Actual: 66 True   5.585413932800293\n",
      "Predicted: [110, 66] Actual: 67 False  5.724674701690674\n",
      "Predicted: [110, 66] Actual: 68 False  5.600437164306641\n",
      "Predicted: [110, 66] Actual: 69 False  5.510080814361572\n",
      "Predicted: [110, 125] Actual: 70 False  5.6057329177856445\n",
      "Predicted: [125, 110] Actual: 71 False  5.655510425567627\n",
      "Predicted: [110, 66] Actual: 72 False  5.535379886627197\n",
      "Predicted: [110, 66] Actual: 73 False  5.596245288848877\n",
      "Predicted: [110, 66] Actual: 74 False  5.532539367675781\n",
      "Predicted: [110, 66] Actual: 75 False  5.528069496154785\n",
      "Predicted: [110, 125] Actual: 76 False  5.513355731964111\n",
      "Predicted: [110, 66] Actual: 77 False  5.382205963134766\n",
      "Predicted: [110, 66] Actual: 78 False  5.542995452880859\n",
      "Predicted: [110, 66] Actual: 79 False  5.596880912780762\n",
      "Predicted: [110, 66] Actual: 80 False  5.644347190856934\n",
      "Predicted: [110, 66] Actual: 81 False  5.613665580749512\n",
      "Predicted: [110, 66] Actual: 82 False  5.646703720092773\n",
      "Predicted: [110, 66] Actual: 83 False  5.595770359039307\n",
      "Predicted: [110, 66] Actual: 84 False  5.4878692626953125\n",
      "Predicted: [110, 66] Actual: 85 False  5.455806732177734\n",
      "Predicted: [110, 66] Actual: 86 False  5.5624871253967285\n",
      "Predicted: [110, 66] Actual: 87 False  5.598960876464844\n",
      "Predicted: [110, 66] Actual: 88 False  5.464210033416748\n",
      "Predicted: [110, 125] Actual: 89 False  5.552488327026367\n",
      "Predicted: [110, 125] Actual: 90 False  5.502824783325195\n",
      "Predicted: [110, 125] Actual: 91 False  5.506705284118652\n",
      "Predicted: [110, 66] Actual: 92 False  5.5009260177612305\n",
      "Predicted: [110, 66] Actual: 93 False  5.610706329345703\n",
      "Predicted: [110, 66] Actual: 94 False  5.422189712524414\n",
      "Predicted: [110, 66] Actual: 95 False  5.646327018737793\n",
      "Predicted: [110, 66] Actual: 96 False  5.742314338684082\n",
      "Predicted: [110, 66] Actual: 97 False  5.424139499664307\n",
      "Predicted: [110, 66] Actual: 98 False  5.525670528411865\n",
      "Predicted: [110, 66] Actual: 99 False  5.474174499511719\n",
      "Predicted: [110, 66] Actual: 100 False  5.678713798522949\n",
      "Predicted: [110, 66] Actual: 101 False  5.597685813903809\n",
      "Predicted: [110, 125] Actual: 102 False  5.525592803955078\n",
      "Predicted: [110, 66] Actual: 103 False  5.528675079345703\n",
      "Predicted: [110, 66] Actual: 104 False  5.66545295715332\n",
      "Predicted: [110, 125] Actual: 105 False  5.500262260437012\n",
      "Predicted: [110, 66] Actual: 106 False  5.483460903167725\n",
      "Predicted: [110, 66] Actual: 107 False  5.609507083892822\n",
      "Predicted: [110, 66] Actual: 108 False  5.411489009857178\n",
      "Predicted: [110, 66] Actual: 109 False  5.517258644104004\n",
      "Predicted: [110, 66] Actual: 110 True   6.254400253295898\n",
      "Predicted: [110, 66] Actual: 111 False  5.525134086608887\n",
      "Predicted: [110, 125] Actual: 112 False  5.585591793060303\n",
      "Predicted: [110, 66] Actual: 113 False  5.533284664154053\n",
      "Predicted: [110, 66] Actual: 114 False  5.523651599884033\n",
      "Predicted: [110, 66] Actual: 115 False  5.490731239318848\n",
      "Predicted: [110, 125] Actual: 116 False  5.576600074768066\n",
      "Predicted: [110, 66] Actual: 117 False  5.477627277374268\n",
      "Predicted: [110, 66] Actual: 118 False  5.5084733963012695\n",
      "Predicted: [110, 66] Actual: 119 False  5.621232032775879\n",
      "Predicted: [110, 66] Actual: 120 False  5.6244964599609375\n",
      "Predicted: [110, 125] Actual: 121 False  5.5486369132995605\n",
      "Predicted: [110, 66] Actual: 122 False  5.464214324951172\n",
      "Predicted: [110, 66] Actual: 123 False  5.55185079574585\n",
      "Predicted: [110, 125] Actual: 124 False  5.5034942626953125\n",
      "Predicted: [125]   Actual: 125 True   42.44108581542969\n",
      "Predicted: [110, 66] Actual: 126 False  5.482995986938477\n",
      "Predicted: [110, 66] Actual: 127 False  5.576312065124512\n",
      "Predicted: [110, 66] Actual: 128 False  5.594930648803711\n",
      "Predicted: [110, 66] Actual: 129 False  5.622818946838379\n",
      "Predicted: [110, 66] Actual: 130 False  5.615977764129639\n",
      "Predicted: [110, 66] Actual: 131 False  5.507842063903809\n",
      "Predicted: [110, 125] Actual: 132 False  5.483245849609375\n",
      "Predicted: [110, 125] Actual: 133 False  5.5379533767700195\n",
      "Predicted: [110, 66] Actual: 134 False  5.5368571281433105\n",
      "Predicted: [110, 66] Actual: 135 False  5.5381364822387695\n",
      "Predicted: [110, 66] Actual: 136 False  5.695313453674316\n",
      "Predicted: [125, 110] Actual: 137 False  6.146002292633057\n",
      "Predicted: [125, 110] Actual: 138 False  5.971770763397217\n",
      "Predicted: [110, 125] Actual: 139 False  5.470095634460449\n",
      "Predicted: [110, 66] Actual: 140 False  5.680103302001953\n",
      "Predicted: [110, 125] Actual: 141 False  5.652100563049316\n",
      "Predicted: [110, 66] Actual: 142 False  5.4419050216674805\n",
      "Predicted: [110, 66] Actual: 143 False  5.524577617645264\n",
      "Predicted: [110, 66] Actual: 144 False  5.485311031341553\n",
      "Predicted: [110, 66] Actual: 145 False  5.549966335296631\n",
      "Predicted: [125, 110] Actual: 146 False  5.958752155303955\n",
      "Predicted: [110, 125] Actual: 147 False  5.668401718139648\n",
      "Predicted: [110, 66] Actual: 148 False  5.571450710296631\n",
      "Predicted: [110, 125] Actual: 149 False  5.549511432647705\n",
      "Predicted: [110, 125] Actual: 150 False  5.539111137390137\n",
      "Predicted: [110, 66] Actual: 151 False  5.629449367523193\n",
      "Predicted: [110, 125] Actual: 152 False  5.638132095336914\n",
      "Predicted: [110, 125] Actual: 153 False  5.605006694793701\n",
      "Predicted: [110, 66] Actual: 154 False  5.548455238342285\n",
      "Predicted: [110, 125] Actual: 155 False  5.488595485687256\n",
      "Predicted: [110, 66] Actual: 156 False  5.640311241149902\n",
      "Predicted: [110, 66] Actual: 157 False  5.51439094543457\n",
      "Predicted: [110, 66] Actual: 158 False  5.548620700836182\n",
      "Predicted: [110, 66] Actual: 159 False  5.581003189086914\n",
      "Predicted: [110, 125] Actual: 160 False  5.49125337600708\n",
      "Predicted: [110, 125] Actual: 161 False  5.568717956542969\n",
      "Predicted: [110, 125] Actual: 162 False  5.481247901916504\n",
      "Predicted: [110, 125] Actual: 163 False  5.5274457931518555\n",
      "Predicted: [110, 66] Actual: 164 False  5.574224948883057\n",
      "Predicted: [110, 125] Actual: 165 False  5.554338455200195\n",
      "Predicted: [110, 125] Actual: 166 False  5.5131330490112305\n",
      "Predicted: [110, 125] Actual: 167 False  5.5303120613098145\n",
      "Predicted: [125, 110] Actual: 168 False  6.241436004638672\n",
      "Predicted: [110, 66] Actual: 169 False  5.5503387451171875\n",
      "Predicted: [110, 66] Actual: 170 False  5.58720588684082\n",
      "Predicted: [110, 66] Actual: 171 False  5.445917129516602\n",
      "Predicted: [110, 66] Actual: 172 False  5.667966842651367\n",
      "Predicted: [110, 66] Actual: 173 False  5.522366523742676\n",
      "Predicted: [110, 66] Actual: 174 False  5.555781841278076\n",
      "Predicted: [110, 66] Actual: 175 False  5.618655204772949\n",
      "Predicted: [110, 66] Actual: 176 False  5.597983360290527\n",
      "Predicted: [110, 66] Actual: 177 False  5.411031246185303\n",
      "Predicted: [110, 66] Actual: 178 False  5.541152477264404\n",
      "Predicted: [110, 125] Actual: 179 False  5.628852844238281\n",
      "Predicted: [110, 125] Actual: 180 False  5.550649642944336\n",
      "Predicted: [110, 66] Actual: 181 False  5.526172637939453\n",
      "Predicted: [110, 66] Actual: 182 False  5.4804301261901855\n",
      "Predicted: [110, 125] Actual: 183 False  5.414523124694824\n",
      "Predicted: [110, 66] Actual: 184 False  5.47065544128418\n",
      "Predicted: [110, 66] Actual: 185 False  5.444228172302246\n",
      "Predicted: [110, 125] Actual: 186 False  5.6209492683410645\n",
      "Predicted: [110, 125] Actual: 187 False  5.549214839935303\n",
      "Predicted: [110, 125] Actual: 188 False  5.631357192993164\n",
      "Predicted: [110, 66] Actual: 189 False  5.524830341339111\n",
      "Predicted: [125, 110] Actual: 190 False  5.962771892547607\n",
      "Predicted: [125, 110] Actual: 191 False  5.791485786437988\n",
      "Predicted: [110, 66] Actual: 192 False  5.4906511306762695\n",
      "Predicted: [125, 110] Actual: 193 False  5.5389838218688965\n",
      "Predicted: [110, 66] Actual: 194 False  5.507001876831055\n",
      "Predicted: [110, 66] Actual: 195 False  5.601381301879883\n",
      "Predicted: [125, 110] Actual: 196 False  5.613839626312256\n",
      "Predicted: [125, 110] Actual: 197 False  5.920839309692383\n",
      "Predicted: [110, 125] Actual: 198 False  5.593192100524902\n",
      "Predicted: [110, 125] Actual: 199 False  5.552978515625\n",
      "Predicted: [110, 66] Actual: 200 False  5.422011375427246\n",
      "Predicted: [110, 66] Actual: 201 False  5.567411422729492\n",
      "Predicted: [110, 66] Actual: 202 False  5.620028972625732\n",
      "Predicted: [110, 66] Actual: 203 False  5.6151347160339355\n",
      "Predicted: [110, 66] Actual: 204 False  5.571390151977539\n",
      "Predicted: [110, 66] Actual: 205 False  5.537862777709961\n",
      "Predicted: [125, 110] Actual: 206 False  5.408080577850342\n",
      "Predicted: [110, 66] Actual: 207 False  5.60166072845459\n",
      "Predicted: [125, 110] Actual: 208 False  5.569331645965576\n",
      "Predicted: [110, 66] Actual: 209 False  5.596159934997559\n",
      "Predicted: [110, 125] Actual: 210 False  5.5604729652404785\n",
      "Predicted: [110, 66] Actual: 211 False  5.510256767272949\n",
      "Predicted: [110, 125] Actual: 212 False  5.5530900955200195\n",
      "Predicted: [110, 125] Actual: 213 False  5.459051609039307\n",
      "Predicted: [110, 66] Actual: 214 False  5.555617809295654\n",
      "Predicted: [110, 66] Actual: 215 False  5.516855239868164\n",
      "Predicted: [110, 125] Actual: 216 False  5.546324729919434\n",
      "Predicted: [125, 110] Actual: 217 False  5.619387149810791\n",
      "Predicted: [110, 66] Actual: 218 False  5.555521488189697\n",
      "Predicted: [110, 66] Actual: 219 False  5.554502010345459\n",
      "Predicted: [110, 66] Actual: 220 False  5.5568928718566895\n",
      "Predicted: [110, 125] Actual: 221 False  5.477689743041992\n",
      "Predicted: [110, 66] Actual: 222 False  5.48740291595459\n",
      "Predicted: [110, 66] Actual: 223 False  5.6816511154174805\n",
      "Predicted: [110, 125] Actual: 224 False  5.538590431213379\n",
      "Edge correct: 3    Size: 225  Edge correct/Size: 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "grid_size = 15\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "chunk_amount = 35222\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "with open('output3.txt', 'a') as f:\n",
    "    for size in range(5, 10):\n",
    "        #grid_size = size\n",
    "        print(f'Grid size: {grid_size}')\n",
    "        f.write(f'Grid size: {grid_size}\\n')\n",
    "        f.write(f'Correct Tolerance {int(max(1, np.floor(grid_size/2)))}\\n')\n",
    "        f.write(f'Chunk Amount: {chunk_amount}\\n')\n",
    "        f.write('------------------------------------------\\n')\n",
    "        class AccidentDataset(Dataset):\n",
    "            def __init__(self, transform=None):\n",
    "                self.coordinates = data\n",
    "                self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "                \n",
    "                #split into 500 chunks using numpy\n",
    "                self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "                #process each chunk and merge it back into one dataframe\n",
    "                self.grids = []\n",
    "                grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "                grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "                grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "                grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "                for i in range(len(self.coordinates)-1):\n",
    "                    grid = np.zeros((grid_size, grid_size))\n",
    "                    for index, row in self.coordinates[i].iterrows():\n",
    "                        coordinates = row['latitude'], row['longitude']\n",
    "                        for j in range(grid_size):\n",
    "                            for k in range(grid_size):\n",
    "                                lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                                lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                                long_lower = grid_lower_long + k * grid_long_step\n",
    "                                long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                                if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                                    grid[j][k] += 1\n",
    "                                    break\n",
    "                    self.grids.append(grid/chunk_size)\n",
    "                self.grids = np.array(self.grids)\n",
    "                self.transform = transform      \n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.grids)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                if torch.is_tensor(idx):\n",
    "                    idx = idx.tolist()\n",
    "\n",
    "                grid = self.grids[idx]\n",
    "                grid = torch.from_numpy(grid).float()\n",
    "\n",
    "                max_index = np.argmax(grid)\n",
    "                max_index = np.array(max_index)\n",
    "                return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "        accident_dataset = AccidentDataset()\n",
    "\n",
    "        #Create new array with 60% of the data\n",
    "        train_size = int(0.6 * len(accident_dataset))\n",
    "        test_size = len(accident_dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "        print(len(train_dataset))\n",
    "        print(len(test_dataset))\n",
    "        print(len(accident_dataset))\n",
    "\n",
    "        #Create dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        class Network(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                #x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        # building the model object\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        #device = torch.device('cpu')\n",
    "        print(f'Using {device} device')\n",
    "\n",
    "        model = Network().to(device)\n",
    "        if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "            model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "            print(f\"Loaded model from model{grid_size}.pth\")\n",
    "        else:\n",
    "            print(\"No model found, creating new model\")\n",
    "\n",
    "        # define the loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "        # define the training loop\n",
    "        def train(dataloader, model, loss_fn, optimizer):\n",
    "            size = len(dataloader.dataset)\n",
    "            print(size)\n",
    "            model.train()\n",
    "            print(\"Training model\")\n",
    "            for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                #print('pred ', pred)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"Finished training model\")\n",
    "\n",
    "        def test(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "            print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "        def logtest(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            f.write(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\\n\")\n",
    "            f.write(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\\n\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            f.write(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "        \n",
    "        epochs = 5\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        logtest(test_dataloader, model, loss_fn)\n",
    "        torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "        print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "        model.eval()\n",
    "        edge_correct = 0\n",
    "        f.write('------------------------------------------\\nEdge cases:\\n')\n",
    "        print('------------------------------------------\\nEdge cases:')\n",
    "        for i in range (grid_size ** 2):\n",
    "            randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "            edge = np.zeros(grid_size ** 2)\n",
    "            edge[i] = 1\n",
    "            x, y = torch.tensor(edge).float(), i\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model(x.to(device))\n",
    "                #print(pred)\n",
    "                predicted, actual = pred.topk(grid_size), y\n",
    "                max_value = pred.max(0)[0]\n",
    "                index = []\n",
    "                for j in range(len(predicted)):\n",
    "                    if predicted.values[j].item() >= 0.8 * max_value:\n",
    "                        index.append(predicted.indices[j].item())\n",
    "                part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "                part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "                part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "                part4 = f'{max_value}'.ljust(10, ' ')\n",
    "                print(part1, part2, part3, part4)\n",
    "                f.write(part1 + part2 + part3 + part4 + '\\n')\n",
    "                #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "                edge_correct += actual in index\n",
    "        f.write('------------------------------------------\\n')\n",
    "        edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "        edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "        edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "        print(edgestr1, edgestr2, edgestr3)\n",
    "        f.write(edgestr1 + edgestr2 + edgestr3 + '\\n')\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
