{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9892de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450620000.0, '40.6720753', '-73.9113364']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "grid_size = 5\n",
    "chunk_amount = 85555\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.coordinates = data\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        \n",
    "        #split into 500 chunks using numpy\n",
    "        self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "        #process each chunk and merge it back into one dataframe\n",
    "        self.grids = []\n",
    "        grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "        grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "        grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "        grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "        for i in range(len(self.coordinates)-1):\n",
    "            grid = np.zeros((grid_size, grid_size))\n",
    "            for index, row in self.coordinates[i].iterrows():\n",
    "                coordinates = row['latitude'], row['longitude']\n",
    "                for j in range(grid_size):\n",
    "                    for k in range(grid_size):\n",
    "                        lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                        lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                        long_lower = grid_lower_long + k * grid_long_step\n",
    "                        long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                        if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                            grid[j][k] += 1\n",
    "                            break\n",
    "            self.grids.append(grid/chunk_size)\n",
    "        self.grids = np.array(self.grids)\n",
    "        self.transform = transform      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        grid = self.grids[idx]\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "\n",
    "        max_index = np.argmax(grid)\n",
    "        max_index = np.array(max_index)\n",
    "        return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "accident_dataset = AccidentDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f366a4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accident_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55240\\1389412538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create new array with 60% of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accident_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.6 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# define the class for multilinear regression\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(grid_size ** 2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, grid_size ** 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# define the class for multilinear regression\n",
    "# building the model object\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network().to(device)\n",
    "if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "    model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "    print(f\"Loaded model from model{grid_size}.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# define the training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print('pred ', pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    print(\"Testing model\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, also_correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print('y ', y)\n",
    "            #print('predition', pred.argmax(1))\n",
    "\n",
    "            #check if prediction is correct\n",
    "            predictions = torch.topk(pred, 2, dim=1).indices\n",
    "            #is_correct = (pred.argmax(1) == y or pred.argmax(1) == max_value)\n",
    "\n",
    "            for i in range (len(predictions)):\n",
    "                if y[i] in predictions[i]:\n",
    "                    if y[i] == pred.argmax(1)[i]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        also_correct += 1\n",
    "\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            #print(correct)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "    print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "    correct += also_correct\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "epochs = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "model.eval()\n",
    "edge_correct = 0\n",
    "for i in range (grid_size ** 2):\n",
    "    randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "    #randomnumber = 86903\n",
    "    #print(randomnumber)\n",
    "    #x, y = test_dataset[randomnumber][0], test_dataset[randomnumber][1]\n",
    "    edge = np.zeros(grid_size ** 2)\n",
    "    edge[i] = 1\n",
    "    x, y = torch.tensor(edge).float(), i\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.to(device))\n",
    "        #print(pred)\n",
    "        predicted, actual = pred.topk(grid_size), y\n",
    "        max_value = pred.max(0)[0]\n",
    "        index = []\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted.values[i].item() >= 0.8 * max_value:\n",
    "                index.append(predicted.indices[i].item())\n",
    "        part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "        part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "        part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "        part4 = f'{max_value}'.ljust(10, ' ')\n",
    "        print(part1, part2, part3, part4)\n",
    "        #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "        edge_correct += actual in index\n",
    "print('------------------------------------------')\n",
    "edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "print(edgestr1, edgestr2, edgestr3)\n",
    "#print(f\"Edge correct: {edge_correct}  size: {25}  edge correct/size: {edge_correct/25}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d3e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1629584760.0, '40.6814069', '-73.8235501']\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.706370  [   64/ 8532]\n",
      "loss: 1.585713  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3110  size: 5689  main correct/size: 0.5466690103708912\n",
      "Also correct: 999  size: 5689  also correct/size: 0.17560203902267535\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.995158\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.689611  [   64/ 8532]\n",
      "loss: 1.583544  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3111  size: 5689  main correct/size: 0.5468447881877307\n",
      "Also correct: 998  size: 5689  also correct/size: 0.17542626120583582\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.994996\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.687304  [   64/ 8532]\n",
      "loss: 1.583404  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3112  size: 5689  main correct/size: 0.5470205660045703\n",
      "Also correct: 997  size: 5689  also correct/size: 0.17525048338899632\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.994745\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.685579  [   64/ 8532]\n",
      "loss: 1.583499  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3113  size: 5689  main correct/size: 0.5471963438214097\n",
      "Also correct: 997  size: 5689  also correct/size: 0.17525048338899632\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.994477\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.684469  [   64/ 8532]\n",
      "loss: 1.583619  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3113  size: 5689  main correct/size: 0.5471963438214097\n",
      "Also correct: 997  size: 5689  also correct/size: 0.17525048338899632\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.994205\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  7.703770160675049\n",
      "Predicted: [110, 82] Actual: 1  False  7.777713298797607\n",
      "Predicted: [110, 82] Actual: 2  False  7.815286636352539\n",
      "Predicted: [110, 82] Actual: 3  False  7.313185691833496\n",
      "Predicted: [110, 82] Actual: 4  False  7.460289478302002\n",
      "Predicted: [110, 82] Actual: 5  False  7.403367042541504\n",
      "Predicted: [110, 82] Actual: 6  False  7.779151439666748\n",
      "Predicted: [110, 82] Actual: 7  False  7.719064235687256\n",
      "Predicted: [110, 82] Actual: 8  False  7.511220455169678\n",
      "Predicted: [110, 82] Actual: 9  False  7.4599456787109375\n",
      "Predicted: [110, 82] Actual: 10 False  7.878537654876709\n",
      "Predicted: [110, 82] Actual: 11 False  7.666354656219482\n",
      "Predicted: [110, 82] Actual: 12 False  7.796212673187256\n",
      "Predicted: [110, 82] Actual: 13 False  7.580785274505615\n",
      "Predicted: [110, 82] Actual: 14 False  7.541972637176514\n",
      "Predicted: [110, 82] Actual: 15 False  7.449267387390137\n",
      "Predicted: [110, 82] Actual: 16 False  7.724879741668701\n",
      "Predicted: [110, 82] Actual: 17 False  7.493172645568848\n",
      "Predicted: [110, 82] Actual: 18 False  7.3779072761535645\n",
      "Predicted: [110, 82] Actual: 19 False  7.549872875213623\n",
      "Predicted: [110, 82] Actual: 20 False  7.5732808113098145\n",
      "Predicted: [110, 125] Actual: 21 False  7.527133464813232\n",
      "Predicted: [110, 82] Actual: 22 False  7.436891078948975\n",
      "Predicted: [110, 82] Actual: 23 False  7.6279497146606445\n",
      "Predicted: [110, 125] Actual: 24 False  7.212619304656982\n",
      "Predicted: [125, 110] Actual: 25 False  7.78318977355957\n",
      "Predicted: [110, 82] Actual: 26 False  7.616917133331299\n",
      "Predicted: [110, 82] Actual: 27 False  7.6221089363098145\n",
      "Predicted: [110, 82] Actual: 28 False  7.760135173797607\n",
      "Predicted: [110, 82] Actual: 29 False  7.533385276794434\n",
      "Predicted: [110, 125] Actual: 30 False  7.237475872039795\n",
      "Predicted: [110, 125] Actual: 31 False  7.440570831298828\n",
      "Predicted: [110, 82] Actual: 32 False  7.468627452850342\n",
      "Predicted: [110, 82] Actual: 33 False  7.689358234405518\n",
      "Predicted: [110, 82] Actual: 34 False  7.523322105407715\n",
      "Predicted: [110, 82] Actual: 35 False  7.722291469573975\n",
      "Predicted: [110, 82] Actual: 36 False  8.03004264831543\n",
      "Predicted: [110, 125] Actual: 37 False  7.501480579376221\n",
      "Predicted: [110, 82] Actual: 38 False  7.702775955200195\n",
      "Predicted: [110, 82] Actual: 39 False  7.84128999710083\n",
      "Predicted: [110, 82] Actual: 40 False  7.656094551086426\n",
      "Predicted: [110, 82] Actual: 41 False  7.782355785369873\n",
      "Predicted: [110, 125] Actual: 42 False  7.5709710121154785\n",
      "Predicted: [110, 82] Actual: 43 False  7.593210220336914\n",
      "Predicted: [110, 82] Actual: 44 False  7.738813877105713\n",
      "Predicted: [125, 110] Actual: 45 False  8.35559368133545\n",
      "Predicted: [110, 82] Actual: 46 False  7.551535129547119\n",
      "Predicted: [110, 82] Actual: 47 False  7.502350807189941\n",
      "Predicted: [110, 82] Actual: 48 False  7.559239864349365\n",
      "Predicted: [110, 82] Actual: 49 False  8.042497634887695\n",
      "Predicted: [110, 82] Actual: 50 False  7.82498025894165\n",
      "Predicted: [110, 82] Actual: 51 False  8.005512237548828\n",
      "Predicted: [110, 82] Actual: 52 False  7.51436710357666\n",
      "Predicted: [110, 82] Actual: 53 False  7.713002681732178\n",
      "Predicted: [125, 110] Actual: 54 False  7.741307258605957\n",
      "Predicted: [110, 82] Actual: 55 False  7.400339603424072\n",
      "Predicted: [110, 82] Actual: 56 False  7.308859348297119\n",
      "Predicted: [110, 82] Actual: 57 False  7.473262310028076\n",
      "Predicted: [110, 125] Actual: 58 False  7.336966514587402\n",
      "Predicted: [110, 82] Actual: 59 False  7.364626884460449\n",
      "Predicted: [110, 82] Actual: 60 False  7.365978717803955\n",
      "Predicted: [110, 82] Actual: 61 False  7.773869514465332\n",
      "Predicted: [110, 82] Actual: 62 False  7.513132572174072\n",
      "Predicted: [110, 82] Actual: 63 False  7.418325901031494\n",
      "Predicted: [110, 82] Actual: 64 False  7.377305507659912\n",
      "Predicted: [110, 82] Actual: 65 False  7.660277843475342\n",
      "Predicted: [110]   Actual: 66 False  8.676258087158203\n",
      "Predicted: [110]   Actual: 67 False  8.754900932312012\n",
      "Predicted: [110, 82] Actual: 68 False  7.803988933563232\n",
      "Predicted: [110, 82] Actual: 69 False  7.496234893798828\n",
      "Predicted: [110, 82] Actual: 70 False  7.6780924797058105\n",
      "Predicted: [110, 125] Actual: 71 False  7.608658313751221\n",
      "Predicted: [110, 125] Actual: 72 False  7.386538982391357\n",
      "Predicted: [110, 82] Actual: 73 False  7.726603031158447\n",
      "Predicted: [110, 82] Actual: 74 False  7.792526721954346\n",
      "Predicted: [110, 82] Actual: 75 False  7.768762111663818\n",
      "Predicted: [110, 125] Actual: 76 False  7.3522467613220215\n",
      "Predicted: [110, 82] Actual: 77 False  7.3242034912109375\n",
      "Predicted: [110, 82] Actual: 78 False  7.611029148101807\n",
      "Predicted: [110, 82] Actual: 79 False  7.67781925201416\n",
      "Predicted: [110]   Actual: 80 False  9.11614990234375\n",
      "Predicted: [110]   Actual: 81 False  8.676763534545898\n",
      "Predicted: [110]   Actual: 82 False  9.201522827148438\n",
      "Predicted: [110]   Actual: 83 False  8.533164978027344\n",
      "Predicted: [110, 82] Actual: 84 False  7.604432106018066\n",
      "Predicted: [110, 82] Actual: 85 False  7.180897235870361\n",
      "Predicted: [110, 82] Actual: 86 False  7.3464789390563965\n",
      "Predicted: [110, 82] Actual: 87 False  7.637592792510986\n",
      "Predicted: [110, 82] Actual: 88 False  7.717103004455566\n",
      "Predicted: [110, 82] Actual: 89 False  7.664307117462158\n",
      "Predicted: [110, 82] Actual: 90 False  7.548782825469971\n",
      "Predicted: [110, 82] Actual: 91 False  7.466583728790283\n",
      "Predicted: [110, 82] Actual: 92 False  7.555377006530762\n",
      "Predicted: [110, 82] Actual: 93 False  7.760354995727539\n",
      "Predicted: [125, 110] Actual: 94 False  7.532782554626465\n",
      "Predicted: [110]   Actual: 95 False  8.589777946472168\n",
      "Predicted: [110]   Actual: 96 False  9.177897453308105\n",
      "Predicted: [110, 82] Actual: 97 False  8.034092903137207\n",
      "Predicted: [110, 82] Actual: 98 False  7.670285701751709\n",
      "Predicted: [110, 82] Actual: 99 False  7.434555530548096\n",
      "Predicted: [110, 82] Actual: 100 False  7.777976036071777\n",
      "Predicted: [110]   Actual: 101 False  8.438121795654297\n",
      "Predicted: [110, 82] Actual: 102 False  7.504257678985596\n",
      "Predicted: [110, 82] Actual: 103 False  7.449415683746338\n",
      "Predicted: [110, 82] Actual: 104 False  7.633964538574219\n",
      "Predicted: [110, 82] Actual: 105 False  7.33132791519165\n",
      "Predicted: [110, 82] Actual: 106 False  7.5575642585754395\n",
      "Predicted: [110, 82] Actual: 107 False  7.738254070281982\n",
      "Predicted: [110, 82] Actual: 108 False  7.621458053588867\n",
      "Predicted: [110, 82] Actual: 109 False  7.800341606140137\n",
      "Predicted: [110]   Actual: 110 True   15.323248863220215\n",
      "Predicted: [110, 82] Actual: 111 False  7.675121784210205\n",
      "Predicted: [110, 82] Actual: 112 False  7.615533351898193\n",
      "Predicted: [110, 82] Actual: 113 False  7.545706272125244\n",
      "Predicted: [110, 82] Actual: 114 False  7.561021327972412\n",
      "Predicted: [110, 82] Actual: 115 False  7.468994140625\n",
      "Predicted: [110, 82] Actual: 116 False  7.590591907501221\n",
      "Predicted: [125, 110] Actual: 117 False  7.208371639251709\n",
      "Predicted: [110, 82] Actual: 118 False  7.513970851898193\n",
      "Predicted: [110, 82] Actual: 119 False  7.735411167144775\n",
      "Predicted: [110, 82] Actual: 120 False  7.733767032623291\n",
      "Predicted: [110, 82] Actual: 121 False  7.43334436416626\n",
      "Predicted: [110, 82] Actual: 122 False  7.700189113616943\n",
      "Predicted: [110, 82] Actual: 123 False  7.6713433265686035\n",
      "Predicted: [110, 82] Actual: 124 False  7.483771324157715\n",
      "Predicted: [125]   Actual: 125 True   156.1334686279297\n",
      "Predicted: [110, 82] Actual: 126 False  7.301699161529541\n",
      "Predicted: [110, 82] Actual: 127 False  7.619793891906738\n",
      "Predicted: [110, 82] Actual: 128 False  7.751627445220947\n",
      "Predicted: [110, 82] Actual: 129 False  7.633772850036621\n",
      "Predicted: [110, 125] Actual: 130 False  7.414809226989746\n",
      "Predicted: [110, 82] Actual: 131 False  7.373169422149658\n",
      "Predicted: [110, 82] Actual: 132 False  7.329010486602783\n",
      "Predicted: [110, 125] Actual: 133 False  7.349327087402344\n",
      "Predicted: [110, 82] Actual: 134 False  7.453226566314697\n",
      "Predicted: [110, 82] Actual: 135 False  7.551907062530518\n",
      "Predicted: [110, 82] Actual: 136 False  7.881982326507568\n",
      "Predicted: [125, 110] Actual: 137 False  8.251420974731445\n",
      "Predicted: [125, 110] Actual: 138 False  7.635347366333008\n",
      "Predicted: [110, 82] Actual: 139 False  7.482309341430664\n",
      "Predicted: [110, 82] Actual: 140 False  8.138486862182617\n",
      "Predicted: [110, 82] Actual: 141 False  8.367132186889648\n",
      "Predicted: [110, 82] Actual: 142 False  7.456191062927246\n",
      "Predicted: [110, 82] Actual: 143 False  7.472533702850342\n",
      "Predicted: [110, 125] Actual: 144 False  7.398156642913818\n",
      "Predicted: [110, 82] Actual: 145 False  7.53196382522583\n",
      "Predicted: [110, 125] Actual: 146 False  7.861483097076416\n",
      "Predicted: [110, 125] Actual: 147 False  7.652651309967041\n",
      "Predicted: [110, 82] Actual: 148 False  7.646423816680908\n",
      "Predicted: [110, 125] Actual: 149 False  7.52994441986084\n",
      "Predicted: [110, 82] Actual: 150 False  7.504405498504639\n",
      "Predicted: [110, 82] Actual: 151 False  7.826991558074951\n",
      "Predicted: [110, 125] Actual: 152 False  7.630336284637451\n",
      "Predicted: [110, 82] Actual: 153 False  7.674865245819092\n",
      "Predicted: [110, 82] Actual: 154 False  7.603850364685059\n",
      "Predicted: [110, 125] Actual: 155 False  7.344424247741699\n",
      "Predicted: [110, 82] Actual: 156 False  7.871791362762451\n",
      "Predicted: [110, 82] Actual: 157 False  7.648502349853516\n",
      "Predicted: [110, 82] Actual: 158 False  7.595971584320068\n",
      "Predicted: [110, 82] Actual: 159 False  7.701013565063477\n",
      "Predicted: [110, 82] Actual: 160 False  7.448877811431885\n",
      "Predicted: [125, 110] Actual: 161 False  7.755566120147705\n",
      "Predicted: [110, 82] Actual: 162 False  7.356899738311768\n",
      "Predicted: [110, 82] Actual: 163 False  7.508589267730713\n",
      "Predicted: [110, 82] Actual: 164 False  7.778170108795166\n",
      "Predicted: [110, 82] Actual: 165 False  7.616909980773926\n",
      "Predicted: [110, 82] Actual: 166 False  7.450188159942627\n",
      "Predicted: [110, 82] Actual: 167 False  7.422642230987549\n",
      "Predicted: [125, 110] Actual: 168 False  8.688063621520996\n",
      "Predicted: [110, 82] Actual: 169 False  7.551214218139648\n",
      "Predicted: [110, 82] Actual: 170 False  7.846264839172363\n",
      "Predicted: [110, 82] Actual: 171 False  7.311450481414795\n",
      "Predicted: [110, 82] Actual: 172 False  7.825192451477051\n",
      "Predicted: [110, 82] Actual: 173 False  7.388567924499512\n",
      "Predicted: [110, 82] Actual: 174 False  7.637176990509033\n",
      "Predicted: [110, 125] Actual: 175 False  7.6495256423950195\n",
      "Predicted: [110, 82] Actual: 176 False  7.616470813751221\n",
      "Predicted: [110, 82] Actual: 177 False  7.434068202972412\n",
      "Predicted: [110, 82] Actual: 178 False  7.787655353546143\n",
      "Predicted: [110, 82] Actual: 179 False  7.646738529205322\n",
      "Predicted: [110, 82] Actual: 180 False  7.457033634185791\n",
      "Predicted: [110, 82] Actual: 181 False  7.64085054397583\n",
      "Predicted: [110, 82] Actual: 182 False  7.49179220199585\n",
      "Predicted: [110, 82] Actual: 183 False  7.2271342277526855\n",
      "Predicted: [110, 82] Actual: 184 False  7.773412227630615\n",
      "Predicted: [110, 82] Actual: 185 False  7.4270758628845215\n",
      "Predicted: [110, 82] Actual: 186 False  7.976348876953125\n",
      "Predicted: [110, 82] Actual: 187 False  7.673210620880127\n",
      "Predicted: [110, 82] Actual: 188 False  7.733757495880127\n",
      "Predicted: [110, 82] Actual: 189 False  7.519118785858154\n",
      "Predicted: [110, 82] Actual: 190 False  7.5808329582214355\n",
      "Predicted: [125, 110] Actual: 191 False  7.811954498291016\n",
      "Predicted: [110, 82] Actual: 192 False  7.751655101776123\n",
      "Predicted: [110, 82] Actual: 193 False  7.389343738555908\n",
      "Predicted: [110, 82] Actual: 194 False  7.687578201293945\n",
      "Predicted: [110, 82] Actual: 195 False  7.831617832183838\n",
      "Predicted: [110, 125] Actual: 196 False  7.428495407104492\n",
      "Predicted: [110, 125] Actual: 197 False  7.620894908905029\n",
      "Predicted: [110, 82] Actual: 198 False  7.609103202819824\n",
      "Predicted: [110, 82] Actual: 199 False  7.565102577209473\n",
      "Predicted: [110, 82] Actual: 200 False  7.443721294403076\n",
      "Predicted: [110, 82] Actual: 201 False  7.633320331573486\n",
      "Predicted: [110, 82] Actual: 202 False  7.65536642074585\n",
      "Predicted: [110, 82] Actual: 203 False  7.6879496574401855\n",
      "Predicted: [125, 110] Actual: 204 False  8.966958045959473\n",
      "Predicted: [110, 82] Actual: 205 False  7.527308940887451\n",
      "Predicted: [110, 82] Actual: 206 False  7.317595958709717\n",
      "Predicted: [110, 82] Actual: 207 False  7.710725784301758\n",
      "Predicted: [110, 125] Actual: 208 False  7.451990127563477\n",
      "Predicted: [110, 82] Actual: 209 False  7.722145080566406\n",
      "Predicted: [110, 82] Actual: 210 False  7.614919185638428\n",
      "Predicted: [110, 82] Actual: 211 False  7.583899021148682\n",
      "Predicted: [110, 82] Actual: 212 False  7.493443965911865\n",
      "Predicted: [110, 82] Actual: 213 False  7.399521350860596\n",
      "Predicted: [110, 82] Actual: 214 False  7.573371887207031\n",
      "Predicted: [110, 82] Actual: 215 False  7.590741157531738\n",
      "Predicted: [110, 82] Actual: 216 False  7.529573917388916\n",
      "Predicted: [110, 125] Actual: 217 False  7.519577503204346\n",
      "Predicted: [110, 82] Actual: 218 False  7.6024699211120605\n",
      "Predicted: [110, 82] Actual: 219 False  7.5721845626831055\n",
      "Predicted: [110, 82] Actual: 220 False  7.402105808258057\n",
      "Predicted: [110, 82] Actual: 221 False  7.492158889770508\n",
      "Predicted: [110, 82] Actual: 222 False  7.578465938568115\n",
      "Predicted: [110, 82] Actual: 223 False  8.015656471252441\n",
      "Predicted: [110, 82] Actual: 224 False  7.586350917816162\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.057686  [   64/ 8532]\n",
      "loss: 1.783889  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3038  size: 5689  main correct/size: 0.5340130075584462\n",
      "Also correct: 1110  size: 5689  also correct/size: 0.1951133766918615\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 2.043838\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.217286  [   64/ 8532]\n",
      "loss: 1.783107  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3037  size: 5689  main correct/size: 0.5338372297416066\n",
      "Also correct: 1111  size: 5689  also correct/size: 0.195289154508701\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 2.044367\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.218686  [   64/ 8532]\n",
      "loss: 1.782888  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3038  size: 5689  main correct/size: 0.5340130075584462\n",
      "Also correct: 1109  size: 5689  also correct/size: 0.19493759887502196\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 2.044452\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.218029  [   64/ 8532]\n",
      "loss: 1.782550  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3038  size: 5689  main correct/size: 0.5340130075584462\n",
      "Also correct: 1111  size: 5689  also correct/size: 0.195289154508701\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 2.044373\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.217099  [   64/ 8532]\n",
      "loss: 1.782044  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3036  size: 5689  main correct/size: 0.5336614519247671\n",
      "Also correct: 1114  size: 5689  also correct/size: 0.19581648795921955\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 2.044178\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.608590602874756\n",
      "Predicted: [110, 82] Actual: 1  False  7.99660587310791\n",
      "Predicted: [110, 82] Actual: 2  False  8.045416831970215\n",
      "Predicted: [110, 82] Actual: 3  False  7.517354488372803\n",
      "Predicted: [110, 82] Actual: 4  False  7.661126613616943\n",
      "Predicted: [110, 82] Actual: 5  False  7.610398769378662\n",
      "Predicted: [110, 82] Actual: 6  False  7.993278980255127\n",
      "Predicted: [110, 82] Actual: 7  False  7.928267002105713\n",
      "Predicted: [110, 82] Actual: 8  False  7.714745044708252\n",
      "Predicted: [110, 82] Actual: 9  False  7.661994457244873\n",
      "Predicted: [110, 82] Actual: 10 False  8.09973430633545\n",
      "Predicted: [110, 82] Actual: 11 False  7.894274711608887\n",
      "Predicted: [110, 82] Actual: 12 False  8.010743141174316\n",
      "Predicted: [110, 82] Actual: 13 False  7.8049139976501465\n",
      "Predicted: [110, 82] Actual: 14 False  7.764855861663818\n",
      "Predicted: [110, 82] Actual: 15 False  7.653004169464111\n",
      "Predicted: [110, 82] Actual: 16 False  7.947021007537842\n",
      "Predicted: [110, 82] Actual: 17 False  7.7002410888671875\n",
      "Predicted: [110, 82] Actual: 18 False  7.578500270843506\n",
      "Predicted: [110, 82] Actual: 19 False  7.7583794593811035\n",
      "Predicted: [110, 82] Actual: 20 False  7.799488067626953\n",
      "Predicted: [110, 82] Actual: 21 False  7.758360385894775\n",
      "Predicted: [110, 82] Actual: 22 False  7.626724720001221\n",
      "Predicted: [110, 82] Actual: 23 False  7.831283092498779\n",
      "Predicted: [110, 82] Actual: 24 False  7.412112712860107\n",
      "Predicted: [110, 82] Actual: 25 False  7.622762680053711\n",
      "Predicted: [110, 82] Actual: 26 False  7.835785865783691\n",
      "Predicted: [110, 82] Actual: 27 False  7.83557653427124\n",
      "Predicted: [110, 82] Actual: 28 False  7.97812032699585\n",
      "Predicted: [110, 82] Actual: 29 False  7.74025297164917\n",
      "Predicted: [110, 82] Actual: 30 False  7.447958946228027\n",
      "Predicted: [110, 82] Actual: 31 False  7.651093006134033\n",
      "Predicted: [110, 82] Actual: 32 False  7.700124263763428\n",
      "Predicted: [110, 82] Actual: 33 False  7.898971080780029\n",
      "Predicted: [110, 82] Actual: 34 False  7.739522457122803\n",
      "Predicted: [110, 82] Actual: 35 False  7.9449543952941895\n",
      "Predicted: [110]   Actual: 36 False  8.25533390045166\n",
      "Predicted: [110, 82] Actual: 37 False  7.698666572570801\n",
      "Predicted: [110, 82] Actual: 38 False  7.912901401519775\n",
      "Predicted: [110, 82] Actual: 39 False  8.081327438354492\n",
      "Predicted: [110, 82] Actual: 40 False  7.864812850952148\n",
      "Predicted: [110, 82] Actual: 41 False  7.9986958503723145\n",
      "Predicted: [110, 82] Actual: 42 False  7.772251605987549\n",
      "Predicted: [110, 82] Actual: 43 False  7.7943434715271\n",
      "Predicted: [110, 82] Actual: 44 False  7.967696189880371\n",
      "Predicted: [110, 82] Actual: 45 False  7.585951328277588\n",
      "Predicted: [110, 82] Actual: 46 False  7.76166296005249\n",
      "Predicted: [110, 82] Actual: 47 False  7.705605983734131\n",
      "Predicted: [110, 82] Actual: 48 False  7.773753643035889\n",
      "Predicted: [110, 82] Actual: 49 False  8.258737564086914\n",
      "Predicted: [110, 82] Actual: 50 False  8.037406921386719\n",
      "Predicted: [110]   Actual: 51 False  8.256217956542969\n",
      "Predicted: [110, 82] Actual: 52 False  7.748497009277344\n",
      "Predicted: [110, 82] Actual: 53 False  7.928968906402588\n",
      "Predicted: [110, 82] Actual: 54 False  7.653282642364502\n",
      "Predicted: [110, 82] Actual: 55 False  7.606377124786377\n",
      "Predicted: [110, 82] Actual: 56 False  7.506833553314209\n",
      "Predicted: [110, 82] Actual: 57 False  7.6784348487854\n",
      "Predicted: [110, 82] Actual: 58 False  7.540354251861572\n",
      "Predicted: [110, 82] Actual: 59 False  7.568043231964111\n",
      "Predicted: [110, 82] Actual: 60 False  7.56931734085083\n",
      "Predicted: [110, 82] Actual: 61 False  7.995579242706299\n",
      "Predicted: [110, 82] Actual: 62 False  7.713626861572266\n",
      "Predicted: [110, 82] Actual: 63 False  7.624813556671143\n",
      "Predicted: [110, 82] Actual: 64 False  7.623572826385498\n",
      "Predicted: [110, 82] Actual: 65 False  7.878234386444092\n",
      "Predicted: [110]   Actual: 66 False  8.84274673461914\n",
      "Predicted: [110]   Actual: 67 False  8.94064712524414\n",
      "Predicted: [110, 82] Actual: 68 False  8.07723331451416\n",
      "Predicted: [110, 82] Actual: 69 False  7.721189498901367\n",
      "Predicted: [110, 82] Actual: 70 False  7.887756824493408\n",
      "Predicted: [110, 82] Actual: 71 False  7.819198131561279\n",
      "Predicted: [110, 82] Actual: 72 False  7.590730667114258\n",
      "Predicted: [110, 82] Actual: 73 False  7.935227870941162\n",
      "Predicted: [110, 82] Actual: 74 False  8.020947456359863\n",
      "Predicted: [110, 82] Actual: 75 False  7.999333381652832\n",
      "Predicted: [110, 82] Actual: 76 False  7.550929069519043\n",
      "Predicted: [110, 82] Actual: 77 False  7.544541835784912\n",
      "Predicted: [110, 82] Actual: 78 False  7.826191425323486\n",
      "Predicted: [110, 82] Actual: 79 False  7.896271228790283\n",
      "Predicted: [110]   Actual: 80 False  9.310136795043945\n",
      "Predicted: [110]   Actual: 81 False  8.880870819091797\n",
      "Predicted: [110]   Actual: 82 False  9.41523551940918\n",
      "Predicted: [110]   Actual: 83 False  8.74138355255127\n",
      "Predicted: [110, 82] Actual: 84 False  7.828320026397705\n",
      "Predicted: [110, 82] Actual: 85 False  7.345905780792236\n",
      "Predicted: [110, 82] Actual: 86 False  7.585636615753174\n",
      "Predicted: [110, 82] Actual: 87 False  7.853065013885498\n",
      "Predicted: [110, 82] Actual: 88 False  7.923171520233154\n",
      "Predicted: [110, 82] Actual: 89 False  7.875583171844482\n",
      "Predicted: [110, 82] Actual: 90 False  7.76174783706665\n",
      "Predicted: [110, 82] Actual: 91 False  7.669588565826416\n",
      "Predicted: [110, 82] Actual: 92 False  7.7665534019470215\n",
      "Predicted: [110, 82] Actual: 93 False  7.974395275115967\n",
      "Predicted: [110, 82] Actual: 94 False  7.318846225738525\n",
      "Predicted: [110]   Actual: 95 False  8.804497718811035\n",
      "Predicted: [110]   Actual: 96 False  9.38066291809082\n",
      "Predicted: [110]   Actual: 97 False  8.235753059387207\n",
      "Predicted: [110, 82] Actual: 98 False  7.905907154083252\n",
      "Predicted: [110, 82] Actual: 99 False  7.634180545806885\n",
      "Predicted: [110, 82] Actual: 100 False  7.951121807098389\n",
      "Predicted: [110]   Actual: 101 False  8.6053466796875\n",
      "Predicted: [110, 82] Actual: 102 False  7.688801288604736\n",
      "Predicted: [110, 82] Actual: 103 False  7.638000965118408\n",
      "Predicted: [110, 82] Actual: 104 False  7.8297271728515625\n",
      "Predicted: [110, 82] Actual: 105 False  7.5285725593566895\n",
      "Predicted: [110, 82] Actual: 106 False  7.768944263458252\n",
      "Predicted: [110, 82] Actual: 107 False  7.9518208503723145\n",
      "Predicted: [110, 82] Actual: 108 False  7.838013172149658\n",
      "Predicted: [110]   Actual: 109 False  8.04820442199707\n",
      "Predicted: [110]   Actual: 110 True   15.719675064086914\n",
      "Predicted: [110, 82] Actual: 111 False  7.878002643585205\n",
      "Predicted: [110, 82] Actual: 112 False  7.791458606719971\n",
      "Predicted: [110, 82] Actual: 113 False  7.737489223480225\n",
      "Predicted: [110, 82] Actual: 114 False  7.7875590324401855\n",
      "Predicted: [110, 82] Actual: 115 False  7.69080114364624\n",
      "Predicted: [110, 82] Actual: 116 False  7.8202033042907715\n",
      "Predicted: [110, 82] Actual: 117 False  7.356835842132568\n",
      "Predicted: [110, 82] Actual: 118 False  7.697525501251221\n",
      "Predicted: [110, 82] Actual: 119 False  7.952539443969727\n",
      "Predicted: [110, 82] Actual: 120 False  7.945789813995361\n",
      "Predicted: [110, 82] Actual: 121 False  7.635808944702148\n",
      "Predicted: [110, 82] Actual: 122 False  7.92544412612915\n",
      "Predicted: [110, 82] Actual: 123 False  7.887034893035889\n",
      "Predicted: [110, 82] Actual: 124 False  7.6911540031433105\n",
      "Predicted: [125]   Actual: 125 True   154.92930603027344\n",
      "Predicted: [110, 82] Actual: 126 False  7.518271446228027\n",
      "Predicted: [110, 82] Actual: 127 False  7.875262260437012\n",
      "Predicted: [110, 82] Actual: 128 False  7.960875034332275\n",
      "Predicted: [110, 82] Actual: 129 False  7.834889888763428\n",
      "Predicted: [110, 82] Actual: 130 False  7.625296592712402\n",
      "Predicted: [110, 82] Actual: 131 False  7.559675693511963\n",
      "Predicted: [110, 82] Actual: 132 False  7.536380290985107\n",
      "Predicted: [110, 82] Actual: 133 False  7.534552574157715\n",
      "Predicted: [110, 82] Actual: 134 False  7.652979373931885\n",
      "Predicted: [110, 82] Actual: 135 False  7.76052188873291\n",
      "Predicted: [110, 82] Actual: 136 False  8.099687576293945\n",
      "Predicted: [110, 82] Actual: 137 False  7.433560848236084\n",
      "Predicted: [110, 82] Actual: 138 False  7.694048881530762\n",
      "Predicted: [110, 82] Actual: 139 False  7.688068389892578\n",
      "Predicted: [110]   Actual: 140 False  8.35342025756836\n",
      "Predicted: [110]   Actual: 141 False  8.565774917602539\n",
      "Predicted: [110, 82] Actual: 142 False  7.652195930480957\n",
      "Predicted: [110, 82] Actual: 143 False  7.700860500335693\n",
      "Predicted: [110, 82] Actual: 144 False  7.600343227386475\n",
      "Predicted: [110, 82] Actual: 145 False  7.752265453338623\n",
      "Predicted: [110, 82] Actual: 146 False  8.082479476928711\n",
      "Predicted: [110, 82] Actual: 147 False  7.852358341217041\n",
      "Predicted: [110, 82] Actual: 148 False  7.8710408210754395\n",
      "Predicted: [110, 82] Actual: 149 False  7.73685884475708\n",
      "Predicted: [110, 82] Actual: 150 False  7.711240768432617\n",
      "Predicted: [110, 82] Actual: 151 False  8.045003890991211\n",
      "Predicted: [110, 82] Actual: 152 False  7.836730480194092\n",
      "Predicted: [110, 82] Actual: 153 False  7.884610652923584\n",
      "Predicted: [110, 82] Actual: 154 False  7.8249592781066895\n",
      "Predicted: [110, 82] Actual: 155 False  7.54202127456665\n",
      "Predicted: [110, 82] Actual: 156 False  8.124545097351074\n",
      "Predicted: [110, 82] Actual: 157 False  7.834807395935059\n",
      "Predicted: [110, 82] Actual: 158 False  7.811624050140381\n",
      "Predicted: [110, 82] Actual: 159 False  7.919280529022217\n",
      "Predicted: [110, 82] Actual: 160 False  7.6545729637146\n",
      "Predicted: [110, 82] Actual: 161 False  7.754823207855225\n",
      "Predicted: [110, 82] Actual: 162 False  7.548292636871338\n",
      "Predicted: [110, 82] Actual: 163 False  7.713556289672852\n",
      "Predicted: [110, 82] Actual: 164 False  8.002171516418457\n",
      "Predicted: [110, 82] Actual: 165 False  7.827957630157471\n",
      "Predicted: [110, 82] Actual: 166 False  7.655993938446045\n",
      "Predicted: [110, 82] Actual: 167 False  7.6273417472839355\n",
      "Predicted: [110, 82] Actual: 168 False  7.569974422454834\n",
      "Predicted: [110, 82] Actual: 169 False  7.758434295654297\n",
      "Predicted: [110, 82] Actual: 170 False  8.085240364074707\n",
      "Predicted: [110, 82] Actual: 171 False  7.543951511383057\n",
      "Predicted: [110, 82] Actual: 172 False  8.078051567077637\n",
      "Predicted: [110, 82] Actual: 173 False  7.587108135223389\n",
      "Predicted: [110, 82] Actual: 174 False  7.895717144012451\n",
      "Predicted: [110, 82] Actual: 175 False  7.8716721534729\n",
      "Predicted: [110, 82] Actual: 176 False  7.818826198577881\n",
      "Predicted: [110, 82] Actual: 177 False  7.650940418243408\n",
      "Predicted: [110, 82] Actual: 178 False  8.009285926818848\n",
      "Predicted: [110, 82] Actual: 179 False  7.856684684753418\n",
      "Predicted: [110, 82] Actual: 180 False  7.6605305671691895\n",
      "Predicted: [110, 82] Actual: 181 False  7.856582164764404\n",
      "Predicted: [110, 82] Actual: 182 False  7.703372478485107\n",
      "Predicted: [110, 82] Actual: 183 False  7.418089389801025\n",
      "Predicted: [110, 82] Actual: 184 False  8.00549602508545\n",
      "Predicted: [110, 82] Actual: 185 False  7.633441925048828\n",
      "Predicted: [110, 82] Actual: 186 False  8.218513488769531\n",
      "Predicted: [110, 82] Actual: 187 False  7.893650531768799\n",
      "Predicted: [110, 82] Actual: 188 False  7.996665954589844\n",
      "Predicted: [110, 82] Actual: 189 False  7.726699352264404\n",
      "Predicted: [110, 82] Actual: 190 False  7.791305065155029\n",
      "Predicted: [110, 82] Actual: 191 False  7.479894161224365\n",
      "Predicted: [110, 82] Actual: 192 False  7.97471284866333\n",
      "Predicted: [110, 82] Actual: 193 False  7.5918684005737305\n",
      "Predicted: [110, 82] Actual: 194 False  7.917872905731201\n",
      "Predicted: [110, 82] Actual: 195 False  8.05371379852295\n",
      "Predicted: [110, 82] Actual: 196 False  7.630733013153076\n",
      "Predicted: [110, 82] Actual: 197 False  7.827362060546875\n",
      "Predicted: [110, 82] Actual: 198 False  7.814918041229248\n",
      "Predicted: [110, 82] Actual: 199 False  7.7722039222717285\n",
      "Predicted: [110, 82] Actual: 200 False  7.664583683013916\n",
      "Predicted: [110, 82] Actual: 201 False  7.845179080963135\n",
      "Predicted: [110, 82] Actual: 202 False  7.841581344604492\n",
      "Predicted: [110, 82] Actual: 203 False  7.896439552307129\n",
      "Predicted: [110, 82] Actual: 204 False  7.5073161125183105\n",
      "Predicted: [110, 82] Actual: 205 False  7.761989116668701\n",
      "Predicted: [110, 82] Actual: 206 False  7.520698070526123\n",
      "Predicted: [110, 82] Actual: 207 False  7.924626350402832\n",
      "Predicted: [110, 82] Actual: 208 False  7.660421848297119\n",
      "Predicted: [110, 82] Actual: 209 False  7.934620380401611\n",
      "Predicted: [110, 82] Actual: 210 False  7.825767993927002\n",
      "Predicted: [110, 82] Actual: 211 False  7.8000922203063965\n",
      "Predicted: [110, 82] Actual: 212 False  7.697385787963867\n",
      "Predicted: [110, 82] Actual: 213 False  7.603024959564209\n",
      "Predicted: [110, 82] Actual: 214 False  7.785513401031494\n",
      "Predicted: [110, 82] Actual: 215 False  7.809002876281738\n",
      "Predicted: [110, 82] Actual: 216 False  7.7333292961120605\n",
      "Predicted: [110, 82] Actual: 217 False  7.730461597442627\n",
      "Predicted: [110, 82] Actual: 218 False  7.8182783126831055\n",
      "Predicted: [110, 82] Actual: 219 False  7.74994421005249\n",
      "Predicted: [110, 82] Actual: 220 False  7.619685173034668\n",
      "Predicted: [110, 82] Actual: 221 False  7.70253849029541\n",
      "Predicted: [110, 82] Actual: 222 False  7.79844856262207\n",
      "Predicted: [110, 82] Actual: 223 False  8.25187873840332\n",
      "Predicted: [110, 82] Actual: 224 False  7.7920331954956055\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.141758  [   64/ 8532]\n",
      "loss: 1.747179  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3127  size: 5689  main correct/size: 0.549657233257163\n",
      "Also correct: 995  size: 5689  also correct/size: 0.1748989277553173\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 2.014328\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.992977  [   64/ 8532]\n",
      "loss: 1.742490  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3129  size: 5689  main correct/size: 0.5500087888908419\n",
      "Also correct: 993  size: 5689  also correct/size: 0.17454737212163826\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 2.015215\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.991491  [   64/ 8532]\n",
      "loss: 1.740476  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3129  size: 5689  main correct/size: 0.5500087888908419\n",
      "Also correct: 994  size: 5689  also correct/size: 0.17472314993847776\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 2.015742\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.990573  [   64/ 8532]\n",
      "loss: 1.739254  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3130  size: 5689  main correct/size: 0.5501845667076815\n",
      "Also correct: 993  size: 5689  also correct/size: 0.17454737212163826\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 2.016072\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.989933  [   64/ 8532]\n",
      "loss: 1.738336  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3130  size: 5689  main correct/size: 0.5501845667076815\n",
      "Also correct: 993  size: 5689  also correct/size: 0.17454737212163826\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 2.016402\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  7.692271709442139\n",
      "Predicted: [110, 82] Actual: 1  False  7.80455207824707\n",
      "Predicted: [110, 82] Actual: 2  False  7.829135417938232\n",
      "Predicted: [110, 82] Actual: 3  False  7.309057712554932\n",
      "Predicted: [110, 125] Actual: 4  False  7.472209930419922\n",
      "Predicted: [110, 82] Actual: 5  False  7.417805194854736\n",
      "Predicted: [110, 82] Actual: 6  False  7.806009769439697\n",
      "Predicted: [110, 82] Actual: 7  False  7.744533061981201\n",
      "Predicted: [110, 82] Actual: 8  False  7.520444869995117\n",
      "Predicted: [110, 82] Actual: 9  False  7.4650678634643555\n",
      "Predicted: [110, 82] Actual: 10 False  7.90565299987793\n",
      "Predicted: [110, 82] Actual: 11 False  7.67668342590332\n",
      "Predicted: [110, 82] Actual: 12 False  7.828044891357422\n",
      "Predicted: [110, 82] Actual: 13 False  7.586863994598389\n",
      "Predicted: [110, 82] Actual: 14 False  7.547773361206055\n",
      "Predicted: [110, 82] Actual: 15 False  7.454401969909668\n",
      "Predicted: [110, 82] Actual: 16 False  7.741823196411133\n",
      "Predicted: [110, 82] Actual: 17 False  7.489490509033203\n",
      "Predicted: [110, 82] Actual: 18 False  7.39019775390625\n",
      "Predicted: [110, 82] Actual: 19 False  7.573827743530273\n",
      "Predicted: [110, 82] Actual: 20 False  7.604027271270752\n",
      "Predicted: [110, 125] Actual: 21 False  7.573941230773926\n",
      "Predicted: [110, 125] Actual: 22 False  7.434340953826904\n",
      "Predicted: [110, 82] Actual: 23 False  7.6389875411987305\n",
      "Predicted: [110, 125] Actual: 24 False  7.223128318786621\n",
      "Predicted: [125, 110] Actual: 25 False  8.11212158203125\n",
      "Predicted: [110, 82] Actual: 26 False  7.632628917694092\n",
      "Predicted: [110, 82] Actual: 27 False  7.6357421875\n",
      "Predicted: [110, 82] Actual: 28 False  7.777327537536621\n",
      "Predicted: [110, 125] Actual: 29 False  7.550845146179199\n",
      "Predicted: [110, 125] Actual: 30 False  7.257957458496094\n",
      "Predicted: [110, 125] Actual: 31 False  7.467203140258789\n",
      "Predicted: [110, 82] Actual: 32 False  7.488832473754883\n",
      "Predicted: [110, 125] Actual: 33 False  7.70629358291626\n",
      "Predicted: [110, 82] Actual: 34 False  7.573513507843018\n",
      "Predicted: [110, 82] Actual: 35 False  7.689650535583496\n",
      "Predicted: [110, 82] Actual: 36 False  8.0160551071167\n",
      "Predicted: [110, 125] Actual: 37 False  7.495929718017578\n",
      "Predicted: [110, 82] Actual: 38 False  7.730692386627197\n",
      "Predicted: [110, 82] Actual: 39 False  7.8566999435424805\n",
      "Predicted: [110, 82] Actual: 40 False  7.67582368850708\n",
      "Predicted: [110, 82] Actual: 41 False  7.801278591156006\n",
      "Predicted: [110, 125] Actual: 42 False  7.58948278427124\n",
      "Predicted: [110, 82] Actual: 43 False  7.606691360473633\n",
      "Predicted: [110, 82] Actual: 44 False  7.760536193847656\n",
      "Predicted: [125, 110] Actual: 45 False  7.894561290740967\n",
      "Predicted: [110, 82] Actual: 46 False  7.5910844802856445\n",
      "Predicted: [110, 82] Actual: 47 False  7.492569923400879\n",
      "Predicted: [110, 82] Actual: 48 False  7.589415550231934\n",
      "Predicted: [110, 82] Actual: 49 False  8.026276588439941\n",
      "Predicted: [110, 82] Actual: 50 False  7.823114395141602\n",
      "Predicted: [110, 82] Actual: 51 False  8.011052131652832\n",
      "Predicted: [110, 82] Actual: 52 False  7.514852523803711\n",
      "Predicted: [110, 82] Actual: 53 False  7.697479248046875\n",
      "Predicted: [125, 110] Actual: 54 False  7.982452869415283\n",
      "Predicted: [110, 82] Actual: 55 False  7.409615516662598\n",
      "Predicted: [110, 125] Actual: 56 False  7.310504913330078\n",
      "Predicted: [110, 82] Actual: 57 False  7.488248825073242\n",
      "Predicted: [110, 125] Actual: 58 False  7.348552703857422\n",
      "Predicted: [110, 82] Actual: 59 False  7.376053810119629\n",
      "Predicted: [110, 82] Actual: 60 False  7.372793197631836\n",
      "Predicted: [110, 82] Actual: 61 False  7.794123649597168\n",
      "Predicted: [110, 82] Actual: 62 False  7.525769233703613\n",
      "Predicted: [110, 125] Actual: 63 False  7.4359893798828125\n",
      "Predicted: [110, 82] Actual: 64 False  7.42238712310791\n",
      "Predicted: [110, 82] Actual: 65 False  7.691516876220703\n",
      "Predicted: [110]   Actual: 66 False  8.648685455322266\n",
      "Predicted: [110]   Actual: 67 False  8.741893768310547\n",
      "Predicted: [110, 82] Actual: 68 False  7.878881454467773\n",
      "Predicted: [110, 82] Actual: 69 False  7.506914138793945\n",
      "Predicted: [110, 82] Actual: 70 False  7.700691223144531\n",
      "Predicted: [110, 125] Actual: 71 False  7.636590480804443\n",
      "Predicted: [110, 125] Actual: 72 False  7.416502952575684\n",
      "Predicted: [110, 82] Actual: 73 False  7.723987102508545\n",
      "Predicted: [110, 82] Actual: 74 False  7.812008857727051\n",
      "Predicted: [110, 82] Actual: 75 False  7.7834930419921875\n",
      "Predicted: [110, 125] Actual: 76 False  7.355869770050049\n",
      "Predicted: [110, 82] Actual: 77 False  7.32783317565918\n",
      "Predicted: [110, 82] Actual: 78 False  7.6259050369262695\n",
      "Predicted: [110, 82] Actual: 79 False  7.685582160949707\n",
      "Predicted: [110]   Actual: 80 False  9.160512924194336\n",
      "Predicted: [110]   Actual: 81 False  8.694117546081543\n",
      "Predicted: [110]   Actual: 82 False  9.258597373962402\n",
      "Predicted: [110]   Actual: 83 False  8.571083068847656\n",
      "Predicted: [110, 82] Actual: 84 False  7.61563777923584\n",
      "Predicted: [110, 82] Actual: 85 False  7.152829170227051\n",
      "Predicted: [110, 82] Actual: 86 False  7.3919477462768555\n",
      "Predicted: [110, 82] Actual: 87 False  7.58610725402832\n",
      "Predicted: [110, 82] Actual: 88 False  7.669160842895508\n",
      "Predicted: [110, 82] Actual: 89 False  7.687380313873291\n",
      "Predicted: [110, 82] Actual: 90 False  7.566154479980469\n",
      "Predicted: [110, 82] Actual: 91 False  7.477127552032471\n",
      "Predicted: [110, 82] Actual: 92 False  7.573210716247559\n",
      "Predicted: [110, 82] Actual: 93 False  7.787388801574707\n",
      "Predicted: [125, 110] Actual: 94 False  7.686392307281494\n",
      "Predicted: [110]   Actual: 95 False  8.625021934509277\n",
      "Predicted: [110]   Actual: 96 False  9.24676513671875\n",
      "Predicted: [110]   Actual: 97 False  8.089635848999023\n",
      "Predicted: [110, 82] Actual: 98 False  7.713747024536133\n",
      "Predicted: [110, 82] Actual: 99 False  7.435038089752197\n",
      "Predicted: [110, 82] Actual: 100 False  7.725994110107422\n",
      "Predicted: [110]   Actual: 101 False  8.430869102478027\n",
      "Predicted: [110, 82] Actual: 102 False  7.486494064331055\n",
      "Predicted: [110, 82] Actual: 103 False  7.426358222961426\n",
      "Predicted: [110, 125] Actual: 104 False  7.638149261474609\n",
      "Predicted: [110, 125] Actual: 105 False  7.336620330810547\n",
      "Predicted: [110, 82] Actual: 106 False  7.57221794128418\n",
      "Predicted: [110, 82] Actual: 107 False  7.762427806854248\n",
      "Predicted: [110, 82] Actual: 108 False  7.648784637451172\n",
      "Predicted: [110, 82] Actual: 109 False  7.839025974273682\n",
      "Predicted: [110]   Actual: 110 True   15.848426818847656\n",
      "Predicted: [110, 82] Actual: 111 False  7.6294684410095215\n",
      "Predicted: [110, 82] Actual: 112 False  7.603082656860352\n",
      "Predicted: [110, 82] Actual: 113 False  7.523946762084961\n",
      "Predicted: [110, 82] Actual: 114 False  7.576904296875\n",
      "Predicted: [110, 82] Actual: 115 False  7.468421936035156\n",
      "Predicted: [110, 82] Actual: 116 False  7.600399017333984\n",
      "Predicted: [125, 110] Actual: 117 False  7.314256191253662\n",
      "Predicted: [110, 82] Actual: 118 False  7.461580276489258\n",
      "Predicted: [110, 82] Actual: 119 False  7.775544166564941\n",
      "Predicted: [110, 82] Actual: 120 False  7.7565131187438965\n",
      "Predicted: [110, 125] Actual: 121 False  7.442046165466309\n",
      "Predicted: [110, 82] Actual: 122 False  7.709771156311035\n",
      "Predicted: [110, 82] Actual: 123 False  7.6892409324646\n",
      "Predicted: [110, 82] Actual: 124 False  7.461517333984375\n",
      "Predicted: [125]   Actual: 125 True   158.37619018554688\n",
      "Predicted: [110, 82] Actual: 126 False  7.308383941650391\n",
      "Predicted: [110, 82] Actual: 127 False  7.665881156921387\n",
      "Predicted: [110, 82] Actual: 128 False  7.756149768829346\n",
      "Predicted: [110, 82] Actual: 129 False  7.632701396942139\n",
      "Predicted: [110, 125] Actual: 130 False  7.450119972229004\n",
      "Predicted: [110, 125] Actual: 131 False  7.369215965270996\n",
      "Predicted: [110, 82] Actual: 132 False  7.316822052001953\n",
      "Predicted: [125, 110] Actual: 133 False  7.807012557983398\n",
      "Predicted: [110, 125] Actual: 134 False  7.460580825805664\n",
      "Predicted: [110, 82] Actual: 135 False  7.565271377563477\n",
      "Predicted: [110, 82] Actual: 136 False  7.908255577087402\n",
      "Predicted: [125, 110] Actual: 137 False  8.524175643920898\n",
      "Predicted: [125, 110] Actual: 138 False  7.918441295623779\n",
      "Predicted: [110, 82] Actual: 139 False  7.498130798339844\n",
      "Predicted: [110, 82] Actual: 140 False  8.103510856628418\n",
      "Predicted: [110, 82] Actual: 141 False  8.387067794799805\n",
      "Predicted: [110, 82] Actual: 142 False  7.44204044342041\n",
      "Predicted: [110, 82] Actual: 143 False  7.504875183105469\n",
      "Predicted: [110, 125] Actual: 144 False  7.419145584106445\n",
      "Predicted: [110, 82] Actual: 145 False  7.5776686668396\n",
      "Predicted: [110, 125] Actual: 146 False  7.896355628967285\n",
      "Predicted: [125, 110] Actual: 147 False  7.878222942352295\n",
      "Predicted: [110, 82] Actual: 148 False  7.679872035980225\n",
      "Predicted: [110, 125] Actual: 149 False  7.548770427703857\n",
      "Predicted: [110, 82] Actual: 150 False  7.516881942749023\n",
      "Predicted: [110, 82] Actual: 151 False  7.843998908996582\n",
      "Predicted: [110, 125] Actual: 152 False  7.650265693664551\n",
      "Predicted: [110, 82] Actual: 153 False  7.698579788208008\n",
      "Predicted: [110, 82] Actual: 154 False  7.611025333404541\n",
      "Predicted: [110, 125] Actual: 155 False  7.349028587341309\n",
      "Predicted: [110, 82] Actual: 156 False  7.940757751464844\n",
      "Predicted: [110, 82] Actual: 157 False  7.613253116607666\n",
      "Predicted: [110, 82] Actual: 158 False  7.595070838928223\n",
      "Predicted: [110, 82] Actual: 159 False  7.718796730041504\n",
      "Predicted: [110, 82] Actual: 160 False  7.464690208435059\n",
      "Predicted: [125, 110] Actual: 161 False  7.9796552658081055\n",
      "Predicted: [110, 125] Actual: 162 False  7.354294776916504\n",
      "Predicted: [110, 125] Actual: 163 False  7.52705192565918\n",
      "Predicted: [110, 82] Actual: 164 False  7.804037570953369\n",
      "Predicted: [110, 82] Actual: 165 False  7.640805244445801\n",
      "Predicted: [110, 125] Actual: 166 False  7.463947296142578\n",
      "Predicted: [110, 82] Actual: 167 False  7.427490234375\n",
      "Predicted: [125, 110] Actual: 168 False  8.97998046875\n",
      "Predicted: [110, 82] Actual: 169 False  7.559439659118652\n",
      "Predicted: [110, 82] Actual: 170 False  7.873143672943115\n",
      "Predicted: [110, 82] Actual: 171 False  7.3494439125061035\n",
      "Predicted: [110, 82] Actual: 172 False  7.886793613433838\n",
      "Predicted: [110, 82] Actual: 173 False  7.323251724243164\n",
      "Predicted: [110, 82] Actual: 174 False  7.708411693572998\n",
      "Predicted: [110, 125] Actual: 175 False  7.68333101272583\n",
      "Predicted: [110, 82] Actual: 176 False  7.603105068206787\n",
      "Predicted: [110, 82] Actual: 177 False  7.444581508636475\n",
      "Predicted: [110, 82] Actual: 178 False  7.815417289733887\n",
      "Predicted: [110, 82] Actual: 179 False  7.664854049682617\n",
      "Predicted: [110, 82] Actual: 180 False  7.465603828430176\n",
      "Predicted: [110, 82] Actual: 181 False  7.659941673278809\n",
      "Predicted: [110, 82] Actual: 182 False  7.501859664916992\n",
      "Predicted: [110, 82] Actual: 183 False  7.225584030151367\n",
      "Predicted: [110, 82] Actual: 184 False  7.797987461090088\n",
      "Predicted: [110, 82] Actual: 185 False  7.435196399688721\n",
      "Predicted: [110, 82] Actual: 186 False  8.010412216186523\n",
      "Predicted: [110, 82] Actual: 187 False  7.6446733474731445\n",
      "Predicted: [110, 82] Actual: 188 False  7.800973892211914\n",
      "Predicted: [110, 82] Actual: 189 False  7.509908199310303\n",
      "Predicted: [110, 82] Actual: 190 False  7.60202693939209\n",
      "Predicted: [125, 110] Actual: 191 False  8.11274242401123\n",
      "Predicted: [110, 82] Actual: 192 False  7.773594379425049\n",
      "Predicted: [110, 125] Actual: 193 False  7.407548904418945\n",
      "Predicted: [110, 82] Actual: 194 False  7.7027130126953125\n",
      "Predicted: [110, 82] Actual: 195 False  7.860114097595215\n",
      "Predicted: [110, 125] Actual: 196 False  7.441470146179199\n",
      "Predicted: [110, 125] Actual: 197 False  7.653503894805908\n",
      "Predicted: [110, 125] Actual: 198 False  7.630880832672119\n",
      "Predicted: [110, 82] Actual: 199 False  7.581175804138184\n",
      "Predicted: [110, 82] Actual: 200 False  7.447586536407471\n",
      "Predicted: [110, 82] Actual: 201 False  7.652768135070801\n",
      "Predicted: [110, 125] Actual: 202 False  7.639718532562256\n",
      "Predicted: [110, 82] Actual: 203 False  7.644601345062256\n",
      "Predicted: [125, 110] Actual: 204 False  8.56397819519043\n",
      "Predicted: [110, 82] Actual: 205 False  7.539443016052246\n",
      "Predicted: [110, 82] Actual: 206 False  7.316357612609863\n",
      "Predicted: [110, 82] Actual: 207 False  7.7323737144470215\n",
      "Predicted: [125, 110] Actual: 208 False  7.511245250701904\n",
      "Predicted: [110, 82] Actual: 209 False  7.74083948135376\n",
      "Predicted: [110, 82] Actual: 210 False  7.635174751281738\n",
      "Predicted: [110, 82] Actual: 211 False  7.600347995758057\n",
      "Predicted: [110, 82] Actual: 212 False  7.503596305847168\n",
      "Predicted: [110, 82] Actual: 213 False  7.408740043640137\n",
      "Predicted: [110, 82] Actual: 214 False  7.5856122970581055\n",
      "Predicted: [110, 82] Actual: 215 False  7.604674339294434\n",
      "Predicted: [110, 82] Actual: 216 False  7.542363166809082\n",
      "Predicted: [110, 125] Actual: 217 False  7.5470075607299805\n",
      "Predicted: [110, 82] Actual: 218 False  7.638535499572754\n",
      "Predicted: [110, 82] Actual: 219 False  7.543363571166992\n",
      "Predicted: [110, 82] Actual: 220 False  7.427578449249268\n",
      "Predicted: [110, 82] Actual: 221 False  7.513404846191406\n",
      "Predicted: [110, 82] Actual: 222 False  7.595942497253418\n",
      "Predicted: [110, 82] Actual: 223 False  8.031187057495117\n",
      "Predicted: [110, 82] Actual: 224 False  7.603490352630615\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.369122  [   64/ 8532]\n",
      "loss: 2.080252  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3184  size: 5689  main correct/size: 0.5596765688170153\n",
      "Also correct: 968  size: 5689  also correct/size: 0.17015292670065038\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.943415\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.278990  [   64/ 8532]\n",
      "loss: 2.077056  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3184  size: 5689  main correct/size: 0.5596765688170153\n",
      "Also correct: 965  size: 5689  also correct/size: 0.16962559325013182\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 1.944103\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.278111  [   64/ 8532]\n",
      "loss: 2.075718  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3185  size: 5689  main correct/size: 0.5598523466338549\n",
      "Also correct: 963  size: 5689  also correct/size: 0.1692740376164528\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 1.944413\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.277404  [   64/ 8532]\n",
      "loss: 2.074826  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3186  size: 5689  main correct/size: 0.5600281244506943\n",
      "Also correct: 962  size: 5689  also correct/size: 0.1690982597996133\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 1.944527\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.276809  [   64/ 8532]\n",
      "loss: 2.074096  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3186  size: 5689  main correct/size: 0.5600281244506943\n",
      "Also correct: 963  size: 5689  also correct/size: 0.1692740376164528\n",
      "Test Error: Accuracy: 72.9%, Avg loss: 1.944528\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.645874977111816\n",
      "Predicted: [110, 82] Actual: 1  False  8.006217956542969\n",
      "Predicted: [110, 82] Actual: 2  False  8.035545349121094\n",
      "Predicted: [110, 82] Actual: 3  False  7.495668411254883\n",
      "Predicted: [110, 82] Actual: 4  False  7.6680121421813965\n",
      "Predicted: [110, 82] Actual: 5  False  7.609371662139893\n",
      "Predicted: [110, 82] Actual: 6  False  8.012638092041016\n",
      "Predicted: [110, 82] Actual: 7  False  7.949921607971191\n",
      "Predicted: [110, 82] Actual: 8  False  7.71696662902832\n",
      "Predicted: [110, 82] Actual: 9  False  7.659617900848389\n",
      "Predicted: [110, 82] Actual: 10 False  8.114087104797363\n",
      "Predicted: [110, 82] Actual: 11 False  7.877301216125488\n",
      "Predicted: [110, 82] Actual: 12 False  8.038483619689941\n",
      "Predicted: [110, 82] Actual: 13 False  7.787424087524414\n",
      "Predicted: [110, 82] Actual: 14 False  7.7453484535217285\n",
      "Predicted: [110, 82] Actual: 15 False  7.65285587310791\n",
      "Predicted: [110, 82] Actual: 16 False  7.933050632476807\n",
      "Predicted: [110, 82] Actual: 17 False  7.674508094787598\n",
      "Predicted: [110, 82] Actual: 18 False  7.583673000335693\n",
      "Predicted: [110, 82] Actual: 19 False  7.775146961212158\n",
      "Predicted: [110, 82] Actual: 20 False  7.819272041320801\n",
      "Predicted: [110, 82] Actual: 21 False  7.787261962890625\n",
      "Predicted: [110, 82] Actual: 22 False  7.619544982910156\n",
      "Predicted: [110, 82] Actual: 23 False  7.833852767944336\n",
      "Predicted: [110, 82] Actual: 24 False  7.410447120666504\n",
      "Predicted: [110, 125] Actual: 25 False  7.625751495361328\n",
      "Predicted: [110, 82] Actual: 26 False  7.835439682006836\n",
      "Predicted: [110, 82] Actual: 27 False  7.828453540802002\n",
      "Predicted: [110, 82] Actual: 28 False  7.978343963623047\n",
      "Predicted: [110, 82] Actual: 29 False  7.750941276550293\n",
      "Predicted: [110, 82] Actual: 30 False  7.454370021820068\n",
      "Predicted: [110, 82] Actual: 31 False  7.662025451660156\n",
      "Predicted: [110, 82] Actual: 32 False  7.680513381958008\n",
      "Predicted: [110, 82] Actual: 33 False  7.908130645751953\n",
      "Predicted: [110, 82] Actual: 34 False  7.790805816650391\n",
      "Predicted: [110, 82] Actual: 35 False  7.869723320007324\n",
      "Predicted: [110, 82] Actual: 36 False  8.219987869262695\n",
      "Predicted: [110, 82] Actual: 37 False  7.695030689239502\n",
      "Predicted: [110, 82] Actual: 38 False  7.9435014724731445\n",
      "Predicted: [110, 82] Actual: 39 False  8.069400787353516\n",
      "Predicted: [110, 82] Actual: 40 False  7.875646591186523\n",
      "Predicted: [110, 82] Actual: 41 False  8.006837844848633\n",
      "Predicted: [110, 82] Actual: 42 False  7.795989990234375\n",
      "Predicted: [110, 82] Actual: 43 False  7.788553714752197\n",
      "Predicted: [110, 82] Actual: 44 False  7.96066951751709\n",
      "Predicted: [110, 82] Actual: 45 False  7.636009693145752\n",
      "Predicted: [110, 82] Actual: 46 False  7.790559768676758\n",
      "Predicted: [110, 82] Actual: 47 False  7.6840434074401855\n",
      "Predicted: [110, 82] Actual: 48 False  7.799333572387695\n",
      "Predicted: [110, 82] Actual: 49 False  8.202247619628906\n",
      "Predicted: [110, 82] Actual: 50 False  7.997344017028809\n",
      "Predicted: [110, 82] Actual: 51 False  8.2271146774292\n",
      "Predicted: [110, 82] Actual: 52 False  7.715921401977539\n",
      "Predicted: [110, 82] Actual: 53 False  7.882838249206543\n",
      "Predicted: [110, 82] Actual: 54 False  7.667545795440674\n",
      "Predicted: [110, 82] Actual: 55 False  7.6033406257629395\n",
      "Predicted: [110, 82] Actual: 56 False  7.4994964599609375\n",
      "Predicted: [110, 82] Actual: 57 False  7.685658931732178\n",
      "Predicted: [110, 82] Actual: 58 False  7.542839050292969\n",
      "Predicted: [110, 82] Actual: 59 False  7.571079730987549\n",
      "Predicted: [110, 82] Actual: 60 False  7.565580368041992\n",
      "Predicted: [110, 82] Actual: 61 False  7.996754169464111\n",
      "Predicted: [110, 82] Actual: 62 False  7.7221784591674805\n",
      "Predicted: [110, 82] Actual: 63 False  7.6330413818359375\n",
      "Predicted: [110, 82] Actual: 64 False  7.633033752441406\n",
      "Predicted: [110, 82] Actual: 65 False  7.89174222946167\n",
      "Predicted: [110]   Actual: 66 False  8.821477890014648\n",
      "Predicted: [110]   Actual: 67 False  8.889144897460938\n",
      "Predicted: [110, 82] Actual: 68 False  8.113935470581055\n",
      "Predicted: [110, 82] Actual: 69 False  7.694520950317383\n",
      "Predicted: [110, 82] Actual: 70 False  7.908393859863281\n",
      "Predicted: [110, 82] Actual: 71 False  7.843761444091797\n",
      "Predicted: [110, 82] Actual: 72 False  7.626589775085449\n",
      "Predicted: [110, 82] Actual: 73 False  7.89794397354126\n",
      "Predicted: [110, 82] Actual: 74 False  8.015275955200195\n",
      "Predicted: [110, 82] Actual: 75 False  7.9891767501831055\n",
      "Predicted: [110, 82] Actual: 76 False  7.54752779006958\n",
      "Predicted: [110, 82] Actual: 77 False  7.515811920166016\n",
      "Predicted: [110, 82] Actual: 78 False  7.821367263793945\n",
      "Predicted: [110, 82] Actual: 79 False  7.867767333984375\n",
      "Predicted: [110]   Actual: 80 False  9.356683731079102\n",
      "Predicted: [110]   Actual: 81 False  8.878171920776367\n",
      "Predicted: [110]   Actual: 82 False  9.437281608581543\n",
      "Predicted: [110]   Actual: 83 False  8.756240844726562\n",
      "Predicted: [110, 82] Actual: 84 False  7.835569381713867\n",
      "Predicted: [110, 82] Actual: 85 False  7.342971324920654\n",
      "Predicted: [110, 82] Actual: 86 False  7.591943740844727\n",
      "Predicted: [110, 82] Actual: 87 False  7.761626243591309\n",
      "Predicted: [110, 82] Actual: 88 False  7.866664886474609\n",
      "Predicted: [110, 82] Actual: 89 False  7.885509967803955\n",
      "Predicted: [110, 82] Actual: 90 False  7.764432907104492\n",
      "Predicted: [110, 82] Actual: 91 False  7.669594764709473\n",
      "Predicted: [110, 82] Actual: 92 False  7.771925449371338\n",
      "Predicted: [110, 82] Actual: 93 False  7.990165710449219\n",
      "Predicted: [110, 82] Actual: 94 False  7.302501678466797\n",
      "Predicted: [110]   Actual: 95 False  8.830718994140625\n",
      "Predicted: [110]   Actual: 96 False  9.435887336730957\n",
      "Predicted: [110]   Actual: 97 False  8.272159576416016\n",
      "Predicted: [110, 82] Actual: 98 False  7.926052093505859\n",
      "Predicted: [110, 82] Actual: 99 False  7.630611896514893\n",
      "Predicted: [110, 82] Actual: 100 False  7.888275623321533\n",
      "Predicted: [110]   Actual: 101 False  8.609992980957031\n",
      "Predicted: [110, 82] Actual: 102 False  7.6850690841674805\n",
      "Predicted: [110, 82] Actual: 103 False  7.602382183074951\n",
      "Predicted: [110, 82] Actual: 104 False  7.842515468597412\n",
      "Predicted: [110, 82] Actual: 105 False  7.526628494262695\n",
      "Predicted: [110, 82] Actual: 106 False  7.7649030685424805\n",
      "Predicted: [110, 82] Actual: 107 False  7.968605995178223\n",
      "Predicted: [110, 82] Actual: 108 False  7.848381996154785\n",
      "Predicted: [110, 82] Actual: 109 False  8.060317993164062\n",
      "Predicted: [110]   Actual: 110 True   16.310895919799805\n",
      "Predicted: [110, 82] Actual: 111 False  7.818755149841309\n",
      "Predicted: [110, 82] Actual: 112 False  7.791680335998535\n",
      "Predicted: [110, 82] Actual: 113 False  7.716007232666016\n",
      "Predicted: [110, 82] Actual: 114 False  7.767906665802002\n",
      "Predicted: [110, 82] Actual: 115 False  7.64314079284668\n",
      "Predicted: [110, 82] Actual: 116 False  7.802329063415527\n",
      "Predicted: [110, 82] Actual: 117 False  7.3509626388549805\n",
      "Predicted: [110, 82] Actual: 118 False  7.622838973999023\n",
      "Predicted: [110, 82] Actual: 119 False  7.97316837310791\n",
      "Predicted: [110, 82] Actual: 120 False  7.960380554199219\n",
      "Predicted: [110, 82] Actual: 121 False  7.638014793395996\n",
      "Predicted: [110, 82] Actual: 122 False  7.910991668701172\n",
      "Predicted: [110, 82] Actual: 123 False  7.887121200561523\n",
      "Predicted: [110, 82] Actual: 124 False  7.661670207977295\n",
      "Predicted: [125]   Actual: 125 True   157.7149200439453\n",
      "Predicted: [110, 82] Actual: 126 False  7.467857360839844\n",
      "Predicted: [110, 82] Actual: 127 False  7.873440742492676\n",
      "Predicted: [110, 82] Actual: 128 False  7.939938068389893\n",
      "Predicted: [110, 82] Actual: 129 False  7.837814807891846\n",
      "Predicted: [110, 82] Actual: 130 False  7.648350715637207\n",
      "Predicted: [110, 82] Actual: 131 False  7.567752838134766\n",
      "Predicted: [110, 82] Actual: 132 False  7.497200012207031\n",
      "Predicted: [110, 82] Actual: 133 False  7.534038543701172\n",
      "Predicted: [110, 82] Actual: 134 False  7.658407688140869\n",
      "Predicted: [110, 82] Actual: 135 False  7.761316299438477\n",
      "Predicted: [110, 82] Actual: 136 False  8.115410804748535\n",
      "Predicted: [110, 125] Actual: 137 False  7.44289493560791\n",
      "Predicted: [110, 82] Actual: 138 False  7.713671684265137\n",
      "Predicted: [110, 82] Actual: 139 False  7.6953606605529785\n",
      "Predicted: [110, 82] Actual: 140 False  8.27572250366211\n",
      "Predicted: [110]   Actual: 141 False  8.603830337524414\n",
      "Predicted: [110, 82] Actual: 142 False  7.6274094581604\n",
      "Predicted: [110, 82] Actual: 143 False  7.703251838684082\n",
      "Predicted: [110, 82] Actual: 144 False  7.617786407470703\n",
      "Predicted: [110, 82] Actual: 145 False  7.800055503845215\n",
      "Predicted: [110, 82] Actual: 146 False  8.114398956298828\n",
      "Predicted: [110, 82] Actual: 147 False  7.856212139129639\n",
      "Predicted: [110, 82] Actual: 148 False  7.899014472961426\n",
      "Predicted: [110, 82] Actual: 149 False  7.756062030792236\n",
      "Predicted: [110, 82] Actual: 150 False  7.714885711669922\n",
      "Predicted: [110, 82] Actual: 151 False  8.045546531677246\n",
      "Predicted: [110, 82] Actual: 152 False  7.855057239532471\n",
      "Predicted: [110, 82] Actual: 153 False  7.904533386230469\n",
      "Predicted: [110, 82] Actual: 154 False  7.809326648712158\n",
      "Predicted: [110, 82] Actual: 155 False  7.529618263244629\n",
      "Predicted: [110, 82] Actual: 156 False  8.168113708496094\n",
      "Predicted: [110, 82] Actual: 157 False  7.77063512802124\n",
      "Predicted: [110, 82] Actual: 158 False  7.780398845672607\n",
      "Predicted: [110, 82] Actual: 159 False  7.917501449584961\n",
      "Predicted: [110, 82] Actual: 160 False  7.65683650970459\n",
      "Predicted: [110, 82] Actual: 161 False  7.796651840209961\n",
      "Predicted: [110, 82] Actual: 162 False  7.542353630065918\n",
      "Predicted: [110, 82] Actual: 163 False  7.7271904945373535\n",
      "Predicted: [110, 82] Actual: 164 False  8.007088661193848\n",
      "Predicted: [110, 82] Actual: 165 False  7.84420919418335\n",
      "Predicted: [110, 82] Actual: 166 False  7.663092613220215\n",
      "Predicted: [110, 82] Actual: 167 False  7.61983585357666\n",
      "Predicted: [110, 125] Actual: 168 False  7.583128929138184\n",
      "Predicted: [110, 82] Actual: 169 False  7.752659320831299\n",
      "Predicted: [110, 82] Actual: 170 False  8.083892822265625\n",
      "Predicted: [110, 82] Actual: 171 False  7.5735883712768555\n",
      "Predicted: [110, 82] Actual: 172 False  8.07937240600586\n",
      "Predicted: [110, 82] Actual: 173 False  7.514950752258301\n",
      "Predicted: [110, 82] Actual: 174 False  7.928417205810547\n",
      "Predicted: [110, 82] Actual: 175 False  7.882932662963867\n",
      "Predicted: [110, 82] Actual: 176 False  7.795748233795166\n",
      "Predicted: [110, 82] Actual: 177 False  7.634593963623047\n",
      "Predicted: [110, 82] Actual: 178 False  8.0179443359375\n",
      "Predicted: [110, 82] Actual: 179 False  7.867806434631348\n",
      "Predicted: [110, 82] Actual: 180 False  7.659926414489746\n",
      "Predicted: [110, 82] Actual: 181 False  7.856447696685791\n",
      "Predicted: [110, 82] Actual: 182 False  7.694529056549072\n",
      "Predicted: [110, 82] Actual: 183 False  7.409746170043945\n",
      "Predicted: [110, 82] Actual: 184 False  8.001209259033203\n",
      "Predicted: [110, 82] Actual: 185 False  7.623022079467773\n",
      "Predicted: [110, 82] Actual: 186 False  8.223259925842285\n",
      "Predicted: [110, 82] Actual: 187 False  7.836139678955078\n",
      "Predicted: [110, 82] Actual: 188 False  8.0205078125\n",
      "Predicted: [110, 82] Actual: 189 False  7.689901351928711\n",
      "Predicted: [110, 82] Actual: 190 False  7.800708293914795\n",
      "Predicted: [110, 125] Actual: 191 False  7.489058971405029\n",
      "Predicted: [110, 82] Actual: 192 False  7.974429130554199\n",
      "Predicted: [110, 82] Actual: 193 False  7.6037187576293945\n",
      "Predicted: [110, 82] Actual: 194 False  7.908425331115723\n",
      "Predicted: [110, 82] Actual: 195 False  8.06709098815918\n",
      "Predicted: [110, 82] Actual: 196 False  7.639406204223633\n",
      "Predicted: [110, 82] Actual: 197 False  7.859638214111328\n",
      "Predicted: [110, 82] Actual: 198 False  7.833865165710449\n",
      "Predicted: [110, 82] Actual: 199 False  7.778681755065918\n",
      "Predicted: [110, 82] Actual: 200 False  7.640984535217285\n",
      "Predicted: [110, 82] Actual: 201 False  7.855525970458984\n",
      "Predicted: [110, 82] Actual: 202 False  7.831337928771973\n",
      "Predicted: [110, 82] Actual: 203 False  7.858380317687988\n",
      "Predicted: [110, 82] Actual: 204 False  7.588542938232422\n",
      "Predicted: [110, 82] Actual: 205 False  7.729676723480225\n",
      "Predicted: [110, 82] Actual: 206 False  7.504045486450195\n",
      "Predicted: [110, 82] Actual: 207 False  7.9354705810546875\n",
      "Predicted: [110, 82] Actual: 208 False  7.671720027923584\n",
      "Predicted: [110, 82] Actual: 209 False  7.9371161460876465\n",
      "Predicted: [110, 82] Actual: 210 False  7.836322784423828\n",
      "Predicted: [110, 82] Actual: 211 False  7.796956539154053\n",
      "Predicted: [110, 82] Actual: 212 False  7.700567245483398\n",
      "Predicted: [110, 82] Actual: 213 False  7.601784706115723\n",
      "Predicted: [110, 82] Actual: 214 False  7.782534122467041\n",
      "Predicted: [110, 82] Actual: 215 False  7.797640323638916\n",
      "Predicted: [110, 82] Actual: 216 False  7.735056400299072\n",
      "Predicted: [110, 82] Actual: 217 False  7.74892520904541\n",
      "Predicted: [110, 82] Actual: 218 False  7.8439836502075195\n",
      "Predicted: [110, 82] Actual: 219 False  7.738978862762451\n",
      "Predicted: [110, 82] Actual: 220 False  7.620809555053711\n",
      "Predicted: [110, 82] Actual: 221 False  7.714709281921387\n",
      "Predicted: [110, 82] Actual: 222 False  7.79096794128418\n",
      "Predicted: [110, 82] Actual: 223 False  8.24239444732666\n",
      "Predicted: [110, 82] Actual: 224 False  7.800480842590332\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.911471  [   64/ 8532]\n",
      "loss: 2.003492  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3187  size: 5689  main correct/size: 0.5602039022675338\n",
      "Also correct: 956  size: 5689  also correct/size: 0.1680435928985762\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.958794\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.917430  [   64/ 8532]\n",
      "loss: 2.001187  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3187  size: 5689  main correct/size: 0.5602039022675338\n",
      "Also correct: 945  size: 5689  also correct/size: 0.16611003691334153\n",
      "Test Error: Accuracy: 72.6%, Avg loss: 1.959354\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.919034  [   64/ 8532]\n",
      "loss: 1.999503  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3186  size: 5689  main correct/size: 0.5600281244506943\n",
      "Also correct: 943  size: 5689  also correct/size: 0.1657584812796625\n",
      "Test Error: Accuracy: 72.6%, Avg loss: 1.959544\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.920045  [   64/ 8532]\n",
      "loss: 1.998392  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3186  size: 5689  main correct/size: 0.5600281244506943\n",
      "Also correct: 943  size: 5689  also correct/size: 0.1657584812796625\n",
      "Test Error: Accuracy: 72.6%, Avg loss: 1.959613\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.920536  [   64/ 8532]\n",
      "loss: 1.997585  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3185  size: 5689  main correct/size: 0.5598523466338549\n",
      "Also correct: 944  size: 5689  also correct/size: 0.16593425909650203\n",
      "Test Error: Accuracy: 72.6%, Avg loss: 1.959631\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.517535209655762\n",
      "Predicted: [110, 82] Actual: 1  False  7.883203983306885\n",
      "Predicted: [110, 82] Actual: 2  False  7.903958320617676\n",
      "Predicted: [110, 82] Actual: 3  False  7.349958896636963\n",
      "Predicted: [110, 82] Actual: 4  False  7.526318550109863\n",
      "Predicted: [110, 82] Actual: 5  False  7.476294040679932\n",
      "Predicted: [110, 82] Actual: 6  False  7.8772101402282715\n",
      "Predicted: [110, 82] Actual: 7  False  7.815804958343506\n",
      "Predicted: [110, 82] Actual: 8  False  7.574751377105713\n",
      "Predicted: [110, 82] Actual: 9  False  7.514389514923096\n",
      "Predicted: [110, 82] Actual: 10 False  7.984219074249268\n",
      "Predicted: [110, 82] Actual: 11 False  7.745577335357666\n",
      "Predicted: [110, 82] Actual: 12 False  7.907591819763184\n",
      "Predicted: [110, 82] Actual: 13 False  7.654240608215332\n",
      "Predicted: [110, 82] Actual: 14 False  7.611695289611816\n",
      "Predicted: [110, 82] Actual: 15 False  7.516021251678467\n",
      "Predicted: [110, 82] Actual: 16 False  7.806471347808838\n",
      "Predicted: [110, 82] Actual: 17 False  7.536492824554443\n",
      "Predicted: [110, 82] Actual: 18 False  7.445595741271973\n",
      "Predicted: [110, 82] Actual: 19 False  7.637253284454346\n",
      "Predicted: [110, 82] Actual: 20 False  7.6841864585876465\n",
      "Predicted: [110, 82] Actual: 21 False  7.66472053527832\n",
      "Predicted: [110, 82] Actual: 22 False  7.476064205169678\n",
      "Predicted: [110, 82] Actual: 23 False  7.696948051452637\n",
      "Predicted: [110, 82] Actual: 24 False  7.272603988647461\n",
      "Predicted: [110, 82] Actual: 25 False  7.481594562530518\n",
      "Predicted: [110, 82] Actual: 26 False  7.71096658706665\n",
      "Predicted: [110, 82] Actual: 27 False  7.694758892059326\n",
      "Predicted: [110, 82] Actual: 28 False  7.840754985809326\n",
      "Predicted: [110, 82] Actual: 29 False  7.6122965812683105\n",
      "Predicted: [110, 82] Actual: 30 False  7.305974006652832\n",
      "Predicted: [110, 82] Actual: 31 False  7.5236124992370605\n",
      "Predicted: [110, 82] Actual: 32 False  7.5585246086120605\n",
      "Predicted: [110, 82] Actual: 33 False  7.774575710296631\n",
      "Predicted: [110, 82] Actual: 34 False  7.666134357452393\n",
      "Predicted: [110, 82] Actual: 35 False  7.738518714904785\n",
      "Predicted: [110, 82] Actual: 36 False  8.10749626159668\n",
      "Predicted: [110, 82] Actual: 37 False  7.5392889976501465\n",
      "Predicted: [110, 82] Actual: 38 False  7.821203708648682\n",
      "Predicted: [110, 82] Actual: 39 False  7.943124771118164\n",
      "Predicted: [110, 82] Actual: 40 False  7.742343425750732\n",
      "Predicted: [110, 82] Actual: 41 False  7.874024391174316\n",
      "Predicted: [110, 82] Actual: 42 False  7.653750419616699\n",
      "Predicted: [110, 82] Actual: 43 False  7.642857074737549\n",
      "Predicted: [110, 82] Actual: 44 False  7.831563472747803\n",
      "Predicted: [110, 82] Actual: 45 False  7.512829303741455\n",
      "Predicted: [110, 82] Actual: 46 False  7.653247356414795\n",
      "Predicted: [110, 82] Actual: 47 False  7.538449764251709\n",
      "Predicted: [110, 82] Actual: 48 False  7.674362659454346\n",
      "Predicted: [110, 82] Actual: 49 False  8.078095436096191\n",
      "Predicted: [110, 82] Actual: 50 False  7.8716583251953125\n",
      "Predicted: [110, 82] Actual: 51 False  8.076359748840332\n",
      "Predicted: [110, 82] Actual: 52 False  7.5774455070495605\n",
      "Predicted: [110, 82] Actual: 53 False  7.745052814483643\n",
      "Predicted: [110, 82] Actual: 54 False  7.524810314178467\n",
      "Predicted: [110, 82] Actual: 55 False  7.465304851531982\n",
      "Predicted: [110, 82] Actual: 56 False  7.3543381690979\n",
      "Predicted: [110, 82] Actual: 57 False  7.5495381355285645\n",
      "Predicted: [110, 82] Actual: 58 False  7.402895927429199\n",
      "Predicted: [110, 82] Actual: 59 False  7.434427261352539\n",
      "Predicted: [110, 82] Actual: 60 False  7.423017978668213\n",
      "Predicted: [110, 82] Actual: 61 False  7.86450719833374\n",
      "Predicted: [110, 82] Actual: 62 False  7.581762790679932\n",
      "Predicted: [110, 82] Actual: 63 False  7.493122577667236\n",
      "Predicted: [110, 82] Actual: 64 False  7.492526531219482\n",
      "Predicted: [110, 82] Actual: 65 False  7.743194580078125\n",
      "Predicted: [110]   Actual: 66 False  8.708181381225586\n",
      "Predicted: [110]   Actual: 67 False  8.7610502243042\n",
      "Predicted: [110, 82] Actual: 68 False  7.998592376708984\n",
      "Predicted: [110, 82] Actual: 69 False  7.563439846038818\n",
      "Predicted: [110, 82] Actual: 70 False  7.773956775665283\n",
      "Predicted: [110, 82] Actual: 71 False  7.7083516120910645\n",
      "Predicted: [110, 82] Actual: 72 False  7.4913506507873535\n",
      "Predicted: [110, 82] Actual: 73 False  7.7518391609191895\n",
      "Predicted: [110, 82] Actual: 74 False  7.889500617980957\n",
      "Predicted: [110, 82] Actual: 75 False  7.862956523895264\n",
      "Predicted: [110, 82] Actual: 76 False  7.401486873626709\n",
      "Predicted: [110, 82] Actual: 77 False  7.382190227508545\n",
      "Predicted: [110, 82] Actual: 78 False  7.687410831451416\n",
      "Predicted: [110, 82] Actual: 79 False  7.73042631149292\n",
      "Predicted: [110]   Actual: 80 False  9.25671100616455\n",
      "Predicted: [110]   Actual: 81 False  8.729011535644531\n",
      "Predicted: [110]   Actual: 82 False  9.342886924743652\n",
      "Predicted: [110]   Actual: 83 False  8.641942977905273\n",
      "Predicted: [110, 82] Actual: 84 False  7.711598873138428\n",
      "Predicted: [110, 82] Actual: 85 False  7.191697120666504\n",
      "Predicted: [110, 82] Actual: 86 False  7.477728366851807\n",
      "Predicted: [110, 82] Actual: 87 False  7.624685764312744\n",
      "Predicted: [110, 82] Actual: 88 False  7.710292339324951\n",
      "Predicted: [110, 82] Actual: 89 False  7.7570366859436035\n",
      "Predicted: [110, 82] Actual: 90 False  7.631417751312256\n",
      "Predicted: [110, 82] Actual: 91 False  7.530576229095459\n",
      "Predicted: [110, 82] Actual: 92 False  7.640571117401123\n",
      "Predicted: [110, 82] Actual: 93 False  7.859821319580078\n",
      "Predicted: [110, 82] Actual: 94 False  7.152463436126709\n",
      "Predicted: [110]   Actual: 95 False  8.722602844238281\n",
      "Predicted: [110]   Actual: 96 False  9.359411239624023\n",
      "Predicted: [110]   Actual: 97 False  8.168228149414062\n",
      "Predicted: [110, 82] Actual: 98 False  7.800400733947754\n",
      "Predicted: [110, 82] Actual: 99 False  7.51137113571167\n",
      "Predicted: [110, 82] Actual: 100 False  7.727780818939209\n",
      "Predicted: [110]   Actual: 101 False  8.49615478515625\n",
      "Predicted: [110, 82] Actual: 102 False  7.542447566986084\n",
      "Predicted: [110, 82] Actual: 103 False  7.460522174835205\n",
      "Predicted: [110, 82] Actual: 104 False  7.706385135650635\n",
      "Predicted: [110, 82] Actual: 105 False  7.382247447967529\n",
      "Predicted: [110, 82] Actual: 106 False  7.631448745727539\n",
      "Predicted: [110, 82] Actual: 107 False  7.835255146026611\n",
      "Predicted: [110, 82] Actual: 108 False  7.728604793548584\n",
      "Predicted: [110, 82] Actual: 109 False  7.960557460784912\n",
      "Predicted: [110]   Actual: 110 True   16.483722686767578\n",
      "Predicted: [110, 82] Actual: 111 False  7.66670560836792\n",
      "Predicted: [110, 82] Actual: 112 False  7.655853748321533\n",
      "Predicted: [110, 82] Actual: 113 False  7.573760509490967\n",
      "Predicted: [110, 82] Actual: 114 False  7.6221699714660645\n",
      "Predicted: [110, 82] Actual: 115 False  7.5125956535339355\n",
      "Predicted: [110, 82] Actual: 116 False  7.661245822906494\n",
      "Predicted: [110, 82] Actual: 117 False  7.202374458312988\n",
      "Predicted: [110, 82] Actual: 118 False  7.469080448150635\n",
      "Predicted: [110, 82] Actual: 119 False  7.847100734710693\n",
      "Predicted: [110, 82] Actual: 120 False  7.826400279998779\n",
      "Predicted: [110, 82] Actual: 121 False  7.494699001312256\n",
      "Predicted: [110, 82] Actual: 122 False  7.785794734954834\n",
      "Predicted: [110, 82] Actual: 123 False  7.753620624542236\n",
      "Predicted: [110, 82] Actual: 124 False  7.514420986175537\n",
      "Predicted: [125]   Actual: 125 True   158.5211181640625\n",
      "Predicted: [110, 82] Actual: 126 False  7.324321269989014\n",
      "Predicted: [110, 82] Actual: 127 False  7.786981105804443\n",
      "Predicted: [110, 82] Actual: 128 False  7.80081033706665\n",
      "Predicted: [110, 82] Actual: 129 False  7.681918621063232\n",
      "Predicted: [110, 82] Actual: 130 False  7.51870584487915\n",
      "Predicted: [110, 82] Actual: 131 False  7.422979354858398\n",
      "Predicted: [110, 82] Actual: 132 False  7.3454461097717285\n",
      "Predicted: [110, 82] Actual: 133 False  7.381415367126465\n",
      "Predicted: [110, 82] Actual: 134 False  7.521040439605713\n",
      "Predicted: [110, 82] Actual: 135 False  7.622992038726807\n",
      "Predicted: [110, 82] Actual: 136 False  7.983701229095459\n",
      "Predicted: [110, 125] Actual: 137 False  7.300791263580322\n",
      "Predicted: [110, 82] Actual: 138 False  7.576916694641113\n",
      "Predicted: [110, 82] Actual: 139 False  7.561779022216797\n",
      "Predicted: [110, 82] Actual: 140 False  8.13265609741211\n",
      "Predicted: [110, 82] Actual: 141 False  8.514283180236816\n",
      "Predicted: [110, 82] Actual: 142 False  7.484962463378906\n",
      "Predicted: [110, 82] Actual: 143 False  7.573079586029053\n",
      "Predicted: [110, 82] Actual: 144 False  7.4839935302734375\n",
      "Predicted: [110, 82] Actual: 145 False  7.656363487243652\n",
      "Predicted: [110, 82] Actual: 146 False  7.9817352294921875\n",
      "Predicted: [110, 82] Actual: 147 False  7.706148624420166\n",
      "Predicted: [110, 82] Actual: 148 False  7.783458232879639\n",
      "Predicted: [110, 82] Actual: 149 False  7.619724750518799\n",
      "Predicted: [110, 82] Actual: 150 False  7.57527494430542\n",
      "Predicted: [110, 82] Actual: 151 False  7.911356449127197\n",
      "Predicted: [110, 82] Actual: 152 False  7.715019702911377\n",
      "Predicted: [110, 82] Actual: 153 False  7.769805431365967\n",
      "Predicted: [110, 82] Actual: 154 False  7.6716389656066895\n",
      "Predicted: [110, 82] Actual: 155 False  7.3911566734313965\n",
      "Predicted: [110, 82] Actual: 156 False  8.056197166442871\n",
      "Predicted: [110, 82] Actual: 157 False  7.610384941101074\n",
      "Predicted: [110, 82] Actual: 158 False  7.63861608505249\n",
      "Predicted: [110, 82] Actual: 159 False  7.781032085418701\n",
      "Predicted: [110, 82] Actual: 160 False  7.529592514038086\n",
      "Predicted: [110, 82] Actual: 161 False  7.6594319343566895\n",
      "Predicted: [110, 82] Actual: 162 False  7.393333435058594\n",
      "Predicted: [110, 82] Actual: 163 False  7.591250419616699\n",
      "Predicted: [110, 82] Actual: 164 False  7.87965202331543\n",
      "Predicted: [110, 82] Actual: 165 False  7.711254596710205\n",
      "Predicted: [110, 82] Actual: 166 False  7.523871898651123\n",
      "Predicted: [110, 82] Actual: 167 False  7.476670742034912\n",
      "Predicted: [110, 125] Actual: 168 False  7.440463542938232\n",
      "Predicted: [110, 82] Actual: 169 False  7.611704349517822\n",
      "Predicted: [110, 82] Actual: 170 False  7.959017276763916\n",
      "Predicted: [110, 82] Actual: 171 False  7.441708087921143\n",
      "Predicted: [110, 82] Actual: 172 False  7.953426837921143\n",
      "Predicted: [110, 82] Actual: 173 False  7.352715969085693\n",
      "Predicted: [110, 82] Actual: 174 False  7.825500965118408\n",
      "Predicted: [110, 82] Actual: 175 False  7.773350238800049\n",
      "Predicted: [110, 82] Actual: 176 False  7.644038677215576\n",
      "Predicted: [110, 82] Actual: 177 False  7.505564212799072\n",
      "Predicted: [110, 82] Actual: 178 False  7.893128871917725\n",
      "Predicted: [110, 82] Actual: 179 False  7.728710174560547\n",
      "Predicted: [110, 82] Actual: 180 False  7.518422603607178\n",
      "Predicted: [110, 82] Actual: 181 False  7.724799633026123\n",
      "Predicted: [110, 82] Actual: 182 False  7.558596134185791\n",
      "Predicted: [110, 82] Actual: 183 False  7.264684200286865\n",
      "Predicted: [110, 82] Actual: 184 False  7.882120132446289\n",
      "Predicted: [110, 82] Actual: 185 False  7.486168384552002\n",
      "Predicted: [110, 82] Actual: 186 False  8.107672691345215\n",
      "Predicted: [110, 82] Actual: 187 False  7.652794361114502\n",
      "Predicted: [110, 82] Actual: 188 False  7.898237705230713\n",
      "Predicted: [110, 82] Actual: 189 False  7.564769268035889\n",
      "Predicted: [110, 82] Actual: 190 False  7.648608684539795\n",
      "Predicted: [110, 82] Actual: 191 False  7.347897529602051\n",
      "Predicted: [110, 82] Actual: 192 False  7.847381114959717\n",
      "Predicted: [110, 82] Actual: 193 False  7.4692912101745605\n",
      "Predicted: [110, 82] Actual: 194 False  7.78080415725708\n",
      "Predicted: [110, 82] Actual: 195 False  7.939180374145508\n",
      "Predicted: [110, 82] Actual: 196 False  7.498968124389648\n",
      "Predicted: [110, 82] Actual: 197 False  7.727425575256348\n",
      "Predicted: [110, 82] Actual: 198 False  7.696088790893555\n",
      "Predicted: [110, 82] Actual: 199 False  7.641164302825928\n",
      "Predicted: [110, 82] Actual: 200 False  7.509332656860352\n",
      "Predicted: [110, 82] Actual: 201 False  7.719855785369873\n",
      "Predicted: [110, 82] Actual: 202 False  7.688449382781982\n",
      "Predicted: [110, 82] Actual: 203 False  7.6837053298950195\n",
      "Predicted: [110, 82] Actual: 204 False  7.461205959320068\n",
      "Predicted: [110, 82] Actual: 205 False  7.58364725112915\n",
      "Predicted: [110, 82] Actual: 206 False  7.361208438873291\n",
      "Predicted: [110, 82] Actual: 207 False  7.802736759185791\n",
      "Predicted: [110, 82] Actual: 208 False  7.533695220947266\n",
      "Predicted: [110, 82] Actual: 209 False  7.802734375\n",
      "Predicted: [110, 82] Actual: 210 False  7.702229022979736\n",
      "Predicted: [110, 82] Actual: 211 False  7.663540840148926\n",
      "Predicted: [110, 82] Actual: 212 False  7.558780193328857\n",
      "Predicted: [110, 82] Actual: 213 False  7.463808536529541\n",
      "Predicted: [110, 82] Actual: 214 False  7.645359516143799\n",
      "Predicted: [110, 82] Actual: 215 False  7.663265705108643\n",
      "Predicted: [110, 82] Actual: 216 False  7.597485065460205\n",
      "Predicted: [110, 82] Actual: 217 False  7.612857341766357\n",
      "Predicted: [110, 82] Actual: 218 False  7.709507465362549\n",
      "Predicted: [110, 82] Actual: 219 False  7.578111171722412\n",
      "Predicted: [110, 82] Actual: 220 False  7.479203701019287\n",
      "Predicted: [110, 82] Actual: 221 False  7.581630706787109\n",
      "Predicted: [110, 82] Actual: 222 False  7.660250186920166\n",
      "Predicted: [110, 82] Actual: 223 False  8.11279296875\n",
      "Predicted: [110, 82] Actual: 224 False  7.6649675369262695\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.535386  [   64/ 8532]\n",
      "loss: 1.685350  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3128  size: 5689  main correct/size: 0.5498330110740025\n",
      "Also correct: 977  size: 5689  also correct/size: 0.171734927052206\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.998989\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.566217  [   64/ 8532]\n",
      "loss: 1.685457  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3127  size: 5689  main correct/size: 0.549657233257163\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999716\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.566897  [   64/ 8532]\n",
      "loss: 1.684236  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3127  size: 5689  main correct/size: 0.549657233257163\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999971\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.566935  [   64/ 8532]\n",
      "loss: 1.683028  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3127  size: 5689  main correct/size: 0.549657233257163\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 2.000042\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.566841  [   64/ 8532]\n",
      "loss: 1.681945  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3127  size: 5689  main correct/size: 0.549657233257163\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 2.000092\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.652420520782471\n",
      "Predicted: [110, 82] Actual: 1  False  8.01741886138916\n",
      "Predicted: [110, 82] Actual: 2  False  8.038334846496582\n",
      "Predicted: [110, 82] Actual: 3  False  7.4649858474731445\n",
      "Predicted: [110, 82] Actual: 4  False  7.650607109069824\n",
      "Predicted: [110, 82] Actual: 5  False  7.600443363189697\n",
      "Predicted: [110, 82] Actual: 6  False  8.012031555175781\n",
      "Predicted: [110, 82] Actual: 7  False  7.950285911560059\n",
      "Predicted: [110, 82] Actual: 8  False  7.697504997253418\n",
      "Predicted: [110, 82] Actual: 9  False  7.634345054626465\n",
      "Predicted: [110, 82] Actual: 10 False  8.120833396911621\n",
      "Predicted: [110, 82] Actual: 11 False  7.87722110748291\n",
      "Predicted: [110, 82] Actual: 12 False  8.045592308044434\n",
      "Predicted: [110, 82] Actual: 13 False  7.781012535095215\n",
      "Predicted: [110, 82] Actual: 14 False  7.736726760864258\n",
      "Predicted: [110, 82] Actual: 15 False  7.638427257537842\n",
      "Predicted: [110, 82] Actual: 16 False  7.940125942230225\n",
      "Predicted: [110, 82] Actual: 17 False  7.652477264404297\n",
      "Predicted: [110, 82] Actual: 18 False  7.567131519317627\n",
      "Predicted: [110, 82] Actual: 19 False  7.765386581420898\n",
      "Predicted: [110, 82] Actual: 20 False  7.832621097564697\n",
      "Predicted: [110, 82] Actual: 21 False  7.819416522979736\n",
      "Predicted: [110, 82] Actual: 22 False  7.592187404632568\n",
      "Predicted: [110, 82] Actual: 23 False  7.821660041809082\n",
      "Predicted: [110, 82] Actual: 24 False  7.390829086303711\n",
      "Predicted: [110, 82] Actual: 25 False  7.611067771911621\n",
      "Predicted: [110, 82] Actual: 26 False  7.839974403381348\n",
      "Predicted: [110, 82] Actual: 27 False  7.818183898925781\n",
      "Predicted: [110, 82] Actual: 28 False  7.97149133682251\n",
      "Predicted: [110, 82] Actual: 29 False  7.7396135330200195\n",
      "Predicted: [110, 82] Actual: 30 False  7.429121494293213\n",
      "Predicted: [110, 82] Actual: 31 False  7.652641296386719\n",
      "Predicted: [110, 82] Actual: 32 False  7.6892547607421875\n",
      "Predicted: [110, 82] Actual: 33 False  7.904088973999023\n",
      "Predicted: [110, 82] Actual: 34 False  7.806065082550049\n",
      "Predicted: [110, 82] Actual: 35 False  7.864208221435547\n",
      "Predicted: [110, 82] Actual: 36 False  8.20296573638916\n",
      "Predicted: [110, 82] Actual: 37 False  7.6583147048950195\n",
      "Predicted: [110, 82] Actual: 38 False  7.948102951049805\n",
      "Predicted: [110, 82] Actual: 39 False  8.07874870300293\n",
      "Predicted: [110, 82] Actual: 40 False  7.8694562911987305\n",
      "Predicted: [110, 82] Actual: 41 False  8.004283905029297\n",
      "Predicted: [110, 82] Actual: 42 False  7.788378715515137\n",
      "Predicted: [110, 82] Actual: 43 False  7.755588531494141\n",
      "Predicted: [110, 82] Actual: 44 False  7.96753454208374\n",
      "Predicted: [110, 82] Actual: 45 False  7.661427021026611\n",
      "Predicted: [110, 82] Actual: 46 False  7.781426429748535\n",
      "Predicted: [110, 82] Actual: 47 False  7.657502174377441\n",
      "Predicted: [110, 82] Actual: 48 False  7.8004631996154785\n",
      "Predicted: [110, 82] Actual: 49 False  8.174022674560547\n",
      "Predicted: [110, 82] Actual: 50 False  7.972993850708008\n",
      "Predicted: [110, 82] Actual: 51 False  8.22238826751709\n",
      "Predicted: [110, 82] Actual: 52 False  7.714688777923584\n",
      "Predicted: [110, 82] Actual: 53 False  7.86435604095459\n",
      "Predicted: [110, 82] Actual: 54 False  7.652682304382324\n",
      "Predicted: [110, 82] Actual: 55 False  7.588366508483887\n",
      "Predicted: [110, 82] Actual: 56 False  7.472151279449463\n",
      "Predicted: [110, 82] Actual: 57 False  7.675142288208008\n",
      "Predicted: [110, 82] Actual: 58 False  7.52604866027832\n",
      "Predicted: [110, 82] Actual: 59 False  7.557870864868164\n",
      "Predicted: [110, 82] Actual: 60 False  7.539427280426025\n",
      "Predicted: [110, 82] Actual: 61 False  7.994426727294922\n",
      "Predicted: [110, 82] Actual: 62 False  7.704221725463867\n",
      "Predicted: [110, 82] Actual: 63 False  7.617399215698242\n",
      "Predicted: [110, 82] Actual: 64 False  7.619932174682617\n",
      "Predicted: [110, 82] Actual: 65 False  7.861560821533203\n",
      "Predicted: [110]   Actual: 66 False  8.83370304107666\n",
      "Predicted: [110]   Actual: 67 False  8.848340034484863\n",
      "Predicted: [110, 82] Actual: 68 False  8.162062644958496\n",
      "Predicted: [110, 82] Actual: 69 False  7.695129871368408\n",
      "Predicted: [110, 82] Actual: 70 False  7.9059224128723145\n",
      "Predicted: [110, 82] Actual: 71 False  7.844359397888184\n",
      "Predicted: [110, 82] Actual: 72 False  7.623171806335449\n",
      "Predicted: [110, 82] Actual: 73 False  7.862438201904297\n",
      "Predicted: [110, 82] Actual: 74 False  8.024114608764648\n",
      "Predicted: [110, 82] Actual: 75 False  7.997787952423096\n",
      "Predicted: [110, 82] Actual: 76 False  7.520071983337402\n",
      "Predicted: [110, 82] Actual: 77 False  7.504127502441406\n",
      "Predicted: [110, 82] Actual: 78 False  7.816647052764893\n",
      "Predicted: [110, 82] Actual: 79 False  7.83627986907959\n",
      "Predicted: [110]   Actual: 80 False  9.403131484985352\n",
      "Predicted: [110]   Actual: 81 False  8.835601806640625\n",
      "Predicted: [110]   Actual: 82 False  9.474907875061035\n",
      "Predicted: [110]   Actual: 83 False  8.777605056762695\n",
      "Predicted: [110, 82] Actual: 84 False  7.847390174865723\n",
      "Predicted: [110, 82] Actual: 85 False  7.293923854827881\n",
      "Predicted: [110, 82] Actual: 86 False  7.625913143157959\n",
      "Predicted: [110, 82] Actual: 87 False  7.736047267913818\n",
      "Predicted: [110, 82] Actual: 88 False  7.818599700927734\n",
      "Predicted: [110, 82] Actual: 89 False  7.887703895568848\n",
      "Predicted: [110, 82] Actual: 90 False  7.758293628692627\n",
      "Predicted: [110, 82] Actual: 91 False  7.651650428771973\n",
      "Predicted: [110, 82] Actual: 92 False  7.767923831939697\n",
      "Predicted: [110, 82] Actual: 93 False  7.9950785636901855\n",
      "Predicted: [110, 82] Actual: 94 False  7.267538070678711\n",
      "Predicted: [110]   Actual: 95 False  8.848811149597168\n",
      "Predicted: [110]   Actual: 96 False  9.515057563781738\n",
      "Predicted: [110]   Actual: 97 False  8.294949531555176\n",
      "Predicted: [110, 82] Actual: 98 False  7.935371398925781\n",
      "Predicted: [110, 82] Actual: 99 False  7.652019500732422\n",
      "Predicted: [110, 82] Actual: 100 False  7.866702079772949\n",
      "Predicted: [110]   Actual: 101 False  8.618382453918457\n",
      "Predicted: [110, 82] Actual: 102 False  7.659416198730469\n",
      "Predicted: [110, 82] Actual: 103 False  7.589195251464844\n",
      "Predicted: [110, 82] Actual: 104 False  7.838701248168945\n",
      "Predicted: [110, 82] Actual: 105 False  7.500823020935059\n",
      "Predicted: [110, 82] Actual: 106 False  7.755886554718018\n",
      "Predicted: [110, 82] Actual: 107 False  7.968624114990234\n",
      "Predicted: [110, 82] Actual: 108 False  7.860404968261719\n",
      "Predicted: [110, 82] Actual: 109 False  8.080133438110352\n",
      "Predicted: [110]   Actual: 110 True   16.971487045288086\n",
      "Predicted: [110, 82] Actual: 111 False  7.747152328491211\n",
      "Predicted: [110, 82] Actual: 112 False  7.757184028625488\n",
      "Predicted: [110, 82] Actual: 113 False  7.673875331878662\n",
      "Predicted: [110, 82] Actual: 114 False  7.7438764572143555\n",
      "Predicted: [110, 82] Actual: 115 False  7.6262078285217285\n",
      "Predicted: [110, 82] Actual: 116 False  7.784028053283691\n",
      "Predicted: [110, 82] Actual: 117 False  7.317090034484863\n",
      "Predicted: [110, 82] Actual: 118 False  7.559938430786133\n",
      "Predicted: [110, 82] Actual: 119 False  7.978322982788086\n",
      "Predicted: [110, 82] Actual: 120 False  7.958626747131348\n",
      "Predicted: [110, 82] Actual: 121 False  7.617518901824951\n",
      "Predicted: [110, 82] Actual: 122 False  7.9145660400390625\n",
      "Predicted: [110, 82] Actual: 123 False  7.8821916580200195\n",
      "Predicted: [110, 82] Actual: 124 False  7.632447242736816\n",
      "Predicted: [125]   Actual: 125 True   158.61404418945312\n",
      "Predicted: [110, 82] Actual: 126 False  7.428921699523926\n",
      "Predicted: [110, 82] Actual: 127 False  7.9419145584106445\n",
      "Predicted: [110, 82] Actual: 128 False  7.9295148849487305\n",
      "Predicted: [110, 82] Actual: 129 False  7.814052581787109\n",
      "Predicted: [110, 82] Actual: 130 False  7.651392459869385\n",
      "Predicted: [110, 82] Actual: 131 False  7.553412437438965\n",
      "Predicted: [110, 82] Actual: 132 False  7.4510297775268555\n",
      "Predicted: [110, 82] Actual: 133 False  7.524030685424805\n",
      "Predicted: [110, 82] Actual: 134 False  7.6448469161987305\n",
      "Predicted: [110, 82] Actual: 135 False  7.7481536865234375\n",
      "Predicted: [110, 82] Actual: 136 False  8.121088981628418\n",
      "Predicted: [110, 82] Actual: 137 False  7.424406051635742\n",
      "Predicted: [110, 82] Actual: 138 False  7.708770751953125\n",
      "Predicted: [110, 82] Actual: 139 False  7.6883864402771\n",
      "Predicted: [110, 82] Actual: 140 False  8.25716495513916\n",
      "Predicted: [110]   Actual: 141 False  8.653313636779785\n",
      "Predicted: [110, 82] Actual: 142 False  7.5999345779418945\n",
      "Predicted: [110, 82] Actual: 143 False  7.7046966552734375\n",
      "Predicted: [110, 82] Actual: 144 False  7.604101657867432\n",
      "Predicted: [110, 82] Actual: 145 False  7.776451110839844\n",
      "Predicted: [110, 82] Actual: 146 False  8.135624885559082\n",
      "Predicted: [110, 82] Actual: 147 False  7.834994316101074\n",
      "Predicted: [110, 82] Actual: 148 False  7.927289962768555\n",
      "Predicted: [110, 82] Actual: 149 False  7.746891975402832\n",
      "Predicted: [110, 82] Actual: 150 False  7.700538635253906\n",
      "Predicted: [110, 82] Actual: 151 False  8.042223930358887\n",
      "Predicted: [110, 82] Actual: 152 False  7.846065521240234\n",
      "Predicted: [110, 82] Actual: 153 False  7.902920722961426\n",
      "Predicted: [110, 82] Actual: 154 False  7.797568321228027\n",
      "Predicted: [110, 82] Actual: 155 False  7.497936248779297\n",
      "Predicted: [110, 82] Actual: 156 False  8.229705810546875\n",
      "Predicted: [110, 82] Actual: 157 False  7.7316083908081055\n",
      "Predicted: [110, 82] Actual: 158 False  7.7574357986450195\n",
      "Predicted: [110, 82] Actual: 159 False  7.913471221923828\n",
      "Predicted: [110, 82] Actual: 160 False  7.659785747528076\n",
      "Predicted: [110, 82] Actual: 161 False  7.792925834655762\n",
      "Predicted: [110, 82] Actual: 162 False  7.507534980773926\n",
      "Predicted: [110, 82] Actual: 163 False  7.719915390014648\n",
      "Predicted: [110, 82] Actual: 164 False  8.013643264770508\n",
      "Predicted: [110, 82] Actual: 165 False  7.843561172485352\n",
      "Predicted: [110, 82] Actual: 166 False  7.650459289550781\n",
      "Predicted: [110, 82] Actual: 167 False  7.595597743988037\n",
      "Predicted: [110, 125] Actual: 168 False  7.569401741027832\n",
      "Predicted: [110, 82] Actual: 169 False  7.734410762786865\n",
      "Predicted: [110, 82] Actual: 170 False  8.099149703979492\n",
      "Predicted: [110, 82] Actual: 171 False  7.562648773193359\n",
      "Predicted: [110, 82] Actual: 172 False  8.073709487915039\n",
      "Predicted: [110, 82] Actual: 173 False  7.462888717651367\n",
      "Predicted: [110, 82] Actual: 174 False  7.990566253662109\n",
      "Predicted: [110, 82] Actual: 175 False  7.910619735717773\n",
      "Predicted: [110, 82] Actual: 176 False  7.759964942932129\n",
      "Predicted: [110, 82] Actual: 177 False  7.629559516906738\n",
      "Predicted: [110, 82] Actual: 178 False  8.027641296386719\n",
      "Predicted: [110, 82] Actual: 179 False  7.8593244552612305\n",
      "Predicted: [110, 82] Actual: 180 False  7.640903472900391\n",
      "Predicted: [110, 82] Actual: 181 False  7.851590156555176\n",
      "Predicted: [110, 82] Actual: 182 False  7.682895660400391\n",
      "Predicted: [110, 82] Actual: 183 False  7.377283573150635\n",
      "Predicted: [110, 82] Actual: 184 False  8.018308639526367\n",
      "Predicted: [110, 82] Actual: 185 False  7.604936122894287\n",
      "Predicted: [110, 82] Actual: 186 False  8.244568824768066\n",
      "Predicted: [110, 82] Actual: 187 False  7.761932373046875\n",
      "Predicted: [110, 82] Actual: 188 False  8.020975112915039\n",
      "Predicted: [110, 82] Actual: 189 False  7.691849708557129\n",
      "Predicted: [110, 82] Actual: 190 False  7.775125503540039\n",
      "Predicted: [110, 82] Actual: 191 False  7.469544887542725\n",
      "Predicted: [110, 82] Actual: 192 False  7.979654312133789\n",
      "Predicted: [110, 82] Actual: 193 False  7.594934940338135\n",
      "Predicted: [110, 82] Actual: 194 False  7.915003776550293\n",
      "Predicted: [110, 82] Actual: 195 False  8.076417922973633\n",
      "Predicted: [110, 82] Actual: 196 False  7.624668121337891\n",
      "Predicted: [110, 82] Actual: 197 False  7.8646559715271\n",
      "Predicted: [110, 82] Actual: 198 False  7.827983379364014\n",
      "Predicted: [110, 82] Actual: 199 False  7.767134666442871\n",
      "Predicted: [110, 82] Actual: 200 False  7.632622241973877\n",
      "Predicted: [110, 82] Actual: 201 False  7.84967565536499\n",
      "Predicted: [110, 82] Actual: 202 False  7.825401306152344\n",
      "Predicted: [110, 82] Actual: 203 False  7.808169841766357\n",
      "Predicted: [110, 82] Actual: 204 False  7.599366664886475\n",
      "Predicted: [110, 82] Actual: 205 False  7.691547393798828\n",
      "Predicted: [110, 82] Actual: 206 False  7.47746467590332\n",
      "Predicted: [110, 82] Actual: 207 False  7.934391498565674\n",
      "Predicted: [110, 82] Actual: 208 False  7.663639068603516\n",
      "Predicted: [110, 82] Actual: 209 False  7.931178092956543\n",
      "Predicted: [110, 82] Actual: 210 False  7.83173942565918\n",
      "Predicted: [110, 82] Actual: 211 False  7.790764808654785\n",
      "Predicted: [110, 82] Actual: 212 False  7.682311058044434\n",
      "Predicted: [110, 82] Actual: 213 False  7.584708213806152\n",
      "Predicted: [110, 82] Actual: 214 False  7.769804000854492\n",
      "Predicted: [110, 82] Actual: 215 False  7.7884721755981445\n",
      "Predicted: [110, 82] Actual: 216 False  7.7211761474609375\n",
      "Predicted: [110, 82] Actual: 217 False  7.7450151443481445\n",
      "Predicted: [110, 82] Actual: 218 False  7.836499214172363\n",
      "Predicted: [110, 82] Actual: 219 False  7.686870098114014\n",
      "Predicted: [110, 82] Actual: 220 False  7.612733364105225\n",
      "Predicted: [110, 82] Actual: 221 False  7.710846424102783\n",
      "Predicted: [110, 82] Actual: 222 False  7.787324905395508\n",
      "Predicted: [110, 82] Actual: 223 False  8.251111030578613\n",
      "Predicted: [110, 82] Actual: 224 False  7.792158126831055\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.470558  [   64/ 8532]\n",
      "loss: 1.598819  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3166  size: 5689  main correct/size: 0.556512568113904\n",
      "Also correct: 947  size: 5689  also correct/size: 0.16646159254702056\n",
      "Test Error: Accuracy: 72.3%, Avg loss: 2.001823\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.652189  [   64/ 8532]\n",
      "loss: 1.598789  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3167  size: 5689  main correct/size: 0.5566883459307436\n",
      "Also correct: 952  size: 5689  also correct/size: 0.16734048163121815\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 2.002517\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.653996  [   64/ 8532]\n",
      "loss: 1.598240  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3167  size: 5689  main correct/size: 0.5566883459307436\n",
      "Also correct: 953  size: 5689  also correct/size: 0.16751625944805765\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 2.002959\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.654429  [   64/ 8532]\n",
      "loss: 1.597679  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3167  size: 5689  main correct/size: 0.5566883459307436\n",
      "Also correct: 952  size: 5689  also correct/size: 0.16734048163121815\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 2.003220\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.654428  [   64/ 8532]\n",
      "loss: 1.597097  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3167  size: 5689  main correct/size: 0.5566883459307436\n",
      "Also correct: 952  size: 5689  also correct/size: 0.16734048163121815\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 2.003387\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 125] Actual: 0  False  7.589550018310547\n",
      "Predicted: [110, 82] Actual: 1  False  7.9509429931640625\n",
      "Predicted: [110, 82] Actual: 2  False  7.949584484100342\n",
      "Predicted: [110, 82] Actual: 3  False  7.37501335144043\n",
      "Predicted: [110, 125] Actual: 4  False  7.575408935546875\n",
      "Predicted: [110, 82] Actual: 5  False  7.527284622192383\n",
      "Predicted: [110, 82] Actual: 6  False  7.949854373931885\n",
      "Predicted: [110, 82] Actual: 7  False  7.883426666259766\n",
      "Predicted: [110, 82] Actual: 8  False  7.618728160858154\n",
      "Predicted: [110, 82] Actual: 9  False  7.551816940307617\n",
      "Predicted: [110, 82] Actual: 10 False  8.053930282592773\n",
      "Predicted: [110, 82] Actual: 11 False  7.788360595703125\n",
      "Predicted: [110, 82] Actual: 12 False  7.987855911254883\n",
      "Predicted: [110, 82] Actual: 13 False  7.684659004211426\n",
      "Predicted: [110, 82] Actual: 14 False  7.643525123596191\n",
      "Predicted: [110, 82] Actual: 15 False  7.564823627471924\n",
      "Predicted: [110, 82] Actual: 16 False  7.872470855712891\n",
      "Predicted: [110, 82] Actual: 17 False  7.555006504058838\n",
      "Predicted: [110, 82] Actual: 18 False  7.491912841796875\n",
      "Predicted: [110, 82] Actual: 19 False  7.6989617347717285\n",
      "Predicted: [110, 82] Actual: 20 False  7.778499603271484\n",
      "Predicted: [110, 125] Actual: 21 False  7.7646613121032715\n",
      "Predicted: [110, 125] Actual: 22 False  7.516663074493408\n",
      "Predicted: [110, 82] Actual: 23 False  7.751125812530518\n",
      "Predicted: [110, 125] Actual: 24 False  7.315056800842285\n",
      "Predicted: [125, 110] Actual: 25 False  8.150394439697266\n",
      "Predicted: [110, 82] Actual: 26 False  7.765840530395508\n",
      "Predicted: [110, 82] Actual: 27 False  7.7412943840026855\n",
      "Predicted: [110, 82] Actual: 28 False  7.899674415588379\n",
      "Predicted: [110, 82] Actual: 29 False  7.666382789611816\n",
      "Predicted: [110, 125] Actual: 30 False  7.3511962890625\n",
      "Predicted: [110, 125] Actual: 31 False  7.58926248550415\n",
      "Predicted: [110, 82] Actual: 32 False  7.613942623138428\n",
      "Predicted: [110, 125] Actual: 33 False  7.833616256713867\n",
      "Predicted: [110, 82] Actual: 34 False  7.750761032104492\n",
      "Predicted: [110, 82] Actual: 35 False  7.748631954193115\n",
      "Predicted: [110, 82] Actual: 36 False  8.075986862182617\n",
      "Predicted: [125, 110] Actual: 37 False  8.061537742614746\n",
      "Predicted: [110, 82] Actual: 38 False  7.889576435089111\n",
      "Predicted: [110, 82] Actual: 39 False  7.979084014892578\n",
      "Predicted: [110, 82] Actual: 40 False  7.799549102783203\n",
      "Predicted: [110, 82] Actual: 41 False  7.934731483459473\n",
      "Predicted: [110, 125] Actual: 42 False  7.713660717010498\n",
      "Predicted: [110, 125] Actual: 43 False  7.676562309265137\n",
      "Predicted: [110, 82] Actual: 44 False  7.893399238586426\n",
      "Predicted: [110, 125] Actual: 45 False  7.61513614654541\n",
      "Predicted: [110, 82] Actual: 46 False  7.721988677978516\n",
      "Predicted: [110, 82] Actual: 47 False  7.576020240783691\n",
      "Predicted: [110, 82] Actual: 48 False  7.7244648933410645\n",
      "Predicted: [110, 82] Actual: 49 False  8.051918029785156\n",
      "Predicted: [110, 82] Actual: 50 False  7.885361671447754\n",
      "Predicted: [110, 82] Actual: 51 False  8.094685554504395\n",
      "Predicted: [110, 82] Actual: 52 False  7.615260124206543\n",
      "Predicted: [110, 82] Actual: 53 False  7.743383407592773\n",
      "Predicted: [125, 110] Actual: 54 False  8.026321411132812\n",
      "Predicted: [110, 82] Actual: 55 False  7.506093502044678\n",
      "Predicted: [110, 125] Actual: 56 False  7.39140510559082\n",
      "Predicted: [110, 82] Actual: 57 False  7.600190162658691\n",
      "Predicted: [110, 125] Actual: 58 False  7.448777198791504\n",
      "Predicted: [110, 82] Actual: 59 False  7.4773945808410645\n",
      "Predicted: [110, 125] Actual: 60 False  7.4571614265441895\n",
      "Predicted: [110, 82] Actual: 61 False  7.923630237579346\n",
      "Predicted: [110, 82] Actual: 62 False  7.62520694732666\n",
      "Predicted: [110, 125] Actual: 63 False  7.545352935791016\n",
      "Predicted: [110, 82] Actual: 64 False  7.536863327026367\n",
      "Predicted: [110, 82] Actual: 65 False  7.8034844398498535\n",
      "Predicted: [110]   Actual: 66 False  8.748481750488281\n",
      "Predicted: [110]   Actual: 67 False  8.737942695617676\n",
      "Predicted: [110, 82] Actual: 68 False  8.061844825744629\n",
      "Predicted: [110, 82] Actual: 69 False  7.591249465942383\n",
      "Predicted: [110, 82] Actual: 70 False  7.841178894042969\n",
      "Predicted: [110, 125] Actual: 71 False  7.781593322753906\n",
      "Predicted: [110, 125] Actual: 72 False  7.552977561950684\n",
      "Predicted: [110, 82] Actual: 73 False  7.771388053894043\n",
      "Predicted: [110, 82] Actual: 74 False  7.945222854614258\n",
      "Predicted: [110, 82] Actual: 75 False  7.904574394226074\n",
      "Predicted: [110, 125] Actual: 76 False  7.435765266418457\n",
      "Predicted: [110, 82] Actual: 77 False  7.408025741577148\n",
      "Predicted: [110, 82] Actual: 78 False  7.741032600402832\n",
      "Predicted: [110, 82] Actual: 79 False  7.7536115646362305\n",
      "Predicted: [110]   Actual: 80 False  9.379677772521973\n",
      "Predicted: [110]   Actual: 81 False  8.754897117614746\n",
      "Predicted: [110]   Actual: 82 False  9.446249961853027\n",
      "Predicted: [110]   Actual: 83 False  8.697137832641602\n",
      "Predicted: [110, 82] Actual: 84 False  7.740535736083984\n",
      "Predicted: [110, 82] Actual: 85 False  7.187010765075684\n",
      "Predicted: [110, 82] Actual: 86 False  7.5542449951171875\n",
      "Predicted: [110, 82] Actual: 87 False  7.608377456665039\n",
      "Predicted: [110, 82] Actual: 88 False  7.712602615356445\n",
      "Predicted: [110, 82] Actual: 89 False  7.822464942932129\n",
      "Predicted: [110, 82] Actual: 90 False  7.684504508972168\n",
      "Predicted: [110, 82] Actual: 91 False  7.575437545776367\n",
      "Predicted: [110, 82] Actual: 92 False  7.691948890686035\n",
      "Predicted: [110, 82] Actual: 93 False  7.936354160308838\n",
      "Predicted: [125, 110] Actual: 94 False  8.144072532653809\n",
      "Predicted: [110]   Actual: 95 False  8.773543357849121\n",
      "Predicted: [110]   Actual: 96 False  9.494327545166016\n",
      "Predicted: [110]   Actual: 97 False  8.20426082611084\n",
      "Predicted: [110, 82] Actual: 98 False  7.871325492858887\n",
      "Predicted: [110, 82] Actual: 99 False  7.565536975860596\n",
      "Predicted: [110, 82] Actual: 100 False  7.768260478973389\n",
      "Predicted: [110]   Actual: 101 False  8.530882835388184\n",
      "Predicted: [110, 82] Actual: 102 False  7.567485809326172\n",
      "Predicted: [110, 82] Actual: 103 False  7.5192060470581055\n",
      "Predicted: [110, 125] Actual: 104 False  7.775824546813965\n",
      "Predicted: [110, 125] Actual: 105 False  7.421992301940918\n",
      "Predicted: [110, 82] Actual: 106 False  7.681643962860107\n",
      "Predicted: [110, 82] Actual: 107 False  7.8989973068237305\n",
      "Predicted: [110, 82] Actual: 108 False  7.787271499633789\n",
      "Predicted: [110, 82] Actual: 109 False  7.969265937805176\n",
      "Predicted: [110]   Actual: 110 True   17.36750602722168\n",
      "Predicted: [110, 82] Actual: 111 False  7.6110005378723145\n",
      "Predicted: [110, 125] Actual: 112 False  7.6816020011901855\n",
      "Predicted: [110, 82] Actual: 113 False  7.604679107666016\n",
      "Predicted: [110, 82] Actual: 114 False  7.641284942626953\n",
      "Predicted: [110, 82] Actual: 115 False  7.52422571182251\n",
      "Predicted: [110, 82] Actual: 116 False  7.691779136657715\n",
      "Predicted: [125, 110] Actual: 117 False  7.3676533699035645\n",
      "Predicted: [110, 82] Actual: 118 False  7.465632915496826\n",
      "Predicted: [110, 82] Actual: 119 False  7.9268717765808105\n",
      "Predicted: [110, 82] Actual: 120 False  7.891204833984375\n",
      "Predicted: [110, 125] Actual: 121 False  7.537715435028076\n",
      "Predicted: [110, 82] Actual: 122 False  7.814431190490723\n",
      "Predicted: [110, 82] Actual: 123 False  7.81207275390625\n",
      "Predicted: [110, 82] Actual: 124 False  7.516291618347168\n",
      "Predicted: [125]   Actual: 125 True   160.639892578125\n",
      "Predicted: [110, 82] Actual: 126 False  7.290955543518066\n",
      "Predicted: [110, 82] Actual: 127 False  7.840606689453125\n",
      "Predicted: [110, 82] Actual: 128 False  7.871600151062012\n",
      "Predicted: [110, 82] Actual: 129 False  7.744111061096191\n",
      "Predicted: [110, 82] Actual: 130 False  7.574873924255371\n",
      "Predicted: [110, 125] Actual: 131 False  7.473397731781006\n",
      "Predicted: [110, 82] Actual: 132 False  7.354058265686035\n",
      "Predicted: [125, 110] Actual: 133 False  7.880868911743164\n",
      "Predicted: [110, 125] Actual: 134 False  7.572659969329834\n",
      "Predicted: [110, 82] Actual: 135 False  7.67215633392334\n",
      "Predicted: [110, 82] Actual: 136 False  8.060129165649414\n",
      "Predicted: [125, 110] Actual: 137 False  8.595520973205566\n",
      "Predicted: [125, 110] Actual: 138 False  8.017093658447266\n",
      "Predicted: [110, 82] Actual: 139 False  7.612813949584961\n",
      "Predicted: [110, 82] Actual: 140 False  8.156132698059082\n",
      "Predicted: [110]   Actual: 141 False  8.582951545715332\n",
      "Predicted: [110, 82] Actual: 142 False  7.502949237823486\n",
      "Predicted: [110, 82] Actual: 143 False  7.633094310760498\n",
      "Predicted: [110, 125] Actual: 144 False  7.519874572753906\n",
      "Predicted: [110, 82] Actual: 145 False  7.71622371673584\n",
      "Predicted: [110, 125] Actual: 146 False  8.093396186828613\n",
      "Predicted: [125, 110] Actual: 147 False  8.145821571350098\n",
      "Predicted: [110, 82] Actual: 148 False  7.845890522003174\n",
      "Predicted: [110, 125] Actual: 149 False  7.676177024841309\n",
      "Predicted: [110, 82] Actual: 150 False  7.623456954956055\n",
      "Predicted: [110, 82] Actual: 151 False  7.96543025970459\n",
      "Predicted: [110, 125] Actual: 152 False  7.778999328613281\n",
      "Predicted: [110, 82] Actual: 153 False  7.835808753967285\n",
      "Predicted: [110, 82] Actual: 154 False  7.705082893371582\n",
      "Predicted: [110, 125] Actual: 155 False  7.417707443237305\n",
      "Predicted: [110, 82] Actual: 156 False  8.12888240814209\n",
      "Predicted: [110, 82] Actual: 157 False  7.597506999969482\n",
      "Predicted: [110, 82] Actual: 158 False  7.658525466918945\n",
      "Predicted: [110, 82] Actual: 159 False  7.838315486907959\n",
      "Predicted: [110, 82] Actual: 160 False  7.583797931671143\n",
      "Predicted: [125, 110] Actual: 161 False  8.020430564880371\n",
      "Predicted: [110, 125] Actual: 162 False  7.421435356140137\n",
      "Predicted: [110, 125] Actual: 163 False  7.650215148925781\n",
      "Predicted: [110, 82] Actual: 164 False  7.945765972137451\n",
      "Predicted: [110, 82] Actual: 165 False  7.778467178344727\n",
      "Predicted: [110, 125] Actual: 166 False  7.57235050201416\n",
      "Predicted: [110, 82] Actual: 167 False  7.513684272766113\n",
      "Predicted: [125, 110] Actual: 168 False  9.0648832321167\n",
      "Predicted: [110, 82] Actual: 169 False  7.656101226806641\n",
      "Predicted: [110, 82] Actual: 170 False  8.022419929504395\n",
      "Predicted: [110, 82] Actual: 171 False  7.470492839813232\n",
      "Predicted: [110, 82] Actual: 172 False  7.955192565917969\n",
      "Predicted: [110, 82] Actual: 173 False  7.343725204467773\n",
      "Predicted: [110, 82] Actual: 174 False  7.908702850341797\n",
      "Predicted: [110, 125] Actual: 175 False  7.848151683807373\n",
      "Predicted: [110, 82] Actual: 176 False  7.667688369750977\n",
      "Predicted: [110, 82] Actual: 177 False  7.544663429260254\n",
      "Predicted: [110, 82] Actual: 178 False  7.961306571960449\n",
      "Predicted: [110, 82] Actual: 179 False  7.78764533996582\n",
      "Predicted: [110, 82] Actual: 180 False  7.564914703369141\n",
      "Predicted: [110, 82] Actual: 181 False  7.778076171875\n",
      "Predicted: [110, 82] Actual: 182 False  7.6034464836120605\n",
      "Predicted: [110, 82] Actual: 183 False  7.2882819175720215\n",
      "Predicted: [110, 82] Actual: 184 False  7.940546035766602\n",
      "Predicted: [110, 82] Actual: 185 False  7.525437831878662\n",
      "Predicted: [110, 82] Actual: 186 False  8.168549537658691\n",
      "Predicted: [110, 82] Actual: 187 False  7.619146347045898\n",
      "Predicted: [110, 82] Actual: 188 False  7.93972110748291\n",
      "Predicted: [110, 82] Actual: 189 False  7.601799011230469\n",
      "Predicted: [110, 82] Actual: 190 False  7.716200828552246\n",
      "Predicted: [125, 110] Actual: 191 False  8.277645111083984\n",
      "Predicted: [110, 82] Actual: 192 False  7.900407791137695\n",
      "Predicted: [110, 125] Actual: 193 False  7.526598930358887\n",
      "Predicted: [110, 82] Actual: 194 False  7.818018913269043\n",
      "Predicted: [110, 82] Actual: 195 False  8.009858131408691\n",
      "Predicted: [110, 125] Actual: 196 False  7.553464889526367\n",
      "Predicted: [110, 125] Actual: 197 False  7.811779022216797\n",
      "Predicted: [110, 125] Actual: 198 False  7.761804580688477\n",
      "Predicted: [110, 82] Actual: 199 False  7.69813346862793\n",
      "Predicted: [110, 82] Actual: 200 False  7.531916618347168\n",
      "Predicted: [110, 82] Actual: 201 False  7.777905464172363\n",
      "Predicted: [110, 125] Actual: 202 False  7.756967067718506\n",
      "Predicted: [110, 82] Actual: 203 False  7.702686309814453\n",
      "Predicted: [110, 125] Actual: 204 False  7.545352935791016\n",
      "Predicted: [110, 82] Actual: 205 False  7.598392486572266\n",
      "Predicted: [110, 82] Actual: 206 False  7.389890670776367\n",
      "Predicted: [110, 82] Actual: 207 False  7.867841720581055\n",
      "Predicted: [110, 125] Actual: 208 False  7.588374137878418\n",
      "Predicted: [110, 82] Actual: 209 False  7.86495304107666\n",
      "Predicted: [110, 82] Actual: 210 False  7.76366662979126\n",
      "Predicted: [110, 82] Actual: 211 False  7.714327335357666\n",
      "Predicted: [110, 82] Actual: 212 False  7.60394287109375\n",
      "Predicted: [110, 82] Actual: 213 False  7.505053520202637\n",
      "Predicted: [110, 82] Actual: 214 False  7.691955089569092\n",
      "Predicted: [110, 82] Actual: 215 False  7.714146137237549\n",
      "Predicted: [110, 82] Actual: 216 False  7.650765895843506\n",
      "Predicted: [110, 125] Actual: 217 False  7.678678035736084\n",
      "Predicted: [110, 82] Actual: 218 False  7.776599884033203\n",
      "Predicted: [110, 125] Actual: 219 False  7.596042633056641\n",
      "Predicted: [110, 82] Actual: 220 False  7.544345855712891\n",
      "Predicted: [110, 82] Actual: 221 False  7.63741397857666\n",
      "Predicted: [110, 82] Actual: 222 False  7.712955474853516\n",
      "Predicted: [110, 82] Actual: 223 False  8.159231185913086\n",
      "Predicted: [110, 82] Actual: 224 False  7.724645614624023\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.921576  [   64/ 8532]\n",
      "loss: 1.768490  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3138  size: 5689  main correct/size: 0.5515907892423976\n",
      "Also correct: 968  size: 5689  also correct/size: 0.17015292670065038\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.998637\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.870843  [   64/ 8532]\n",
      "loss: 1.767067  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3138  size: 5689  main correct/size: 0.5515907892423976\n",
      "Also correct: 967  size: 5689  also correct/size: 0.16997714888381085\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999160\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.870343  [   64/ 8532]\n",
      "loss: 1.765994  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3139  size: 5689  main correct/size: 0.5517665670592371\n",
      "Also correct: 966  size: 5689  also correct/size: 0.16980137106697135\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999393\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.869875  [   64/ 8532]\n",
      "loss: 1.765217  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3140  size: 5689  main correct/size: 0.5519423448760766\n",
      "Also correct: 965  size: 5689  also correct/size: 0.16962559325013182\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999486\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.869472  [   64/ 8532]\n",
      "loss: 1.764636  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3140  size: 5689  main correct/size: 0.5519423448760766\n",
      "Also correct: 965  size: 5689  also correct/size: 0.16962559325013182\n",
      "Test Error: Accuracy: 72.2%, Avg loss: 1.999501\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 125] Actual: 0  False  7.694601535797119\n",
      "Predicted: [110, 82] Actual: 1  False  8.059127807617188\n",
      "Predicted: [110, 82] Actual: 2  False  8.053628921508789\n",
      "Predicted: [110, 82] Actual: 3  False  7.458047389984131\n",
      "Predicted: [110, 82] Actual: 4  False  7.668667316436768\n",
      "Predicted: [110, 82] Actual: 5  False  7.622092247009277\n",
      "Predicted: [110, 82] Actual: 6  False  8.055269241333008\n",
      "Predicted: [110, 82] Actual: 7  False  7.988522529602051\n",
      "Predicted: [110, 82] Actual: 8  False  7.71133279800415\n",
      "Predicted: [110, 82] Actual: 9  False  7.640929222106934\n",
      "Predicted: [110, 82] Actual: 10 False  8.163066864013672\n",
      "Predicted: [110, 82] Actual: 11 False  7.887767314910889\n",
      "Predicted: [110, 82] Actual: 12 False  8.097949028015137\n",
      "Predicted: [110, 82] Actual: 13 False  7.780064105987549\n",
      "Predicted: [110, 82] Actual: 14 False  7.737990379333496\n",
      "Predicted: [110, 82] Actual: 15 False  7.662588596343994\n",
      "Predicted: [110, 82] Actual: 16 False  7.964218616485596\n",
      "Predicted: [110, 82] Actual: 17 False  7.641835689544678\n",
      "Predicted: [110, 82] Actual: 18 False  7.583887577056885\n",
      "Predicted: [110, 82] Actual: 19 False  7.795531749725342\n",
      "Predicted: [110, 82] Actual: 20 False  7.8771820068359375\n",
      "Predicted: [110, 82] Actual: 21 False  7.867772579193115\n",
      "Predicted: [110, 125] Actual: 22 False  7.602860927581787\n",
      "Predicted: [110, 82] Actual: 23 False  7.84873628616333\n",
      "Predicted: [110, 125] Actual: 24 False  7.4064459800720215\n",
      "Predicted: [125, 110] Actual: 25 False  7.668859481811523\n",
      "Predicted: [110, 82] Actual: 26 False  7.865585803985596\n",
      "Predicted: [110, 82] Actual: 27 False  7.838050365447998\n",
      "Predicted: [110, 82] Actual: 28 False  8.00035572052002\n",
      "Predicted: [110, 82] Actual: 29 False  7.76379919052124\n",
      "Predicted: [110, 82] Actual: 30 False  7.437556743621826\n",
      "Predicted: [110, 82] Actual: 31 False  7.678359508514404\n",
      "Predicted: [110, 82] Actual: 32 False  7.71629524230957\n",
      "Predicted: [110, 125] Actual: 33 False  7.937851428985596\n",
      "Predicted: [110, 82] Actual: 34 False  7.862411975860596\n",
      "Predicted: [110, 82] Actual: 35 False  7.84540319442749\n",
      "Predicted: [110, 82] Actual: 36 False  8.148571014404297\n",
      "Predicted: [110, 125] Actual: 37 False  7.67350435256958\n",
      "Predicted: [110, 82] Actual: 38 False  7.988946437835693\n",
      "Predicted: [110, 82] Actual: 39 False  8.087526321411133\n",
      "Predicted: [110, 82] Actual: 40 False  7.900847911834717\n",
      "Predicted: [110, 82] Actual: 41 False  8.038601875305176\n",
      "Predicted: [110, 125] Actual: 42 False  7.810229301452637\n",
      "Predicted: [110, 125] Actual: 43 False  7.767402648925781\n",
      "Predicted: [110, 82] Actual: 44 False  7.997230052947998\n",
      "Predicted: [110, 82] Actual: 45 False  7.723406791687012\n",
      "Predicted: [110, 82] Actual: 46 False  7.835481643676758\n",
      "Predicted: [110, 82] Actual: 47 False  7.664351940155029\n",
      "Predicted: [110, 82] Actual: 48 False  7.83206033706665\n",
      "Predicted: [110, 82] Actual: 49 False  8.129343032836914\n",
      "Predicted: [110, 82] Actual: 50 False  7.978912353515625\n",
      "Predicted: [110]   Actual: 51 False  8.21108627319336\n",
      "Predicted: [110, 82] Actual: 52 False  7.721348285675049\n",
      "Predicted: [110, 82] Actual: 53 False  7.827717304229736\n",
      "Predicted: [110, 125] Actual: 54 False  7.676850318908691\n",
      "Predicted: [110, 82] Actual: 55 False  7.597481727600098\n",
      "Predicted: [110, 82] Actual: 56 False  7.476047515869141\n",
      "Predicted: [110, 82] Actual: 57 False  7.695916652679443\n",
      "Predicted: [110, 125] Actual: 58 False  7.5376410484313965\n",
      "Predicted: [110, 82] Actual: 59 False  7.570322036743164\n",
      "Predicted: [110, 82] Actual: 60 False  7.54664945602417\n",
      "Predicted: [110, 82] Actual: 61 False  8.02397632598877\n",
      "Predicted: [110, 82] Actual: 62 False  7.717299938201904\n",
      "Predicted: [110, 82] Actual: 63 False  7.6402435302734375\n",
      "Predicted: [110, 82] Actual: 64 False  7.6228346824646\n",
      "Predicted: [110, 82] Actual: 65 False  7.905874729156494\n",
      "Predicted: [110]   Actual: 66 False  8.870173454284668\n",
      "Predicted: [110]   Actual: 67 False  8.844640731811523\n",
      "Predicted: [110]   Actual: 68 False  8.209383010864258\n",
      "Predicted: [110, 82] Actual: 69 False  7.688859462738037\n",
      "Predicted: [110, 82] Actual: 70 False  7.948474884033203\n",
      "Predicted: [110, 125] Actual: 71 False  7.885041236877441\n",
      "Predicted: [110, 82] Actual: 72 False  7.654489517211914\n",
      "Predicted: [110, 82] Actual: 73 False  7.861083507537842\n",
      "Predicted: [110, 82] Actual: 74 False  8.04978084564209\n",
      "Predicted: [110, 82] Actual: 75 False  8.008734703063965\n",
      "Predicted: [110, 82] Actual: 76 False  7.521856784820557\n",
      "Predicted: [110, 82] Actual: 77 False  7.496308326721191\n",
      "Predicted: [110, 82] Actual: 78 False  7.839849948883057\n",
      "Predicted: [110, 82] Actual: 79 False  7.828758716583252\n",
      "Predicted: [110]   Actual: 80 False  9.516073226928711\n",
      "Predicted: [110]   Actual: 81 False  8.876087188720703\n",
      "Predicted: [110]   Actual: 82 False  9.575977325439453\n",
      "Predicted: [110]   Actual: 83 False  8.788455963134766\n",
      "Predicted: [110, 82] Actual: 84 False  7.792705059051514\n",
      "Predicted: [110, 82] Actual: 85 False  7.263844013214111\n",
      "Predicted: [110, 82] Actual: 86 False  7.6482367515563965\n",
      "Predicted: [110, 82] Actual: 87 False  7.675631046295166\n",
      "Predicted: [110, 82] Actual: 88 False  7.799006938934326\n",
      "Predicted: [110, 82] Actual: 89 False  7.920956134796143\n",
      "Predicted: [110, 82] Actual: 90 False  7.783353328704834\n",
      "Predicted: [110, 82] Actual: 91 False  7.668167591094971\n",
      "Predicted: [110, 82] Actual: 92 False  7.791279315948486\n",
      "Predicted: [110, 82] Actual: 93 False  8.04344654083252\n",
      "Predicted: [125, 110] Actual: 94 False  7.533007621765137\n",
      "Predicted: [110]   Actual: 95 False  8.91471004486084\n",
      "Predicted: [110]   Actual: 96 False  9.617914199829102\n",
      "Predicted: [110]   Actual: 97 False  8.322463989257812\n",
      "Predicted: [110, 82] Actual: 98 False  7.986328601837158\n",
      "Predicted: [110, 82] Actual: 99 False  7.654203414916992\n",
      "Predicted: [110, 82] Actual: 100 False  7.863194465637207\n",
      "Predicted: [110]   Actual: 101 False  8.66515064239502\n",
      "Predicted: [110, 82] Actual: 102 False  7.656820774078369\n",
      "Predicted: [110, 82] Actual: 103 False  7.603390693664551\n",
      "Predicted: [110, 82] Actual: 104 False  7.871822834014893\n",
      "Predicted: [110, 82] Actual: 105 False  7.509761810302734\n",
      "Predicted: [110, 82] Actual: 106 False  7.778062343597412\n",
      "Predicted: [110, 82] Actual: 107 False  8.004460334777832\n",
      "Predicted: [110, 82] Actual: 108 False  7.893528461456299\n",
      "Predicted: [110]   Actual: 109 False  8.088351249694824\n",
      "Predicted: [110]   Actual: 110 True   17.900957107543945\n",
      "Predicted: [110, 82] Actual: 111 False  7.695099830627441\n",
      "Predicted: [110, 82] Actual: 112 False  7.776703834533691\n",
      "Predicted: [110, 82] Actual: 113 False  7.709792613983154\n",
      "Predicted: [110, 82] Actual: 114 False  7.70780611038208\n",
      "Predicted: [110, 82] Actual: 115 False  7.6299028396606445\n",
      "Predicted: [110, 82] Actual: 116 False  7.782707691192627\n",
      "Predicted: [110, 125] Actual: 117 False  7.306288242340088\n",
      "Predicted: [110, 82] Actual: 118 False  7.539382457733154\n",
      "Predicted: [110, 82] Actual: 119 False  8.036498069763184\n",
      "Predicted: [110, 82] Actual: 120 False  7.99447774887085\n",
      "Predicted: [110, 82] Actual: 121 False  7.629526615142822\n",
      "Predicted: [110, 82] Actual: 122 False  7.917618751525879\n",
      "Predicted: [110, 82] Actual: 123 False  7.912916660308838\n",
      "Predicted: [110, 82] Actual: 124 False  7.571450710296631\n",
      "Predicted: [125]   Actual: 125 True   161.1560516357422\n",
      "Predicted: [110, 82] Actual: 126 False  7.371495723724365\n",
      "Predicted: [110, 82] Actual: 127 False  7.934906005859375\n",
      "Predicted: [110, 82] Actual: 128 False  7.977787017822266\n",
      "Predicted: [110, 82] Actual: 129 False  7.848474025726318\n",
      "Predicted: [110, 82] Actual: 130 False  7.665542125701904\n",
      "Predicted: [110, 82] Actual: 131 False  7.547510147094727\n",
      "Predicted: [110, 82] Actual: 132 False  7.4390997886657715\n",
      "Predicted: [125, 110] Actual: 133 False  7.541913986206055\n",
      "Predicted: [110, 82] Actual: 134 False  7.667012691497803\n",
      "Predicted: [110, 82] Actual: 135 False  7.766708850860596\n",
      "Predicted: [110, 82] Actual: 136 False  8.169046401977539\n",
      "Predicted: [125, 110] Actual: 137 False  8.118210792541504\n",
      "Predicted: [110, 125] Actual: 138 False  7.741272449493408\n",
      "Predicted: [110, 82] Actual: 139 False  7.712276458740234\n",
      "Predicted: [110, 82] Actual: 140 False  8.247983932495117\n",
      "Predicted: [110]   Actual: 141 False  8.709123611450195\n",
      "Predicted: [110, 82] Actual: 142 False  7.569359302520752\n",
      "Predicted: [110, 82] Actual: 143 False  7.723433017730713\n",
      "Predicted: [110, 125] Actual: 144 False  7.627791881561279\n",
      "Predicted: [110, 82] Actual: 145 False  7.8067450523376465\n",
      "Predicted: [110, 82] Actual: 146 False  8.214956283569336\n",
      "Predicted: [110, 125] Actual: 147 False  7.849305629730225\n",
      "Predicted: [110, 82] Actual: 148 False  7.951548099517822\n",
      "Predicted: [110, 125] Actual: 149 False  7.774799823760986\n",
      "Predicted: [110, 82] Actual: 150 False  7.7180609703063965\n",
      "Predicted: [110, 82] Actual: 151 False  8.06869888305664\n",
      "Predicted: [110, 125] Actual: 152 False  7.878513813018799\n",
      "Predicted: [110, 82] Actual: 153 False  7.938961505889893\n",
      "Predicted: [110, 82] Actual: 154 False  7.798821926116943\n",
      "Predicted: [110, 125] Actual: 155 False  7.513919353485107\n",
      "Predicted: [110, 82] Actual: 156 False  8.26519775390625\n",
      "Predicted: [110, 82] Actual: 157 False  7.682831287384033\n",
      "Predicted: [110, 82] Actual: 158 False  7.757019519805908\n",
      "Predicted: [110, 82] Actual: 159 False  7.937678813934326\n",
      "Predicted: [110, 82] Actual: 160 False  7.679783344268799\n",
      "Predicted: [110, 125] Actual: 161 False  7.844117641448975\n",
      "Predicted: [110, 125] Actual: 162 False  7.505731105804443\n",
      "Predicted: [110, 82] Actual: 163 False  7.74805212020874\n",
      "Predicted: [110, 82] Actual: 164 False  8.052892684936523\n",
      "Predicted: [110, 82] Actual: 165 False  7.880424976348877\n",
      "Predicted: [110, 82] Actual: 166 False  7.667007923126221\n",
      "Predicted: [110, 82] Actual: 167 False  7.603084087371826\n",
      "Predicted: [125, 110] Actual: 168 False  8.55866527557373\n",
      "Predicted: [110, 82] Actual: 169 False  7.748593807220459\n",
      "Predicted: [110, 82] Actual: 170 False  8.13249397277832\n",
      "Predicted: [110, 82] Actual: 171 False  7.575047016143799\n",
      "Predicted: [110, 82] Actual: 172 False  8.04990005493164\n",
      "Predicted: [110, 82] Actual: 173 False  7.408390998840332\n",
      "Predicted: [110, 82] Actual: 174 False  8.008906364440918\n",
      "Predicted: [110, 82] Actual: 175 False  7.965543270111084\n",
      "Predicted: [110, 82] Actual: 176 False  7.761981010437012\n",
      "Predicted: [110, 82] Actual: 177 False  7.6377434730529785\n",
      "Predicted: [110, 82] Actual: 178 False  8.069911003112793\n",
      "Predicted: [110, 82] Actual: 179 False  7.887537479400635\n",
      "Predicted: [110, 82] Actual: 180 False  7.657102108001709\n",
      "Predicted: [110, 82] Actual: 181 False  7.878625392913818\n",
      "Predicted: [110, 82] Actual: 182 False  7.69722318649292\n",
      "Predicted: [110, 82] Actual: 183 False  7.3706793785095215\n",
      "Predicted: [110]   Actual: 184 False  8.05111026763916\n",
      "Predicted: [110, 82] Actual: 185 False  7.616098880767822\n",
      "Predicted: [110]   Actual: 186 False  8.285544395446777\n",
      "Predicted: [110, 82] Actual: 187 False  7.697129249572754\n",
      "Predicted: [110, 82] Actual: 188 False  8.059943199157715\n",
      "Predicted: [110, 82] Actual: 189 False  7.683973789215088\n",
      "Predicted: [110, 82] Actual: 190 False  7.826769828796387\n",
      "Predicted: [125, 110] Actual: 191 False  7.792556285858154\n",
      "Predicted: [110, 82] Actual: 192 False  8.005746841430664\n",
      "Predicted: [110, 82] Actual: 193 False  7.622234344482422\n",
      "Predicted: [110, 82] Actual: 194 False  7.920708179473877\n",
      "Predicted: [110, 82] Actual: 195 False  8.119229316711426\n",
      "Predicted: [110, 125] Actual: 196 False  7.64703893661499\n",
      "Predicted: [110, 125] Actual: 197 False  7.916849613189697\n",
      "Predicted: [110, 82] Actual: 198 False  7.861286640167236\n",
      "Predicted: [110, 82] Actual: 199 False  7.7951579093933105\n",
      "Predicted: [110, 82] Actual: 200 False  7.623942852020264\n",
      "Predicted: [110, 82] Actual: 201 False  7.878158092498779\n",
      "Predicted: [110, 125] Actual: 202 False  7.847447872161865\n",
      "Predicted: [110, 82] Actual: 203 False  7.795377254486084\n",
      "Predicted: [110, 82] Actual: 204 False  7.651237964630127\n",
      "Predicted: [110, 82] Actual: 205 False  7.695601940155029\n",
      "Predicted: [110, 82] Actual: 206 False  7.473998546600342\n",
      "Predicted: [110, 82] Actual: 207 False  7.971457004547119\n",
      "Predicted: [110, 125] Actual: 208 False  7.686082363128662\n",
      "Predicted: [110, 82] Actual: 209 False  7.964954853057861\n",
      "Predicted: [110, 82] Actual: 210 False  7.864325046539307\n",
      "Predicted: [110, 82] Actual: 211 False  7.812619209289551\n",
      "Predicted: [110, 82] Actual: 212 False  7.697066307067871\n",
      "Predicted: [110, 82] Actual: 213 False  7.596740245819092\n",
      "Predicted: [110, 82] Actual: 214 False  7.788154125213623\n",
      "Predicted: [110, 82] Actual: 215 False  7.810778617858887\n",
      "Predicted: [110, 82] Actual: 216 False  7.745579719543457\n",
      "Predicted: [110, 125] Actual: 217 False  7.7778544425964355\n",
      "Predicted: [110, 82] Actual: 218 False  7.879771709442139\n",
      "Predicted: [110, 125] Actual: 219 False  7.678459644317627\n",
      "Predicted: [110, 82] Actual: 220 False  7.640934467315674\n",
      "Predicted: [110, 82] Actual: 221 False  7.737334728240967\n",
      "Predicted: [110, 82] Actual: 222 False  7.811854362487793\n",
      "Predicted: [110, 82] Actual: 223 False  8.266178131103516\n",
      "Predicted: [110, 82] Actual: 224 False  7.822265148162842\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.146585  [   64/ 8532]\n",
      "loss: 2.008183  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3183  size: 5689  main correct/size: 0.5595007910001758\n",
      "Also correct: 937  size: 5689  also correct/size: 0.1647038143786254\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.960792\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.130936  [   64/ 8532]\n",
      "loss: 2.008031  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3183  size: 5689  main correct/size: 0.5595007910001758\n",
      "Also correct: 937  size: 5689  also correct/size: 0.1647038143786254\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.961460\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.131040  [   64/ 8532]\n",
      "loss: 2.008134  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3182  size: 5689  main correct/size: 0.5593250131833363\n",
      "Also correct: 937  size: 5689  also correct/size: 0.1647038143786254\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.961739\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.130539  [   64/ 8532]\n",
      "loss: 2.008068  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3182  size: 5689  main correct/size: 0.5593250131833363\n",
      "Also correct: 936  size: 5689  also correct/size: 0.1645280365617859\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.961848\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.130005  [   64/ 8532]\n",
      "loss: 2.007863  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3182  size: 5689  main correct/size: 0.5593250131833363\n",
      "Also correct: 936  size: 5689  also correct/size: 0.1645280365617859\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.961812\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.594135761260986\n",
      "Predicted: [110, 82] Actual: 1  False  7.9669389724731445\n",
      "Predicted: [110, 82] Actual: 2  False  7.949390888214111\n",
      "Predicted: [110, 82] Actual: 3  False  7.326830863952637\n",
      "Predicted: [110, 82] Actual: 4  False  7.546273231506348\n",
      "Predicted: [110, 82] Actual: 5  False  7.5088067054748535\n",
      "Predicted: [110, 82] Actual: 6  False  7.940765857696533\n",
      "Predicted: [110, 82] Actual: 7  False  7.875799655914307\n",
      "Predicted: [110, 82] Actual: 8  False  7.589187145233154\n",
      "Predicted: [110, 82] Actual: 9  False  7.513490200042725\n",
      "Predicted: [110, 82] Actual: 10 False  8.057744979858398\n",
      "Predicted: [110, 82] Actual: 11 False  7.778811931610107\n",
      "Predicted: [110, 82] Actual: 12 False  7.989789009094238\n",
      "Predicted: [110, 82] Actual: 13 False  7.671212673187256\n",
      "Predicted: [110, 82] Actual: 14 False  7.62713098526001\n",
      "Predicted: [110, 82] Actual: 15 False  7.536416053771973\n",
      "Predicted: [110, 82] Actual: 16 False  7.866690158843994\n",
      "Predicted: [110, 82] Actual: 17 False  7.5177388191223145\n",
      "Predicted: [110, 82] Actual: 18 False  7.464599132537842\n",
      "Predicted: [110, 82] Actual: 19 False  7.675966739654541\n",
      "Predicted: [110, 82] Actual: 20 False  7.789439678192139\n",
      "Predicted: [110, 82] Actual: 21 False  7.750494480133057\n",
      "Predicted: [110, 82] Actual: 22 False  7.470104694366455\n",
      "Predicted: [110, 82] Actual: 23 False  7.7331929206848145\n",
      "Predicted: [110, 82] Actual: 24 False  7.288863182067871\n",
      "Predicted: [110, 82] Actual: 25 False  7.509531497955322\n",
      "Predicted: [110, 82] Actual: 26 False  7.767917633056641\n",
      "Predicted: [110, 82] Actual: 27 False  7.724227428436279\n",
      "Predicted: [110, 82] Actual: 28 False  7.883072376251221\n",
      "Predicted: [110, 82] Actual: 29 False  7.646227836608887\n",
      "Predicted: [110, 82] Actual: 30 False  7.32202672958374\n",
      "Predicted: [110, 82] Actual: 31 False  7.5594563484191895\n",
      "Predicted: [110, 82] Actual: 32 False  7.608653545379639\n",
      "Predicted: [110, 82] Actual: 33 False  7.815589427947998\n",
      "Predicted: [110, 82] Actual: 34 False  7.75839900970459\n",
      "Predicted: [110, 82] Actual: 35 False  7.702474117279053\n",
      "Predicted: [110, 82] Actual: 36 False  8.041068077087402\n",
      "Predicted: [110, 125] Actual: 37 False  7.532392978668213\n",
      "Predicted: [110, 82] Actual: 38 False  7.870556354522705\n",
      "Predicted: [110, 82] Actual: 39 False  7.991388320922852\n",
      "Predicted: [110, 82] Actual: 40 False  7.78598165512085\n",
      "Predicted: [110, 82] Actual: 41 False  7.923869609832764\n",
      "Predicted: [110, 82] Actual: 42 False  7.706399440765381\n",
      "Predicted: [110, 82] Actual: 43 False  7.642879009246826\n",
      "Predicted: [110, 82] Actual: 44 False  7.888070583343506\n",
      "Predicted: [110, 82] Actual: 45 False  7.627516269683838\n",
      "Predicted: [110, 82] Actual: 46 False  7.740470886230469\n",
      "Predicted: [110, 82] Actual: 47 False  7.529147148132324\n",
      "Predicted: [110, 82] Actual: 48 False  7.721301555633545\n",
      "Predicted: [110, 82] Actual: 49 False  8.055289268493652\n",
      "Predicted: [110, 82] Actual: 50 False  7.866524696350098\n",
      "Predicted: [110, 82] Actual: 51 False  8.106407165527344\n",
      "Predicted: [110, 82] Actual: 52 False  7.597238063812256\n",
      "Predicted: [110, 82] Actual: 53 False  7.726809978485107\n",
      "Predicted: [110, 82] Actual: 54 False  7.555331707000732\n",
      "Predicted: [110, 82] Actual: 55 False  7.479367733001709\n",
      "Predicted: [110, 82] Actual: 56 False  7.347665309906006\n",
      "Predicted: [110, 82] Actual: 57 False  7.579742908477783\n",
      "Predicted: [110, 82] Actual: 58 False  7.4147539138793945\n",
      "Predicted: [110, 82] Actual: 59 False  7.454853057861328\n",
      "Predicted: [110, 82] Actual: 60 False  7.425258159637451\n",
      "Predicted: [110, 82] Actual: 61 False  7.9182329177856445\n",
      "Predicted: [110, 82] Actual: 62 False  7.600254535675049\n",
      "Predicted: [110, 82] Actual: 63 False  7.519073009490967\n",
      "Predicted: [110, 82] Actual: 64 False  7.502649784088135\n",
      "Predicted: [110, 82] Actual: 65 False  7.787020683288574\n",
      "Predicted: [110]   Actual: 66 False  8.774760246276855\n",
      "Predicted: [110]   Actual: 67 False  8.709833145141602\n",
      "Predicted: [110, 82] Actual: 68 False  8.124061584472656\n",
      "Predicted: [110, 82] Actual: 69 False  7.579951763153076\n",
      "Predicted: [110, 82] Actual: 70 False  7.83429479598999\n",
      "Predicted: [110, 82] Actual: 71 False  7.771597385406494\n",
      "Predicted: [110, 82] Actual: 72 False  7.5431036949157715\n",
      "Predicted: [110, 82] Actual: 73 False  7.7326979637146\n",
      "Predicted: [110, 82] Actual: 74 False  7.944950103759766\n",
      "Predicted: [110, 82] Actual: 75 False  7.9070143699646\n",
      "Predicted: [110, 82] Actual: 76 False  7.393779754638672\n",
      "Predicted: [110, 82] Actual: 77 False  7.3797736167907715\n",
      "Predicted: [110, 82] Actual: 78 False  7.724996089935303\n",
      "Predicted: [110, 82] Actual: 79 False  7.692630290985107\n",
      "Predicted: [110]   Actual: 80 False  9.416152000427246\n",
      "Predicted: [110]   Actual: 81 False  8.759896278381348\n",
      "Predicted: [110]   Actual: 82 False  9.484966278076172\n",
      "Predicted: [110]   Actual: 83 False  8.68081283569336\n",
      "Predicted: [110, 82] Actual: 84 False  7.671804428100586\n",
      "Predicted: [110, 82] Actual: 85 False  7.131811618804932\n",
      "Predicted: [110, 82] Actual: 86 False  7.5436625480651855\n",
      "Predicted: [110, 82] Actual: 87 False  7.547929763793945\n",
      "Predicted: [110, 82] Actual: 88 False  7.6816792488098145\n",
      "Predicted: [110, 82] Actual: 89 False  7.80526876449585\n",
      "Predicted: [110, 82] Actual: 90 False  7.671691417694092\n",
      "Predicted: [110, 82] Actual: 91 False  7.5471296310424805\n",
      "Predicted: [110, 82] Actual: 92 False  7.681665897369385\n",
      "Predicted: [110, 82] Actual: 93 False  7.936143398284912\n",
      "Predicted: [110, 125] Actual: 94 False  7.144587993621826\n",
      "Predicted: [110]   Actual: 95 False  8.848377227783203\n",
      "Predicted: [110]   Actual: 96 False  9.531789779663086\n",
      "Predicted: [110]   Actual: 97 False  8.259658813476562\n",
      "Predicted: [110, 82] Actual: 98 False  7.894374370574951\n",
      "Predicted: [110, 82] Actual: 99 False  7.553378105163574\n",
      "Predicted: [110, 82] Actual: 100 False  7.745154857635498\n",
      "Predicted: [110]   Actual: 101 False  8.552812576293945\n",
      "Predicted: [110, 82] Actual: 102 False  7.535496234893799\n",
      "Predicted: [110, 82] Actual: 103 False  7.465294361114502\n",
      "Predicted: [110, 82] Actual: 104 False  7.745426654815674\n",
      "Predicted: [110, 82] Actual: 105 False  7.385770320892334\n",
      "Predicted: [110, 82] Actual: 106 False  7.66389799118042\n",
      "Predicted: [110, 82] Actual: 107 False  7.894859313964844\n",
      "Predicted: [110, 82] Actual: 108 False  7.799391269683838\n",
      "Predicted: [110, 82] Actual: 109 False  8.01855182647705\n",
      "Predicted: [110]   Actual: 110 True   18.18802261352539\n",
      "Predicted: [110, 82] Actual: 111 False  7.562270641326904\n",
      "Predicted: [110, 82] Actual: 112 False  7.654649257659912\n",
      "Predicted: [110, 82] Actual: 113 False  7.596205234527588\n",
      "Predicted: [110, 82] Actual: 114 False  7.602025985717773\n",
      "Predicted: [110, 82] Actual: 115 False  7.514584064483643\n",
      "Predicted: [110, 82] Actual: 116 False  7.671536922454834\n",
      "Predicted: [110, 82] Actual: 117 False  7.17689323425293\n",
      "Predicted: [110, 82] Actual: 118 False  7.392828464508057\n",
      "Predicted: [110, 82] Actual: 119 False  7.927047252655029\n",
      "Predicted: [110, 82] Actual: 120 False  7.882239818572998\n",
      "Predicted: [110, 82] Actual: 121 False  7.506149768829346\n",
      "Predicted: [110, 82] Actual: 122 False  7.821412563323975\n",
      "Predicted: [110, 82] Actual: 123 False  7.7997002601623535\n",
      "Predicted: [110, 82] Actual: 124 False  7.446959018707275\n",
      "Predicted: [125]   Actual: 125 True   160.66783142089844\n",
      "Predicted: [110, 82] Actual: 126 False  7.2251105308532715\n",
      "Predicted: [110, 82] Actual: 127 False  7.819851398468018\n",
      "Predicted: [110, 82] Actual: 128 False  7.850358009338379\n",
      "Predicted: [110, 82] Actual: 129 False  7.734035015106201\n",
      "Predicted: [110, 82] Actual: 130 False  7.540536880493164\n",
      "Predicted: [110, 82] Actual: 131 False  7.431741237640381\n",
      "Predicted: [110, 82] Actual: 132 False  7.295921802520752\n",
      "Predicted: [110, 82] Actual: 133 False  7.402944564819336\n",
      "Predicted: [110, 82] Actual: 134 False  7.5478949546813965\n",
      "Predicted: [110, 82] Actual: 135 False  7.6483473777771\n",
      "Predicted: [110, 82] Actual: 136 False  8.05993366241455\n",
      "Predicted: [110, 125] Actual: 137 False  7.315357685089111\n",
      "Predicted: [110, 82] Actual: 138 False  7.625419616699219\n",
      "Predicted: [110, 82] Actual: 139 False  7.602833271026611\n",
      "Predicted: [110, 82] Actual: 140 False  8.159446716308594\n",
      "Predicted: [110]   Actual: 141 False  8.603809356689453\n",
      "Predicted: [110, 82] Actual: 142 False  7.466393947601318\n",
      "Predicted: [110, 82] Actual: 143 False  7.613597869873047\n",
      "Predicted: [110, 82] Actual: 144 False  7.527054786682129\n",
      "Predicted: [110, 82] Actual: 145 False  7.687948703765869\n",
      "Predicted: [110, 82] Actual: 146 False  8.105506896972656\n",
      "Predicted: [110, 125] Actual: 147 False  7.728476047515869\n",
      "Predicted: [110, 82] Actual: 148 False  7.859102725982666\n",
      "Predicted: [110, 82] Actual: 149 False  7.662824630737305\n",
      "Predicted: [110, 82] Actual: 150 False  7.597841739654541\n",
      "Predicted: [110, 82] Actual: 151 False  7.955409526824951\n",
      "Predicted: [110, 82] Actual: 152 False  7.759019374847412\n",
      "Predicted: [110, 82] Actual: 153 False  7.825058460235596\n",
      "Predicted: [110, 82] Actual: 154 False  7.683182716369629\n",
      "Predicted: [110, 82] Actual: 155 False  7.399086952209473\n",
      "Predicted: [110, 82] Actual: 156 False  8.166754722595215\n",
      "Predicted: [110, 82] Actual: 157 False  7.529786109924316\n",
      "Predicted: [110, 82] Actual: 158 False  7.648907661437988\n",
      "Predicted: [110, 82] Actual: 159 False  7.826138973236084\n",
      "Predicted: [110, 82] Actual: 160 False  7.570306777954102\n",
      "Predicted: [110, 82] Actual: 161 False  7.7365031242370605\n",
      "Predicted: [110, 82] Actual: 162 False  7.377439975738525\n",
      "Predicted: [110, 82] Actual: 163 False  7.6328816413879395\n",
      "Predicted: [110, 82] Actual: 164 False  7.948116779327393\n",
      "Predicted: [110, 82] Actual: 165 False  7.768313884735107\n",
      "Predicted: [110, 82] Actual: 166 False  7.549625396728516\n",
      "Predicted: [110, 82] Actual: 167 False  7.478694915771484\n",
      "Predicted: [125, 110] Actual: 168 False  7.604500770568848\n",
      "Predicted: [110, 82] Actual: 169 False  7.626469612121582\n",
      "Predicted: [110, 82] Actual: 170 False  8.032140731811523\n",
      "Predicted: [110, 82] Actual: 171 False  7.475536823272705\n",
      "Predicted: [110, 82] Actual: 172 False  7.974837779998779\n",
      "Predicted: [110, 82] Actual: 173 False  7.262587070465088\n",
      "Predicted: [110, 82] Actual: 174 False  7.921227931976318\n",
      "Predicted: [110, 82] Actual: 175 False  7.855611324310303\n",
      "Predicted: [110, 82] Actual: 176 False  7.632390022277832\n",
      "Predicted: [110, 82] Actual: 177 False  7.525428295135498\n",
      "Predicted: [110, 82] Actual: 178 False  7.968538761138916\n",
      "Predicted: [110, 82] Actual: 179 False  7.770974636077881\n",
      "Predicted: [110, 82] Actual: 180 False  7.533793926239014\n",
      "Predicted: [110, 82] Actual: 181 False  7.767853736877441\n",
      "Predicted: [110, 82] Actual: 182 False  7.580280780792236\n",
      "Predicted: [110, 82] Actual: 183 False  7.243587017059326\n",
      "Predicted: [110, 82] Actual: 184 False  7.95875358581543\n",
      "Predicted: [110, 82] Actual: 185 False  7.497735023498535\n",
      "Predicted: [110, 82] Actual: 186 False  8.200809478759766\n",
      "Predicted: [110, 82] Actual: 187 False  7.598984241485596\n",
      "Predicted: [110, 82] Actual: 188 False  7.92390775680542\n",
      "Predicted: [110, 82] Actual: 189 False  7.538316249847412\n",
      "Predicted: [110, 82] Actual: 190 False  7.703770637512207\n",
      "Predicted: [110, 125] Actual: 191 False  7.359786510467529\n",
      "Predicted: [110, 82] Actual: 192 False  7.903913974761963\n",
      "Predicted: [110, 82] Actual: 193 False  7.5078887939453125\n",
      "Predicted: [110, 82] Actual: 194 False  7.818518161773682\n",
      "Predicted: [110, 82] Actual: 195 False  8.015646934509277\n",
      "Predicted: [110, 82] Actual: 196 False  7.525650501251221\n",
      "Predicted: [110, 82] Actual: 197 False  7.80553674697876\n",
      "Predicted: [110, 82] Actual: 198 False  7.744431972503662\n",
      "Predicted: [110, 82] Actual: 199 False  7.675381183624268\n",
      "Predicted: [110, 82] Actual: 200 False  7.515738487243652\n",
      "Predicted: [110, 82] Actual: 201 False  7.76353120803833\n",
      "Predicted: [110, 82] Actual: 202 False  7.721803188323975\n",
      "Predicted: [110, 82] Actual: 203 False  7.670991897583008\n",
      "Predicted: [110, 82] Actual: 204 False  7.542482852935791\n",
      "Predicted: [110, 82] Actual: 205 False  7.580175399780273\n",
      "Predicted: [110, 82] Actual: 206 False  7.356843948364258\n",
      "Predicted: [110, 82] Actual: 207 False  7.859711170196533\n",
      "Predicted: [110, 82] Actual: 208 False  7.572071075439453\n",
      "Predicted: [110, 82] Actual: 209 False  7.848241329193115\n",
      "Predicted: [110, 82] Actual: 210 False  7.750290393829346\n",
      "Predicted: [110, 82] Actual: 211 False  7.699674129486084\n",
      "Predicted: [110, 82] Actual: 212 False  7.57456111907959\n",
      "Predicted: [110, 82] Actual: 213 False  7.478104114532471\n",
      "Predicted: [110, 82] Actual: 214 False  7.671714782714844\n",
      "Predicted: [110, 82] Actual: 215 False  7.694355487823486\n",
      "Predicted: [110, 82] Actual: 216 False  7.626014232635498\n",
      "Predicted: [110, 82] Actual: 217 False  7.663403034210205\n",
      "Predicted: [110, 82] Actual: 218 False  7.762403964996338\n",
      "Predicted: [110, 82] Actual: 219 False  7.568892002105713\n",
      "Predicted: [110, 82] Actual: 220 False  7.531668186187744\n",
      "Predicted: [110, 82] Actual: 221 False  7.625172138214111\n",
      "Predicted: [110, 82] Actual: 222 False  7.701187610626221\n",
      "Predicted: [110, 82] Actual: 223 False  8.166056632995605\n",
      "Predicted: [110, 82] Actual: 224 False  7.7051215171813965\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.992259  [   64/ 8532]\n",
      "loss: 1.966694  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3181  size: 5689  main correct/size: 0.5591492353664967\n",
      "Also correct: 975  size: 5689  also correct/size: 0.17138337141852697\n",
      "Test Error: Accuracy: 73.1%, Avg loss: 1.952763\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.997366  [   64/ 8532]\n",
      "loss: 1.966878  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3181  size: 5689  main correct/size: 0.5591492353664967\n",
      "Also correct: 973  size: 5689  also correct/size: 0.17103181578484794\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.953050\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.997913  [   64/ 8532]\n",
      "loss: 1.966475  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3181  size: 5689  main correct/size: 0.5591492353664967\n",
      "Also correct: 973  size: 5689  also correct/size: 0.17103181578484794\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.953116\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.998158  [   64/ 8532]\n",
      "loss: 1.966069  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3181  size: 5689  main correct/size: 0.5591492353664967\n",
      "Also correct: 973  size: 5689  also correct/size: 0.17103181578484794\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.953010\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.998090  [   64/ 8532]\n",
      "loss: 1.965654  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3181  size: 5689  main correct/size: 0.5591492353664967\n",
      "Also correct: 973  size: 5689  also correct/size: 0.17103181578484794\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.952844\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.407956600189209\n",
      "Predicted: [110, 82] Actual: 1  False  7.785876274108887\n",
      "Predicted: [110, 82] Actual: 2  False  7.757582664489746\n",
      "Predicted: [110, 82] Actual: 3  False  7.118765830993652\n",
      "Predicted: [110, 82] Actual: 4  False  7.347646236419678\n",
      "Predicted: [110, 82] Actual: 5  False  7.318641662597656\n",
      "Predicted: [110, 82] Actual: 6  False  7.748208045959473\n",
      "Predicted: [110, 82] Actual: 7  False  7.685401439666748\n",
      "Predicted: [110, 82] Actual: 8  False  7.386092662811279\n",
      "Predicted: [110, 82] Actual: 9  False  7.3080573081970215\n",
      "Predicted: [110, 82] Actual: 10 False  7.869649887084961\n",
      "Predicted: [110, 82] Actual: 11 False  7.584155559539795\n",
      "Predicted: [110, 82] Actual: 12 False  7.803772926330566\n",
      "Predicted: [110, 82] Actual: 13 False  7.473746299743652\n",
      "Predicted: [110, 82] Actual: 14 False  7.432079315185547\n",
      "Predicted: [110, 82] Actual: 15 False  7.3334550857543945\n",
      "Predicted: [110, 82] Actual: 16 False  7.685601234436035\n",
      "Predicted: [110, 82] Actual: 17 False  7.3176116943359375\n",
      "Predicted: [110, 82] Actual: 18 False  7.26840877532959\n",
      "Predicted: [110, 82] Actual: 19 False  7.48219108581543\n",
      "Predicted: [110, 82] Actual: 20 False  7.6237568855285645\n",
      "Predicted: [110, 82] Actual: 21 False  7.580841064453125\n",
      "Predicted: [110, 82] Actual: 22 False  7.261990070343018\n",
      "Predicted: [110, 82] Actual: 23 False  7.533048629760742\n",
      "Predicted: [110, 82] Actual: 24 False  7.090758323669434\n",
      "Predicted: [110, 82] Actual: 25 False  7.321441650390625\n",
      "Predicted: [110, 82] Actual: 26 False  7.580955505371094\n",
      "Predicted: [110, 82] Actual: 27 False  7.527126312255859\n",
      "Predicted: [110, 82] Actual: 28 False  7.685175895690918\n",
      "Predicted: [110, 82] Actual: 29 False  7.451267242431641\n",
      "Predicted: [110, 82] Actual: 30 False  7.114745616912842\n",
      "Predicted: [110, 82] Actual: 31 False  7.372027397155762\n",
      "Predicted: [110, 82] Actual: 32 False  7.416738033294678\n",
      "Predicted: [110, 82] Actual: 33 False  7.619416236877441\n",
      "Predicted: [110, 82] Actual: 34 False  7.579178810119629\n",
      "Predicted: [110, 82] Actual: 35 False  7.47808837890625\n",
      "Predicted: [110, 82] Actual: 36 False  7.850834369659424\n",
      "Predicted: [110, 125] Actual: 37 False  7.318541049957275\n",
      "Predicted: [110, 82] Actual: 38 False  7.679602146148682\n",
      "Predicted: [110, 82] Actual: 39 False  7.803701877593994\n",
      "Predicted: [110, 82] Actual: 40 False  7.591811180114746\n",
      "Predicted: [110, 82] Actual: 41 False  7.72693395614624\n",
      "Predicted: [110, 82] Actual: 42 False  7.51070499420166\n",
      "Predicted: [110, 82] Actual: 43 False  7.444248199462891\n",
      "Predicted: [110, 82] Actual: 44 False  7.69695520401001\n",
      "Predicted: [110, 82] Actual: 45 False  7.446374416351318\n",
      "Predicted: [110, 82] Actual: 46 False  7.552297115325928\n",
      "Predicted: [110, 82] Actual: 47 False  7.326411247253418\n",
      "Predicted: [110, 82] Actual: 48 False  7.528120040893555\n",
      "Predicted: [110, 82] Actual: 49 False  7.824175834655762\n",
      "Predicted: [110, 82] Actual: 50 False  7.677640438079834\n",
      "Predicted: [110, 82] Actual: 51 False  7.913963317871094\n",
      "Predicted: [110, 82] Actual: 52 False  7.384397506713867\n",
      "Predicted: [110, 82] Actual: 53 False  7.53175687789917\n",
      "Predicted: [110, 82] Actual: 54 False  7.356195449829102\n",
      "Predicted: [110, 82] Actual: 55 False  7.282187461853027\n",
      "Predicted: [110, 82] Actual: 56 False  7.142403602600098\n",
      "Predicted: [110, 82] Actual: 57 False  7.383546829223633\n",
      "Predicted: [110, 82] Actual: 58 False  7.216254234313965\n",
      "Predicted: [110, 82] Actual: 59 False  7.259779453277588\n",
      "Predicted: [110, 82] Actual: 60 False  7.231814384460449\n",
      "Predicted: [110, 82] Actual: 61 False  7.723611354827881\n",
      "Predicted: [110, 82] Actual: 62 False  7.401299476623535\n",
      "Predicted: [110, 82] Actual: 63 False  7.323281764984131\n",
      "Predicted: [110, 82] Actual: 64 False  7.312763214111328\n",
      "Predicted: [110, 82] Actual: 65 False  7.570437431335449\n",
      "Predicted: [110]   Actual: 66 False  8.589556694030762\n",
      "Predicted: [110]   Actual: 67 False  8.50677490234375\n",
      "Predicted: [110, 82] Actual: 68 False  7.938242435455322\n",
      "Predicted: [110, 82] Actual: 69 False  7.3778839111328125\n",
      "Predicted: [110, 82] Actual: 70 False  7.642131805419922\n",
      "Predicted: [110, 82] Actual: 71 False  7.580044269561768\n",
      "Predicted: [110, 82] Actual: 72 False  7.34737491607666\n",
      "Predicted: [110, 82] Actual: 73 False  7.518681526184082\n",
      "Predicted: [110, 82] Actual: 74 False  7.756196975708008\n",
      "Predicted: [110, 82] Actual: 75 False  7.716650009155273\n",
      "Predicted: [110, 82] Actual: 76 False  7.188162803649902\n",
      "Predicted: [110, 82] Actual: 77 False  7.181445598602295\n",
      "Predicted: [110, 82] Actual: 78 False  7.52986478805542\n",
      "Predicted: [110, 82] Actual: 79 False  7.485654830932617\n",
      "Predicted: [110]   Actual: 80 False  9.247214317321777\n",
      "Predicted: [110]   Actual: 81 False  8.544526100158691\n",
      "Predicted: [110]   Actual: 82 False  9.264410018920898\n",
      "Predicted: [110]   Actual: 83 False  8.512060165405273\n",
      "Predicted: [110, 82] Actual: 84 False  7.503186225891113\n",
      "Predicted: [110, 82] Actual: 85 False  6.933957099914551\n",
      "Predicted: [110, 82] Actual: 86 False  7.38713264465332\n",
      "Predicted: [110, 82] Actual: 87 False  7.321817398071289\n",
      "Predicted: [110, 82] Actual: 88 False  7.479534149169922\n",
      "Predicted: [110, 82] Actual: 89 False  7.605116367340088\n",
      "Predicted: [110, 82] Actual: 90 False  7.481570243835449\n",
      "Predicted: [110, 82] Actual: 91 False  7.347229957580566\n",
      "Predicted: [110, 82] Actual: 92 False  7.492952346801758\n",
      "Predicted: [110, 82] Actual: 93 False  7.749273300170898\n",
      "Predicted: [110, 82] Actual: 94 False  6.949856758117676\n",
      "Predicted: [110]   Actual: 95 False  8.671323776245117\n",
      "Predicted: [110]   Actual: 96 False  9.349294662475586\n",
      "Predicted: [110]   Actual: 97 False  8.074213027954102\n",
      "Predicted: [110, 82] Actual: 98 False  7.733046531677246\n",
      "Predicted: [110, 82] Actual: 99 False  7.364527702331543\n",
      "Predicted: [110, 82] Actual: 100 False  7.541651725769043\n",
      "Predicted: [110]   Actual: 101 False  8.356639862060547\n",
      "Predicted: [110, 82] Actual: 102 False  7.326822280883789\n",
      "Predicted: [110, 82] Actual: 103 False  7.257843971252441\n",
      "Predicted: [110, 82] Actual: 104 False  7.539917945861816\n",
      "Predicted: [110, 82] Actual: 105 False  7.1886162757873535\n",
      "Predicted: [110, 82] Actual: 106 False  7.469705581665039\n",
      "Predicted: [110, 82] Actual: 107 False  7.7061567306518555\n",
      "Predicted: [110, 82] Actual: 108 False  7.620482444763184\n",
      "Predicted: [110]   Actual: 109 False  7.8298659324646\n",
      "Predicted: [110]   Actual: 110 True   18.373153686523438\n",
      "Predicted: [110, 82] Actual: 111 False  7.356725692749023\n",
      "Predicted: [110, 82] Actual: 112 False  7.447691917419434\n",
      "Predicted: [110, 82] Actual: 113 False  7.388773441314697\n",
      "Predicted: [110, 82] Actual: 114 False  7.419549465179443\n",
      "Predicted: [110, 82] Actual: 115 False  7.309340476989746\n",
      "Predicted: [110, 82] Actual: 116 False  7.467211723327637\n",
      "Predicted: [110, 82] Actual: 117 False  6.974246501922607\n",
      "Predicted: [110, 82] Actual: 118 False  7.1617631912231445\n",
      "Predicted: [110, 82] Actual: 119 False  7.740912437438965\n",
      "Predicted: [110, 82] Actual: 120 False  7.689852237701416\n",
      "Predicted: [110, 82] Actual: 121 False  7.30432653427124\n",
      "Predicted: [110, 82] Actual: 122 False  7.632258415222168\n",
      "Predicted: [110, 82] Actual: 123 False  7.606889247894287\n",
      "Predicted: [110, 82] Actual: 124 False  7.226479530334473\n",
      "Predicted: [125]   Actual: 125 True   160.70750427246094\n",
      "Predicted: [110, 82] Actual: 126 False  7.050750732421875\n",
      "Predicted: [110, 82] Actual: 127 False  7.608773231506348\n",
      "Predicted: [110, 82] Actual: 128 False  7.626814842224121\n",
      "Predicted: [110, 82] Actual: 129 False  7.53366231918335\n",
      "Predicted: [110, 82] Actual: 130 False  7.353210926055908\n",
      "Predicted: [110, 82] Actual: 131 False  7.248204231262207\n",
      "Predicted: [110, 82] Actual: 132 False  7.087482929229736\n",
      "Predicted: [110, 82] Actual: 133 False  7.207408905029297\n",
      "Predicted: [110, 82] Actual: 134 False  7.3379716873168945\n",
      "Predicted: [110, 82] Actual: 135 False  7.449335098266602\n",
      "Predicted: [110, 82] Actual: 136 False  7.870251655578613\n",
      "Predicted: [110, 125] Actual: 137 False  7.1169328689575195\n",
      "Predicted: [110, 82] Actual: 138 False  7.433494567871094\n",
      "Predicted: [110, 82] Actual: 139 False  7.41782283782959\n",
      "Predicted: [110, 82] Actual: 140 False  7.965196132659912\n",
      "Predicted: [110]   Actual: 141 False  8.39880657196045\n",
      "Predicted: [110, 82] Actual: 142 False  7.260390281677246\n",
      "Predicted: [110, 82] Actual: 143 False  7.413208961486816\n",
      "Predicted: [110, 82] Actual: 144 False  7.3265485763549805\n",
      "Predicted: [110, 82] Actual: 145 False  7.487425804138184\n",
      "Predicted: [110, 82] Actual: 146 False  7.9254608154296875\n",
      "Predicted: [110, 125] Actual: 147 False  7.517597198486328\n",
      "Predicted: [110, 82] Actual: 148 False  7.675945281982422\n",
      "Predicted: [110, 82] Actual: 149 False  7.471437454223633\n",
      "Predicted: [110, 82] Actual: 150 False  7.398125171661377\n",
      "Predicted: [110, 82] Actual: 151 False  7.758026599884033\n",
      "Predicted: [110, 82] Actual: 152 False  7.561699867248535\n",
      "Predicted: [110, 82] Actual: 153 False  7.633151054382324\n",
      "Predicted: [110, 82] Actual: 154 False  7.482295989990234\n",
      "Predicted: [110, 82] Actual: 155 False  7.213163375854492\n",
      "Predicted: [110, 82] Actual: 156 False  8.019644737243652\n",
      "Predicted: [110, 82] Actual: 157 False  7.312124252319336\n",
      "Predicted: [110, 82] Actual: 158 False  7.43521785736084\n",
      "Predicted: [110, 82] Actual: 159 False  7.6265459060668945\n",
      "Predicted: [110, 82] Actual: 160 False  7.375205993652344\n",
      "Predicted: [110, 82] Actual: 161 False  7.546612739562988\n",
      "Predicted: [110, 82] Actual: 162 False  7.168125152587891\n",
      "Predicted: [110, 82] Actual: 163 False  7.439277172088623\n",
      "Predicted: [110, 82] Actual: 164 False  7.761143684387207\n",
      "Predicted: [110, 82] Actual: 165 False  7.576914310455322\n",
      "Predicted: [110, 82] Actual: 166 False  7.352499008178711\n",
      "Predicted: [110, 82] Actual: 167 False  7.2806806564331055\n",
      "Predicted: [110, 125] Actual: 168 False  7.2708330154418945\n",
      "Predicted: [110, 82] Actual: 169 False  7.421893119812012\n",
      "Predicted: [110, 82] Actual: 170 False  7.8492279052734375\n",
      "Predicted: [110, 82] Actual: 171 False  7.27091121673584\n",
      "Predicted: [110, 82] Actual: 172 False  7.784743309020996\n",
      "Predicted: [110, 82] Actual: 173 False  7.044037818908691\n",
      "Predicted: [110, 82] Actual: 174 False  7.766847610473633\n",
      "Predicted: [110, 82] Actual: 175 False  7.6826372146606445\n",
      "Predicted: [110, 82] Actual: 176 False  7.423120975494385\n",
      "Predicted: [110, 82] Actual: 177 False  7.331240653991699\n",
      "Predicted: [110, 82] Actual: 178 False  7.78515100479126\n",
      "Predicted: [110, 82] Actual: 179 False  7.574378967285156\n",
      "Predicted: [110, 82] Actual: 180 False  7.3310227394104\n",
      "Predicted: [110, 82] Actual: 181 False  7.575841903686523\n",
      "Predicted: [110, 82] Actual: 182 False  7.383410930633545\n",
      "Predicted: [110, 82] Actual: 183 False  7.039399147033691\n",
      "Predicted: [110, 82] Actual: 184 False  7.7808637619018555\n",
      "Predicted: [110, 82] Actual: 185 False  7.300426006317139\n",
      "Predicted: [110, 82] Actual: 186 False  8.030546188354492\n",
      "Predicted: [110, 82] Actual: 187 False  7.393736839294434\n",
      "Predicted: [110, 82] Actual: 188 False  7.73893928527832\n",
      "Predicted: [110, 82] Actual: 189 False  7.329079627990723\n",
      "Predicted: [110, 82] Actual: 190 False  7.507909774780273\n",
      "Predicted: [110, 125] Actual: 191 False  7.1623759269714355\n",
      "Predicted: [110, 82] Actual: 192 False  7.717480182647705\n",
      "Predicted: [110, 82] Actual: 193 False  7.316897392272949\n",
      "Predicted: [110, 82] Actual: 194 False  7.625818252563477\n",
      "Predicted: [110, 82] Actual: 195 False  7.829453468322754\n",
      "Predicted: [110, 82] Actual: 196 False  7.326817035675049\n",
      "Predicted: [110, 82] Actual: 197 False  7.618594169616699\n",
      "Predicted: [110, 82] Actual: 198 False  7.548259258270264\n",
      "Predicted: [110, 82] Actual: 199 False  7.476701736450195\n",
      "Predicted: [110, 82] Actual: 200 False  7.3206892013549805\n",
      "Predicted: [110, 82] Actual: 201 False  7.5698137283325195\n",
      "Predicted: [110, 82] Actual: 202 False  7.532337188720703\n",
      "Predicted: [110, 82] Actual: 203 False  7.449008464813232\n",
      "Predicted: [110, 82] Actual: 204 False  7.330117225646973\n",
      "Predicted: [110, 82] Actual: 205 False  7.381228923797607\n",
      "Predicted: [110, 82] Actual: 206 False  7.151237487792969\n",
      "Predicted: [110, 82] Actual: 207 False  7.666763782501221\n",
      "Predicted: [110, 82] Actual: 208 False  7.380184650421143\n",
      "Predicted: [110, 82] Actual: 209 False  7.650950908660889\n",
      "Predicted: [110, 82] Actual: 210 False  7.558337211608887\n",
      "Predicted: [110, 82] Actual: 211 False  7.506792068481445\n",
      "Predicted: [110, 82] Actual: 212 False  7.37647819519043\n",
      "Predicted: [110, 82] Actual: 213 False  7.279562473297119\n",
      "Predicted: [110, 82] Actual: 214 False  7.474387168884277\n",
      "Predicted: [110, 82] Actual: 215 False  7.498503684997559\n",
      "Predicted: [110, 82] Actual: 216 False  7.428925037384033\n",
      "Predicted: [110, 82] Actual: 217 False  7.4713544845581055\n",
      "Predicted: [110, 82] Actual: 218 False  7.566770076751709\n",
      "Predicted: [110, 82] Actual: 219 False  7.375958442687988\n",
      "Predicted: [110, 82] Actual: 220 False  7.324433326721191\n",
      "Predicted: [110, 82] Actual: 221 False  7.436037063598633\n",
      "Predicted: [110, 82] Actual: 222 False  7.511425495147705\n",
      "Predicted: [110, 82] Actual: 223 False  7.971560478210449\n",
      "Predicted: [110, 82] Actual: 224 False  7.50777530670166\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.324699  [   64/ 8532]\n",
      "loss: 1.753919  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3162  size: 5689  main correct/size: 0.5558094568465459\n",
      "Also correct: 982  size: 5689  also correct/size: 0.17261381613640359\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.977325\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.404052  [   64/ 8532]\n",
      "loss: 1.753026  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3162  size: 5689  main correct/size: 0.5558094568465459\n",
      "Also correct: 979  size: 5689  also correct/size: 0.17208648268588503\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.977769\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.403867  [   64/ 8532]\n",
      "loss: 1.752435  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3162  size: 5689  main correct/size: 0.5558094568465459\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.977919\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.403266  [   64/ 8532]\n",
      "loss: 1.751925  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3162  size: 5689  main correct/size: 0.5558094568465459\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.977934\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.402657  [   64/ 8532]\n",
      "loss: 1.751418  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3162  size: 5689  main correct/size: 0.5558094568465459\n",
      "Also correct: 978  size: 5689  also correct/size: 0.17191070486904553\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.977900\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.519899845123291\n",
      "Predicted: [110, 82] Actual: 1  False  7.896439075469971\n",
      "Predicted: [110, 82] Actual: 2  False  7.85132360458374\n",
      "Predicted: [110, 82] Actual: 3  False  7.199203968048096\n",
      "Predicted: [110, 82] Actual: 4  False  7.444113254547119\n",
      "Predicted: [110, 82] Actual: 5  False  7.414384365081787\n",
      "Predicted: [110, 82] Actual: 6  False  7.8631815910339355\n",
      "Predicted: [110, 82] Actual: 7  False  7.791324138641357\n",
      "Predicted: [110, 82] Actual: 8  False  7.476480960845947\n",
      "Predicted: [110, 82] Actual: 9  False  7.398314476013184\n",
      "Predicted: [110, 82] Actual: 10 False  7.9827561378479\n",
      "Predicted: [110, 82] Actual: 11 False  7.677107810974121\n",
      "Predicted: [110, 82] Actual: 12 False  7.925713062286377\n",
      "Predicted: [110, 82] Actual: 13 False  7.553731441497803\n",
      "Predicted: [110, 82] Actual: 14 False  7.514796733856201\n",
      "Predicted: [110, 82] Actual: 15 False  7.426456928253174\n",
      "Predicted: [110, 82] Actual: 16 False  7.78407621383667\n",
      "Predicted: [110, 82] Actual: 17 False  7.395841121673584\n",
      "Predicted: [110, 82] Actual: 18 False  7.361867904663086\n",
      "Predicted: [110, 82] Actual: 19 False  7.586371898651123\n",
      "Predicted: [110, 82] Actual: 20 False  7.735402584075928\n",
      "Predicted: [110, 82] Actual: 21 False  7.706130504608154\n",
      "Predicted: [110, 125] Actual: 22 False  7.358675003051758\n",
      "Predicted: [110, 82] Actual: 23 False  7.629546165466309\n",
      "Predicted: [110, 125] Actual: 24 False  7.1836724281311035\n",
      "Predicted: [125, 110] Actual: 25 False  7.46355676651001\n",
      "Predicted: [110, 82] Actual: 26 False  7.68367862701416\n",
      "Predicted: [110, 82] Actual: 27 False  7.622854232788086\n",
      "Predicted: [110, 82] Actual: 28 False  7.791443347930908\n",
      "Predicted: [110, 82] Actual: 29 False  7.550377368927002\n",
      "Predicted: [110, 82] Actual: 30 False  7.2115888595581055\n",
      "Predicted: [110, 82] Actual: 31 False  7.473709583282471\n",
      "Predicted: [110, 82] Actual: 32 False  7.5082621574401855\n",
      "Predicted: [110, 125] Actual: 33 False  7.729088306427002\n",
      "Predicted: [110, 82] Actual: 34 False  7.695292949676514\n",
      "Predicted: [110, 82] Actual: 35 False  7.5518107414245605\n",
      "Predicted: [110, 82] Actual: 36 False  7.9046454429626465\n",
      "Predicted: [125, 110] Actual: 37 False  8.149423599243164\n",
      "Predicted: [110, 82] Actual: 38 False  7.803487300872803\n",
      "Predicted: [110, 82] Actual: 39 False  7.8919172286987305\n",
      "Predicted: [110, 82] Actual: 40 False  7.697970390319824\n",
      "Predicted: [110, 82] Actual: 41 False  7.8346171379089355\n",
      "Predicted: [110, 82] Actual: 42 False  7.619981288909912\n",
      "Predicted: [110, 125] Actual: 43 False  7.540825366973877\n",
      "Predicted: [110, 82] Actual: 44 False  7.80373477935791\n",
      "Predicted: [110, 82] Actual: 45 False  7.567154407501221\n",
      "Predicted: [110, 82] Actual: 46 False  7.669500827789307\n",
      "Predicted: [110, 82] Actual: 47 False  7.404813766479492\n",
      "Predicted: [110, 82] Actual: 48 False  7.638636589050293\n",
      "Predicted: [110, 82] Actual: 49 False  7.854210376739502\n",
      "Predicted: [110, 82] Actual: 50 False  7.769821643829346\n",
      "Predicted: [110, 82] Actual: 51 False  7.9803547859191895\n",
      "Predicted: [110, 82] Actual: 52 False  7.47266149520874\n",
      "Predicted: [110, 82] Actual: 53 False  7.600623607635498\n",
      "Predicted: [110, 125] Actual: 54 False  7.457777500152588\n",
      "Predicted: [110, 82] Actual: 55 False  7.372396469116211\n",
      "Predicted: [110, 82] Actual: 56 False  7.229973316192627\n",
      "Predicted: [110, 82] Actual: 57 False  7.479919910430908\n",
      "Predicted: [110, 125] Actual: 58 False  7.309933185577393\n",
      "Predicted: [110, 82] Actual: 59 False  7.350767612457275\n",
      "Predicted: [110, 82] Actual: 60 False  7.322239875793457\n",
      "Predicted: [110, 82] Actual: 61 False  7.828369617462158\n",
      "Predicted: [110, 82] Actual: 62 False  7.489041805267334\n",
      "Predicted: [110, 82] Actual: 63 False  7.41973876953125\n",
      "Predicted: [110, 82] Actual: 64 False  7.403468608856201\n",
      "Predicted: [110, 82] Actual: 65 False  7.662390232086182\n",
      "Predicted: [110]   Actual: 66 False  8.639154434204102\n",
      "Predicted: [110]   Actual: 67 False  8.569604873657227\n",
      "Predicted: [110, 82] Actual: 68 False  8.014212608337402\n",
      "Predicted: [110, 82] Actual: 69 False  7.4489312171936035\n",
      "Predicted: [110, 82] Actual: 70 False  7.753039836883545\n",
      "Predicted: [110, 125] Actual: 71 False  7.689253330230713\n",
      "Predicted: [110, 82] Actual: 72 False  7.446798801422119\n",
      "Predicted: [110, 82] Actual: 73 False  7.60205602645874\n",
      "Predicted: [110, 82] Actual: 74 False  7.855933666229248\n",
      "Predicted: [110, 82] Actual: 75 False  7.80926513671875\n",
      "Predicted: [110, 82] Actual: 76 False  7.272428035736084\n",
      "Predicted: [110, 82] Actual: 77 False  7.262430667877197\n",
      "Predicted: [110, 82] Actual: 78 False  7.628298282623291\n",
      "Predicted: [110, 82] Actual: 79 False  7.566447734832764\n",
      "Predicted: [110]   Actual: 80 False  9.383760452270508\n",
      "Predicted: [110]   Actual: 81 False  8.634815216064453\n",
      "Predicted: [110]   Actual: 82 False  9.380599975585938\n",
      "Predicted: [110]   Actual: 83 False  8.62121868133545\n",
      "Predicted: [110, 82] Actual: 84 False  7.590484619140625\n",
      "Predicted: [110, 82] Actual: 85 False  6.979921817779541\n",
      "Predicted: [110, 82] Actual: 86 False  7.473093509674072\n",
      "Predicted: [110, 82] Actual: 87 False  7.371161937713623\n",
      "Predicted: [110, 82] Actual: 88 False  7.555933952331543\n",
      "Predicted: [110, 82] Actual: 89 False  7.708371639251709\n",
      "Predicted: [110, 82] Actual: 90 False  7.580456256866455\n",
      "Predicted: [110, 82] Actual: 91 False  7.442345142364502\n",
      "Predicted: [110, 82] Actual: 92 False  7.590860843658447\n",
      "Predicted: [110, 82] Actual: 93 False  7.867425441741943\n",
      "Predicted: [125, 110] Actual: 94 False  7.276772499084473\n",
      "Predicted: [110]   Actual: 95 False  8.794843673706055\n",
      "Predicted: [110]   Actual: 96 False  9.501314163208008\n",
      "Predicted: [110]   Actual: 97 False  8.19163703918457\n",
      "Predicted: [110, 82] Actual: 98 False  7.833510398864746\n",
      "Predicted: [110, 82] Actual: 99 False  7.472555637359619\n",
      "Predicted: [110, 82] Actual: 100 False  7.633406162261963\n",
      "Predicted: [110]   Actual: 101 False  8.438924789428711\n",
      "Predicted: [110, 82] Actual: 102 False  7.417948246002197\n",
      "Predicted: [110, 82] Actual: 103 False  7.349315166473389\n",
      "Predicted: [110, 125] Actual: 104 False  7.636303424835205\n",
      "Predicted: [110, 82] Actual: 105 False  7.277296543121338\n",
      "Predicted: [110, 82] Actual: 106 False  7.56653356552124\n",
      "Predicted: [110, 82] Actual: 107 False  7.815247058868408\n",
      "Predicted: [110, 82] Actual: 108 False  7.719015598297119\n",
      "Predicted: [110, 82] Actual: 109 False  7.903894424438477\n",
      "Predicted: [110]   Actual: 110 True   19.116289138793945\n",
      "Predicted: [110, 82] Actual: 111 False  7.413580894470215\n",
      "Predicted: [110, 125] Actual: 112 False  7.537743091583252\n",
      "Predicted: [110, 82] Actual: 113 False  7.466301441192627\n",
      "Predicted: [110, 82] Actual: 114 False  7.4925856590271\n",
      "Predicted: [110, 82] Actual: 115 False  7.397371768951416\n",
      "Predicted: [110, 82] Actual: 116 False  7.543305397033691\n",
      "Predicted: [110, 82] Actual: 117 False  7.056406497955322\n",
      "Predicted: [110, 125] Actual: 118 False  7.233596324920654\n",
      "Predicted: [110, 82] Actual: 119 False  7.867029190063477\n",
      "Predicted: [110, 82] Actual: 120 False  7.7981743812561035\n",
      "Predicted: [110, 82] Actual: 121 False  7.394676685333252\n",
      "Predicted: [110, 82] Actual: 122 False  7.710702419281006\n",
      "Predicted: [110, 82] Actual: 123 False  7.711014270782471\n",
      "Predicted: [110, 82] Actual: 124 False  7.284496784210205\n",
      "Predicted: [125]   Actual: 125 True   162.78451538085938\n",
      "Predicted: [110, 82] Actual: 126 False  7.0768561363220215\n",
      "Predicted: [110, 82] Actual: 127 False  7.691778182983398\n",
      "Predicted: [110, 82] Actual: 128 False  7.742427825927734\n",
      "Predicted: [110, 82] Actual: 129 False  7.617381572723389\n",
      "Predicted: [110, 82] Actual: 130 False  7.46420955657959\n",
      "Predicted: [110, 82] Actual: 131 False  7.357590198516846\n",
      "Predicted: [110, 82] Actual: 132 False  7.1740193367004395\n",
      "Predicted: [125, 110] Actual: 133 False  7.548666477203369\n",
      "Predicted: [110, 82] Actual: 134 False  7.440766334533691\n",
      "Predicted: [110, 82] Actual: 135 False  7.543272495269775\n",
      "Predicted: [110, 82] Actual: 136 False  7.9878315925598145\n",
      "Predicted: [125, 110] Actual: 137 False  8.085296630859375\n",
      "Predicted: [110, 125] Actual: 138 False  7.539637565612793\n",
      "Predicted: [110, 82] Actual: 139 False  7.515130043029785\n",
      "Predicted: [110, 82] Actual: 140 False  8.050247192382812\n",
      "Predicted: [110]   Actual: 141 False  8.523347854614258\n",
      "Predicted: [110, 82] Actual: 142 False  7.3492608070373535\n",
      "Predicted: [110, 82] Actual: 143 False  7.5052337646484375\n",
      "Predicted: [110, 125] Actual: 144 False  7.409445762634277\n",
      "Predicted: [110, 82] Actual: 145 False  7.611299514770508\n",
      "Predicted: [110, 82] Actual: 146 False  8.071370124816895\n",
      "Predicted: [125, 110] Actual: 147 False  7.851696491241455\n",
      "Predicted: [110, 82] Actual: 148 False  7.778830051422119\n",
      "Predicted: [110, 82] Actual: 149 False  7.574804782867432\n",
      "Predicted: [110, 82] Actual: 150 False  7.491267681121826\n",
      "Predicted: [110, 82] Actual: 151 False  7.858511447906494\n",
      "Predicted: [110, 82] Actual: 152 False  7.669012546539307\n",
      "Predicted: [110, 82] Actual: 153 False  7.740077495574951\n",
      "Predicted: [110, 82] Actual: 154 False  7.567727565765381\n",
      "Predicted: [110, 82] Actual: 155 False  7.307896137237549\n",
      "Predicted: [110, 82] Actual: 156 False  8.13821029663086\n",
      "Predicted: [110, 82] Actual: 157 False  7.372894287109375\n",
      "Predicted: [110, 82] Actual: 158 False  7.515944480895996\n",
      "Predicted: [110, 82] Actual: 159 False  7.726185321807861\n",
      "Predicted: [110, 82] Actual: 160 False  7.46097993850708\n",
      "Predicted: [110, 125] Actual: 161 False  7.65008020401001\n",
      "Predicted: [110, 125] Actual: 162 False  7.25104284286499\n",
      "Predicted: [110, 82] Actual: 163 False  7.540204048156738\n",
      "Predicted: [110, 82] Actual: 164 False  7.8685503005981445\n",
      "Predicted: [110, 82] Actual: 165 False  7.687783718109131\n",
      "Predicted: [110, 82] Actual: 166 False  7.447269916534424\n",
      "Predicted: [110, 82] Actual: 167 False  7.371091365814209\n",
      "Predicted: [125, 110] Actual: 168 False  8.468149185180664\n",
      "Predicted: [110, 82] Actual: 169 False  7.514699459075928\n",
      "Predicted: [110, 82] Actual: 170 False  7.957021236419678\n",
      "Predicted: [110, 82] Actual: 171 False  7.370769023895264\n",
      "Predicted: [110, 82] Actual: 172 False  7.853209018707275\n",
      "Predicted: [110, 82] Actual: 173 False  7.111007213592529\n",
      "Predicted: [110, 82] Actual: 174 False  7.886624813079834\n",
      "Predicted: [110, 82] Actual: 175 False  7.812267303466797\n",
      "Predicted: [110, 82] Actual: 176 False  7.511269569396973\n",
      "Predicted: [110, 82] Actual: 177 False  7.422225475311279\n",
      "Predicted: [110, 82] Actual: 178 False  7.894470691680908\n",
      "Predicted: [110, 82] Actual: 179 False  7.676743984222412\n",
      "Predicted: [110, 82] Actual: 180 False  7.4271559715271\n",
      "Predicted: [110, 82] Actual: 181 False  7.673833847045898\n",
      "Predicted: [110, 82] Actual: 182 False  7.474058628082275\n",
      "Predicted: [110, 82] Actual: 183 False  7.118358612060547\n",
      "Predicted: [110, 82] Actual: 184 False  7.884727954864502\n",
      "Predicted: [110, 82] Actual: 185 False  7.386142253875732\n",
      "Predicted: [110, 82] Actual: 186 False  8.13257884979248\n",
      "Predicted: [110, 82] Actual: 187 False  7.4377923011779785\n",
      "Predicted: [110, 82] Actual: 188 False  7.81578254699707\n",
      "Predicted: [110, 82] Actual: 189 False  7.40319299697876\n",
      "Predicted: [110, 82] Actual: 190 False  7.599973201751709\n",
      "Predicted: [125, 110] Actual: 191 False  7.8350911140441895\n",
      "Predicted: [110, 82] Actual: 192 False  7.813981056213379\n",
      "Predicted: [110, 82] Actual: 193 False  7.419810771942139\n",
      "Predicted: [110, 82] Actual: 194 False  7.712975025177002\n",
      "Predicted: [110, 82] Actual: 195 False  7.940496921539307\n",
      "Predicted: [110, 125] Actual: 196 False  7.428244113922119\n",
      "Predicted: [110, 125] Actual: 197 False  7.739132404327393\n",
      "Predicted: [110, 82] Actual: 198 False  7.6536664962768555\n",
      "Predicted: [110, 82] Actual: 199 False  7.57855224609375\n",
      "Predicted: [110, 82] Actual: 200 False  7.396422863006592\n",
      "Predicted: [110, 82] Actual: 201 False  7.670851230621338\n",
      "Predicted: [110, 125] Actual: 202 False  7.62799072265625\n",
      "Predicted: [110, 82] Actual: 203 False  7.5210394859313965\n",
      "Predicted: [110, 82] Actual: 204 False  7.4476542472839355\n",
      "Predicted: [110, 82] Actual: 205 False  7.477649211883545\n",
      "Predicted: [110, 82] Actual: 206 False  7.235350131988525\n",
      "Predicted: [110, 82] Actual: 207 False  7.775654315948486\n",
      "Predicted: [110, 125] Actual: 208 False  7.479398250579834\n",
      "Predicted: [110, 82] Actual: 209 False  7.758635997772217\n",
      "Predicted: [110, 82] Actual: 210 False  7.6675028800964355\n",
      "Predicted: [110, 82] Actual: 211 False  7.604485034942627\n",
      "Predicted: [110, 82] Actual: 212 False  7.471043109893799\n",
      "Predicted: [110, 82] Actual: 213 False  7.367530345916748\n",
      "Predicted: [110, 82] Actual: 214 False  7.568418025970459\n",
      "Predicted: [110, 82] Actual: 215 False  7.598022937774658\n",
      "Predicted: [110, 82] Actual: 216 False  7.531730651855469\n",
      "Predicted: [110, 125] Actual: 217 False  7.577108860015869\n",
      "Predicted: [110, 82] Actual: 218 False  7.6784772872924805\n",
      "Predicted: [110, 82] Actual: 219 False  7.4607720375061035\n",
      "Predicted: [110, 82] Actual: 220 False  7.422338008880615\n",
      "Predicted: [110, 82] Actual: 221 False  7.5394978523254395\n",
      "Predicted: [110, 82] Actual: 222 False  7.611216068267822\n",
      "Predicted: [110, 82] Actual: 223 False  8.065232276916504\n",
      "Predicted: [110, 82] Actual: 224 False  7.609753131866455\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.543889  [   64/ 8532]\n",
      "loss: 1.445590  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3196  size: 5689  main correct/size: 0.5617859026190895\n",
      "Also correct: 948  size: 5689  also correct/size: 0.1666373703638601\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.939274\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.507512  [   64/ 8532]\n",
      "loss: 1.442972  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3196  size: 5689  main correct/size: 0.5617859026190895\n",
      "Also correct: 943  size: 5689  also correct/size: 0.1657584812796625\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 1.939842\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.509090  [   64/ 8532]\n",
      "loss: 1.441549  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3195  size: 5689  main correct/size: 0.5616101248022499\n",
      "Also correct: 943  size: 5689  also correct/size: 0.1657584812796625\n",
      "Test Error: Accuracy: 72.7%, Avg loss: 1.940040\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.509696  [   64/ 8532]\n",
      "loss: 1.440591  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3194  size: 5689  main correct/size: 0.5614343469854104\n",
      "Also correct: 944  size: 5689  also correct/size: 0.16593425909650203\n",
      "Test Error: Accuracy: 72.7%, Avg loss: 1.940109\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.509928  [   64/ 8532]\n",
      "loss: 1.439790  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3195  size: 5689  main correct/size: 0.5616101248022499\n",
      "Also correct: 943  size: 5689  also correct/size: 0.1657584812796625\n",
      "Test Error: Accuracy: 72.7%, Avg loss: 1.940097\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.627345085144043\n",
      "Predicted: [110, 82] Actual: 1  False  7.99847936630249\n",
      "Predicted: [110, 82] Actual: 2  False  7.952321529388428\n",
      "Predicted: [110, 82] Actual: 3  False  7.260350704193115\n",
      "Predicted: [110, 82] Actual: 4  False  7.5265374183654785\n",
      "Predicted: [110, 82] Actual: 5  False  7.498900890350342\n",
      "Predicted: [110, 82] Actual: 6  False  7.95815896987915\n",
      "Predicted: [110, 82] Actual: 7  False  7.884899616241455\n",
      "Predicted: [110, 82] Actual: 8  False  7.55589485168457\n",
      "Predicted: [110, 82] Actual: 9  False  7.474223613739014\n",
      "Predicted: [110, 82] Actual: 10 False  8.085356712341309\n",
      "Predicted: [110, 82] Actual: 11 False  7.767328262329102\n",
      "Predicted: [110, 82] Actual: 12 False  8.025612831115723\n",
      "Predicted: [110, 82] Actual: 13 False  7.639974117279053\n",
      "Predicted: [110, 82] Actual: 14 False  7.603047847747803\n",
      "Predicted: [110, 82] Actual: 15 False  7.5056939125061035\n",
      "Predicted: [110, 82] Actual: 16 False  7.8636674880981445\n",
      "Predicted: [110, 82] Actual: 17 False  7.468050003051758\n",
      "Predicted: [110, 82] Actual: 18 False  7.4413886070251465\n",
      "Predicted: [110, 82] Actual: 19 False  7.671950817108154\n",
      "Predicted: [110, 82] Actual: 20 False  7.827320098876953\n",
      "Predicted: [110, 82] Actual: 21 False  7.82039213180542\n",
      "Predicted: [110, 82] Actual: 22 False  7.437036514282227\n",
      "Predicted: [110, 82] Actual: 23 False  7.71432638168335\n",
      "Predicted: [110, 82] Actual: 24 False  7.254793643951416\n",
      "Predicted: [110, 82] Actual: 25 False  7.492936611175537\n",
      "Predicted: [110, 82] Actual: 26 False  7.779825210571289\n",
      "Predicted: [110, 82] Actual: 27 False  7.7060322761535645\n",
      "Predicted: [110, 82] Actual: 28 False  7.879097938537598\n",
      "Predicted: [110, 82] Actual: 29 False  7.6389241218566895\n",
      "Predicted: [110, 82] Actual: 30 False  7.292426586151123\n",
      "Predicted: [110, 82] Actual: 31 False  7.57142972946167\n",
      "Predicted: [110, 82] Actual: 32 False  7.607882976531982\n",
      "Predicted: [110, 82] Actual: 33 False  7.825697422027588\n",
      "Predicted: [110, 82] Actual: 34 False  7.789917469024658\n",
      "Predicted: [110, 82] Actual: 35 False  7.634012699127197\n",
      "Predicted: [110, 82] Actual: 36 False  8.013907432556152\n",
      "Predicted: [110, 125] Actual: 37 False  7.4836554527282715\n",
      "Predicted: [110, 82] Actual: 38 False  7.89508581161499\n",
      "Predicted: [110, 82] Actual: 39 False  7.998045921325684\n",
      "Predicted: [110, 82] Actual: 40 False  7.790208339691162\n",
      "Predicted: [110, 82] Actual: 41 False  7.925906658172607\n",
      "Predicted: [110, 82] Actual: 42 False  7.720326900482178\n",
      "Predicted: [110, 82] Actual: 43 False  7.625040054321289\n",
      "Predicted: [110, 82] Actual: 44 False  7.895689487457275\n",
      "Predicted: [110, 82] Actual: 45 False  7.664041042327881\n",
      "Predicted: [110, 82] Actual: 46 False  7.767186641693115\n",
      "Predicted: [110, 82] Actual: 47 False  7.473060607910156\n",
      "Predicted: [110, 82] Actual: 48 False  7.743157386779785\n",
      "Predicted: [110, 82] Actual: 49 False  7.923892974853516\n",
      "Predicted: [110, 82] Actual: 50 False  7.848731517791748\n",
      "Predicted: [110, 82] Actual: 51 False  8.066521644592285\n",
      "Predicted: [110, 82] Actual: 52 False  7.550650119781494\n",
      "Predicted: [110, 82] Actual: 53 False  7.665881633758545\n",
      "Predicted: [110, 82] Actual: 54 False  7.540643215179443\n",
      "Predicted: [110, 82] Actual: 55 False  7.452507495880127\n",
      "Predicted: [110, 82] Actual: 56 False  7.29747200012207\n",
      "Predicted: [110, 82] Actual: 57 False  7.563998222351074\n",
      "Predicted: [110, 82] Actual: 58 False  7.383760452270508\n",
      "Predicted: [110, 82] Actual: 59 False  7.434503078460693\n",
      "Predicted: [110, 82] Actual: 60 False  7.401135444641113\n",
      "Predicted: [110, 82] Actual: 61 False  7.922307014465332\n",
      "Predicted: [110, 82] Actual: 62 False  7.570798873901367\n",
      "Predicted: [110, 82] Actual: 63 False  7.499796390533447\n",
      "Predicted: [110, 82] Actual: 64 False  7.513418674468994\n",
      "Predicted: [110, 82] Actual: 65 False  7.757607936859131\n",
      "Predicted: [110]   Actual: 66 False  8.746006965637207\n",
      "Predicted: [110]   Actual: 67 False  8.66051197052002\n",
      "Predicted: [110, 82] Actual: 68 False  8.114876747131348\n",
      "Predicted: [110, 82] Actual: 69 False  7.510267734527588\n",
      "Predicted: [110, 82] Actual: 70 False  7.842254161834717\n",
      "Predicted: [110, 82] Actual: 71 False  7.78410005569458\n",
      "Predicted: [110, 82] Actual: 72 False  7.536767482757568\n",
      "Predicted: [110, 82] Actual: 73 False  7.662691593170166\n",
      "Predicted: [110, 82] Actual: 74 False  7.951632022857666\n",
      "Predicted: [110, 82] Actual: 75 False  7.90804386138916\n",
      "Predicted: [110, 82] Actual: 76 False  7.343041896820068\n",
      "Predicted: [110, 82] Actual: 77 False  7.337831974029541\n",
      "Predicted: [110, 82] Actual: 78 False  7.7141313552856445\n",
      "Predicted: [110, 82] Actual: 79 False  7.635529518127441\n",
      "Predicted: [110]   Actual: 80 False  9.513943672180176\n",
      "Predicted: [110]   Actual: 81 False  8.708833694458008\n",
      "Predicted: [110]   Actual: 82 False  9.474823951721191\n",
      "Predicted: [110]   Actual: 83 False  8.705049514770508\n",
      "Predicted: [110, 82] Actual: 84 False  7.684323787689209\n",
      "Predicted: [110, 82] Actual: 85 False  7.030567646026611\n",
      "Predicted: [110, 82] Actual: 86 False  7.580739498138428\n",
      "Predicted: [110, 82] Actual: 87 False  7.464967250823975\n",
      "Predicted: [110, 82] Actual: 88 False  7.6216864585876465\n",
      "Predicted: [110, 82] Actual: 89 False  7.800896167755127\n",
      "Predicted: [110, 82] Actual: 90 False  7.670844554901123\n",
      "Predicted: [110, 82] Actual: 91 False  7.520686626434326\n",
      "Predicted: [110, 82] Actual: 92 False  7.682766914367676\n",
      "Predicted: [110, 82] Actual: 93 False  7.962183475494385\n",
      "Predicted: [110, 82] Actual: 94 False  7.101093769073486\n",
      "Predicted: [110]   Actual: 95 False  8.90044116973877\n",
      "Predicted: [110]   Actual: 96 False  9.652848243713379\n",
      "Predicted: [110]   Actual: 97 False  8.278571128845215\n",
      "Predicted: [110, 82] Actual: 98 False  7.927730083465576\n",
      "Predicted: [110, 82] Actual: 99 False  7.56621789932251\n",
      "Predicted: [110, 82] Actual: 100 False  7.723222732543945\n",
      "Predicted: [110]   Actual: 101 False  8.528038024902344\n",
      "Predicted: [110, 82] Actual: 102 False  7.47637939453125\n",
      "Predicted: [110, 82] Actual: 103 False  7.414927005767822\n",
      "Predicted: [110, 82] Actual: 104 False  7.714985370635986\n",
      "Predicted: [110, 82] Actual: 105 False  7.348769664764404\n",
      "Predicted: [110, 82] Actual: 106 False  7.649023532867432\n",
      "Predicted: [110, 82] Actual: 107 False  7.915103435516357\n",
      "Predicted: [110, 82] Actual: 108 False  7.821900844573975\n",
      "Predicted: [110, 82] Actual: 109 False  7.991971015930176\n",
      "Predicted: [110]   Actual: 110 True   19.7823429107666\n",
      "Predicted: [110, 82] Actual: 111 False  7.4741902351379395\n",
      "Predicted: [110, 82] Actual: 112 False  7.630244255065918\n",
      "Predicted: [110, 82] Actual: 113 False  7.522454738616943\n",
      "Predicted: [110, 82] Actual: 114 False  7.590439319610596\n",
      "Predicted: [110, 82] Actual: 115 False  7.455549716949463\n",
      "Predicted: [110, 82] Actual: 116 False  7.618920803070068\n",
      "Predicted: [110, 82] Actual: 117 False  7.104529857635498\n",
      "Predicted: [110, 82] Actual: 118 False  7.2857890129089355\n",
      "Predicted: [110, 82] Actual: 119 False  7.951941013336182\n",
      "Predicted: [110, 82] Actual: 120 False  7.891221523284912\n",
      "Predicted: [110, 82] Actual: 121 False  7.474634647369385\n",
      "Predicted: [110, 82] Actual: 122 False  7.810788154602051\n",
      "Predicted: [110, 82] Actual: 123 False  7.799859523773193\n",
      "Predicted: [110, 82] Actual: 124 False  7.346868515014648\n",
      "Predicted: [125]   Actual: 125 True   161.62046813964844\n",
      "Predicted: [110, 82] Actual: 126 False  7.125917911529541\n",
      "Predicted: [110, 82] Actual: 127 False  7.7625203132629395\n",
      "Predicted: [110, 82] Actual: 128 False  7.843891620635986\n",
      "Predicted: [110, 82] Actual: 129 False  7.687438488006592\n",
      "Predicted: [110, 82] Actual: 130 False  7.549393177032471\n",
      "Predicted: [110, 82] Actual: 131 False  7.440150737762451\n",
      "Predicted: [110, 82] Actual: 132 False  7.227888584136963\n",
      "Predicted: [110, 82] Actual: 133 False  7.3468499183654785\n",
      "Predicted: [110, 82] Actual: 134 False  7.51071834564209\n",
      "Predicted: [110, 82] Actual: 135 False  7.626987934112549\n",
      "Predicted: [110, 82] Actual: 136 False  8.089009284973145\n",
      "Predicted: [110, 125] Actual: 137 False  7.287827968597412\n",
      "Predicted: [110, 82] Actual: 138 False  7.629667282104492\n",
      "Predicted: [110, 82] Actual: 139 False  7.599091053009033\n",
      "Predicted: [110, 82] Actual: 140 False  8.138758659362793\n",
      "Predicted: [110]   Actual: 141 False  8.605240821838379\n",
      "Predicted: [110, 82] Actual: 142 False  7.432828426361084\n",
      "Predicted: [110, 82] Actual: 143 False  7.5733160972595215\n",
      "Predicted: [110, 82] Actual: 144 False  7.501162052154541\n",
      "Predicted: [110, 82] Actual: 145 False  7.706577301025391\n",
      "Predicted: [110, 82] Actual: 146 False  8.173651695251465\n",
      "Predicted: [110, 82] Actual: 147 False  7.699840068817139\n",
      "Predicted: [110, 82] Actual: 148 False  7.889556407928467\n",
      "Predicted: [110, 82] Actual: 149 False  7.66520881652832\n",
      "Predicted: [110, 82] Actual: 150 False  7.5718674659729\n",
      "Predicted: [110, 82] Actual: 151 False  7.950472354888916\n",
      "Predicted: [110, 82] Actual: 152 False  7.758169651031494\n",
      "Predicted: [110, 82] Actual: 153 False  7.83437967300415\n",
      "Predicted: [110, 82] Actual: 154 False  7.648106098175049\n",
      "Predicted: [110, 82] Actual: 155 False  7.389895915985107\n",
      "Predicted: [110, 82] Actual: 156 False  8.248773574829102\n",
      "Predicted: [110, 82] Actual: 157 False  7.455040454864502\n",
      "Predicted: [110, 82] Actual: 158 False  7.5929741859436035\n",
      "Predicted: [110, 82] Actual: 159 False  7.820079326629639\n",
      "Predicted: [110, 82] Actual: 160 False  7.548046112060547\n",
      "Predicted: [110, 82] Actual: 161 False  7.750971794128418\n",
      "Predicted: [110, 82] Actual: 162 False  7.321487903594971\n",
      "Predicted: [110, 82] Actual: 163 False  7.627640247344971\n",
      "Predicted: [110, 82] Actual: 164 False  7.9680047035217285\n",
      "Predicted: [110, 82] Actual: 165 False  7.77728271484375\n",
      "Predicted: [110, 82] Actual: 166 False  7.532449245452881\n",
      "Predicted: [110, 82] Actual: 167 False  7.4445977210998535\n",
      "Predicted: [110, 125] Actual: 168 False  7.457699775695801\n",
      "Predicted: [110, 82] Actual: 169 False  7.593857288360596\n",
      "Predicted: [110, 82] Actual: 170 False  8.0598783493042\n",
      "Predicted: [110, 82] Actual: 171 False  7.436153888702393\n",
      "Predicted: [110, 82] Actual: 172 False  7.928710460662842\n",
      "Predicted: [110, 82] Actual: 173 False  7.157858848571777\n",
      "Predicted: [110, 82] Actual: 174 False  8.038884162902832\n",
      "Predicted: [110, 82] Actual: 175 False  7.916167736053467\n",
      "Predicted: [110, 82] Actual: 176 False  7.588415622711182\n",
      "Predicted: [110, 82] Actual: 177 False  7.502908229827881\n",
      "Predicted: [110, 82] Actual: 178 False  7.9961957931518555\n",
      "Predicted: [110, 82] Actual: 179 False  7.767091274261475\n",
      "Predicted: [110, 82] Actual: 180 False  7.503189563751221\n",
      "Predicted: [110, 82] Actual: 181 False  7.762981414794922\n",
      "Predicted: [110, 82] Actual: 182 False  7.553966999053955\n",
      "Predicted: [110, 82] Actual: 183 False  7.1831440925598145\n",
      "Predicted: [110, 82] Actual: 184 False  7.992158889770508\n",
      "Predicted: [110, 82] Actual: 185 False  7.463634014129639\n",
      "Predicted: [110, 82] Actual: 186 False  8.231541633605957\n",
      "Predicted: [110, 82] Actual: 187 False  7.49183988571167\n",
      "Predicted: [110, 82] Actual: 188 False  7.93585205078125\n",
      "Predicted: [110, 82] Actual: 189 False  7.469179630279541\n",
      "Predicted: [110, 82] Actual: 190 False  7.687741756439209\n",
      "Predicted: [110, 82] Actual: 191 False  7.3333868980407715\n",
      "Predicted: [110, 82] Actual: 192 False  7.908295154571533\n",
      "Predicted: [110, 82] Actual: 193 False  7.504582405090332\n",
      "Predicted: [110, 82] Actual: 194 False  7.808457851409912\n",
      "Predicted: [110, 82] Actual: 195 False  8.042288780212402\n",
      "Predicted: [110, 82] Actual: 196 False  7.51068639755249\n",
      "Predicted: [110, 82] Actual: 197 False  7.836060047149658\n",
      "Predicted: [110, 82] Actual: 198 False  7.745080471038818\n",
      "Predicted: [110, 82] Actual: 199 False  7.660627841949463\n",
      "Predicted: [110, 82] Actual: 200 False  7.481021404266357\n",
      "Predicted: [110, 82] Actual: 201 False  7.761291027069092\n",
      "Predicted: [110, 82] Actual: 202 False  7.7223944664001465\n",
      "Predicted: [110, 82] Actual: 203 False  7.602718830108643\n",
      "Predicted: [110, 82] Actual: 204 False  7.558447360992432\n",
      "Predicted: [110, 82] Actual: 205 False  7.535634994506836\n",
      "Predicted: [110, 82] Actual: 206 False  7.303779125213623\n",
      "Predicted: [110, 82] Actual: 207 False  7.86759614944458\n",
      "Predicted: [110, 82] Actual: 208 False  7.572017192840576\n",
      "Predicted: [110, 82] Actual: 209 False  7.844171047210693\n",
      "Predicted: [110, 82] Actual: 210 False  7.7577338218688965\n",
      "Predicted: [110, 82] Actual: 211 False  7.690993309020996\n",
      "Predicted: [110, 82] Actual: 212 False  7.548842906951904\n",
      "Predicted: [110, 82] Actual: 213 False  7.4455952644348145\n",
      "Predicted: [110, 82] Actual: 214 False  7.65182638168335\n",
      "Predicted: [110, 82] Actual: 215 False  7.681485176086426\n",
      "Predicted: [110, 82] Actual: 216 False  7.61074161529541\n",
      "Predicted: [110, 82] Actual: 217 False  7.666337013244629\n",
      "Predicted: [110, 82] Actual: 218 False  7.750120639801025\n",
      "Predicted: [110, 82] Actual: 219 False  7.542693614959717\n",
      "Predicted: [110, 82] Actual: 220 False  7.497092247009277\n",
      "Predicted: [110, 82] Actual: 221 False  7.631495952606201\n",
      "Predicted: [110, 82] Actual: 222 False  7.699421405792236\n",
      "Predicted: [110, 82] Actual: 223 False  8.172134399414062\n",
      "Predicted: [110, 82] Actual: 224 False  7.69357967376709\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.820433  [   64/ 8532]\n",
      "loss: 1.941991  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3041  size: 5689  main correct/size: 0.5345403410089646\n",
      "Also correct: 1100  size: 5689  also correct/size: 0.19335559852346634\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 2.159540\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.023703  [   64/ 8532]\n",
      "loss: 1.934081  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3041  size: 5689  main correct/size: 0.5345403410089646\n",
      "Also correct: 1100  size: 5689  also correct/size: 0.19335559852346634\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 2.159656\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.024042  [   64/ 8532]\n",
      "loss: 1.929966  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3041  size: 5689  main correct/size: 0.5345403410089646\n",
      "Also correct: 1100  size: 5689  also correct/size: 0.19335559852346634\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 2.159504\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.023500  [   64/ 8532]\n",
      "loss: 1.927573  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3041  size: 5689  main correct/size: 0.5345403410089646\n",
      "Also correct: 1099  size: 5689  also correct/size: 0.19317982070662681\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 2.159025\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.022524  [   64/ 8532]\n",
      "loss: 1.925989  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3042  size: 5689  main correct/size: 0.5347161188258042\n",
      "Also correct: 1098  size: 5689  also correct/size: 0.19300404288978731\n",
      "Test Error: Accuracy: 72.8%, Avg loss: 2.158391\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [125, 110] Actual: 0  False  7.736010551452637\n",
      "Predicted: [110, 82] Actual: 1  False  7.512538433074951\n",
      "Predicted: [110, 82] Actual: 2  False  7.441220760345459\n",
      "Predicted: [125, 110] Actual: 3  False  7.020478248596191\n",
      "Predicted: [125, 110] Actual: 4  False  7.813868522644043\n",
      "Predicted: [110, 82] Actual: 5  False  7.012692928314209\n",
      "Predicted: [110, 125] Actual: 6  False  7.470448970794678\n",
      "Predicted: [110, 125] Actual: 7  False  7.391512393951416\n",
      "Predicted: [125, 110] Actual: 8  False  7.463772773742676\n",
      "Predicted: [125, 110] Actual: 9  False  7.4799346923828125\n",
      "Predicted: [110, 82] Actual: 10 False  7.594729900360107\n",
      "Predicted: [110, 82] Actual: 11 False  7.274658203125\n",
      "Predicted: [110, 125] Actual: 12 False  7.551840782165527\n",
      "Predicted: [110, 82] Actual: 13 False  7.132147312164307\n",
      "Predicted: [110, 82] Actual: 14 False  7.094111919403076\n",
      "Predicted: [125, 110] Actual: 15 False  7.1655778884887695\n",
      "Predicted: [110, 82] Actual: 16 False  7.365800380706787\n",
      "Predicted: [110, 125] Actual: 17 False  6.956729412078857\n",
      "Predicted: [125, 110] Actual: 18 False  7.4066162109375\n",
      "Predicted: [110, 125] Actual: 19 False  7.1908464431762695\n",
      "Predicted: [110, 82] Actual: 20 False  7.345152378082275\n",
      "Predicted: [125, 110] Actual: 21 False  7.707094192504883\n",
      "Predicted: [125]   Actual: 22 False  8.690329551696777\n",
      "Predicted: [110, 82] Actual: 23 False  7.221399784088135\n",
      "Predicted: [125, 110] Actual: 24 False  7.979645729064941\n",
      "Predicted: [125]   Actual: 25 False  9.101964950561523\n",
      "Predicted: [110, 82] Actual: 26 False  7.292557716369629\n",
      "Predicted: [110, 82] Actual: 27 False  7.213566303253174\n",
      "Predicted: [110, 82] Actual: 28 False  7.389605522155762\n",
      "Predicted: [125, 110] Actual: 29 False  7.687047004699707\n",
      "Predicted: [125, 110] Actual: 30 False  6.952478408813477\n",
      "Predicted: [125, 110] Actual: 31 False  7.689175605773926\n",
      "Predicted: [110, 82] Actual: 32 False  7.1059088706970215\n",
      "Predicted: [125, 110] Actual: 33 False  8.670183181762695\n",
      "Predicted: [110, 82] Actual: 34 False  7.307712078094482\n",
      "Predicted: [110, 82] Actual: 35 False  7.137859344482422\n",
      "Predicted: [110, 82] Actual: 36 False  7.466466426849365\n",
      "Predicted: [125]   Actual: 37 False  9.853425979614258\n",
      "Predicted: [125, 110] Actual: 38 False  7.633583068847656\n",
      "Predicted: [110, 82] Actual: 39 False  7.4929280281066895\n",
      "Predicted: [110, 125] Actual: 40 False  7.300553798675537\n",
      "Predicted: [110, 82] Actual: 41 False  7.4383625984191895\n",
      "Predicted: [125, 110] Actual: 42 False  8.040518760681152\n",
      "Predicted: [125]   Actual: 43 False  9.376423835754395\n",
      "Predicted: [110, 82] Actual: 44 False  7.413767337799072\n",
      "Predicted: [110, 82] Actual: 45 False  7.17944860458374\n",
      "Predicted: [110, 125] Actual: 46 False  7.284818172454834\n",
      "Predicted: [125, 110] Actual: 47 False  8.24376392364502\n",
      "Predicted: [110, 82] Actual: 48 False  7.257490634918213\n",
      "Predicted: [110, 82] Actual: 49 False  7.3613057136535645\n",
      "Predicted: [110, 82] Actual: 50 False  7.3461174964904785\n",
      "Predicted: [110, 82] Actual: 51 False  7.539788722991943\n",
      "Predicted: [110, 82] Actual: 52 False  7.052944660186768\n",
      "Predicted: [110, 82] Actual: 53 False  7.16750955581665\n",
      "Predicted: [125]   Actual: 54 False  8.968680381774902\n",
      "Predicted: [125, 110] Actual: 55 False  7.229199409484863\n",
      "Predicted: [125, 110] Actual: 56 False  7.664485931396484\n",
      "Predicted: [125, 110] Actual: 57 False  7.225549697875977\n",
      "Predicted: [125, 110] Actual: 58 False  8.294405937194824\n",
      "Predicted: [125, 110] Actual: 59 False  7.368831634521484\n",
      "Predicted: [125, 110] Actual: 60 False  7.696466445922852\n",
      "Predicted: [110, 82] Actual: 61 False  7.432009220123291\n",
      "Predicted: [125, 110] Actual: 62 False  7.242668151855469\n",
      "Predicted: [125, 110] Actual: 63 False  7.527067184448242\n",
      "Predicted: [110, 82] Actual: 64 False  7.015049457550049\n",
      "Predicted: [110, 125] Actual: 65 False  7.25518798828125\n",
      "Predicted: [110, 82] Actual: 66 False  8.201918601989746\n",
      "Predicted: [110, 82] Actual: 67 False  8.142565727233887\n",
      "Predicted: [110, 82] Actual: 68 False  7.558290958404541\n",
      "Predicted: [110, 82] Actual: 69 False  6.9854960441589355\n",
      "Predicted: [125, 110] Actual: 70 False  7.3894548416137695\n",
      "Predicted: [125, 110] Actual: 71 False  8.500134468078613\n",
      "Predicted: [125, 110] Actual: 72 False  7.119441986083984\n",
      "Predicted: [125, 110] Actual: 73 False  7.766457557678223\n",
      "Predicted: [110, 82] Actual: 74 False  7.46142053604126\n",
      "Predicted: [110, 82] Actual: 75 False  7.411070346832275\n",
      "Predicted: [125, 110] Actual: 76 False  7.992420196533203\n",
      "Predicted: [110, 82] Actual: 77 False  6.831700801849365\n",
      "Predicted: [110, 82] Actual: 78 False  7.224857807159424\n",
      "Predicted: [110, 125] Actual: 79 False  7.129067897796631\n",
      "Predicted: [110]   Actual: 80 False  9.082198143005371\n",
      "Predicted: [110, 82] Actual: 81 False  8.199734687805176\n",
      "Predicted: [110]   Actual: 82 False  9.00350284576416\n",
      "Predicted: [110]   Actual: 83 False  8.21270751953125\n",
      "Predicted: [110, 82] Actual: 84 False  7.211645603179932\n",
      "Predicted: [125, 110] Actual: 85 False  7.52305793762207\n",
      "Predicted: [110, 82] Actual: 86 False  7.049568176269531\n",
      "Predicted: [110, 82] Actual: 87 False  6.948022365570068\n",
      "Predicted: [110, 82] Actual: 88 False  7.123935222625732\n",
      "Predicted: [110, 125] Actual: 89 False  7.316319942474365\n",
      "Predicted: [110, 125] Actual: 90 False  7.178434371948242\n",
      "Predicted: [110, 125] Actual: 91 False  7.026960849761963\n",
      "Predicted: [110, 82] Actual: 92 False  7.18549108505249\n",
      "Predicted: [110, 82] Actual: 93 False  7.494869709014893\n",
      "Predicted: [125]   Actual: 94 False  9.152159690856934\n",
      "Predicted: [110]   Actual: 95 False  8.423393249511719\n",
      "Predicted: [110]   Actual: 96 False  9.185190200805664\n",
      "Predicted: [110]   Actual: 97 False  7.854768753051758\n",
      "Predicted: [110, 82] Actual: 98 False  7.45724630355835\n",
      "Predicted: [110, 125] Actual: 99 False  7.079958438873291\n",
      "Predicted: [125, 110] Actual: 100 False  7.68498420715332\n",
      "Predicted: [110, 82] Actual: 101 False  8.0079927444458\n",
      "Predicted: [125, 110] Actual: 102 False  8.15819263458252\n",
      "Predicted: [125, 110] Actual: 103 False  7.465132713317871\n",
      "Predicted: [125, 110] Actual: 104 False  8.541339874267578\n",
      "Predicted: [125, 110] Actual: 105 False  7.715533256530762\n",
      "Predicted: [110, 82] Actual: 106 False  7.162276744842529\n",
      "Predicted: [110, 125] Actual: 107 False  7.421769618988037\n",
      "Predicted: [110, 82] Actual: 108 False  7.340487957000732\n",
      "Predicted: [110, 82] Actual: 109 False  7.42937707901001\n",
      "Predicted: [110]   Actual: 110 True   20.022232055664062\n",
      "Predicted: [110, 82] Actual: 111 False  6.944844722747803\n",
      "Predicted: [125, 110] Actual: 112 False  8.469364166259766\n",
      "Predicted: [110, 125] Actual: 113 False  7.03219747543335\n",
      "Predicted: [110, 82] Actual: 114 False  7.045330047607422\n",
      "Predicted: [110, 82] Actual: 115 False  6.949399471282959\n",
      "Predicted: [110, 82] Actual: 116 False  7.120483875274658\n",
      "Predicted: [125, 110] Actual: 117 False  8.196568489074707\n",
      "Predicted: [125]   Actual: 118 False  8.930534362792969\n",
      "Predicted: [110, 125] Actual: 119 False  7.484470844268799\n",
      "Predicted: [110, 82] Actual: 120 False  7.398951530456543\n",
      "Predicted: [125, 110] Actual: 121 False  7.770298004150391\n",
      "Predicted: [110, 82] Actual: 122 False  7.3054938316345215\n",
      "Predicted: [110, 82] Actual: 123 False  7.316030502319336\n",
      "Predicted: [110, 82] Actual: 124 False  6.841137886047363\n",
      "Predicted: [125]   Actual: 125 True   163.9868621826172\n",
      "Predicted: [110, 82] Actual: 126 False  6.586702823638916\n",
      "Predicted: [110, 82] Actual: 127 False  7.217706203460693\n",
      "Predicted: [110, 82] Actual: 128 False  7.325856685638428\n",
      "Predicted: [110, 125] Actual: 129 False  7.152313709259033\n",
      "Predicted: [125, 110] Actual: 130 False  7.106220245361328\n",
      "Predicted: [125, 110] Actual: 131 False  7.08204460144043\n",
      "Predicted: [125, 110] Actual: 132 False  7.898781776428223\n",
      "Predicted: [125]   Actual: 133 False  9.565694808959961\n",
      "Predicted: [125, 110] Actual: 134 False  8.06399917602539\n",
      "Predicted: [110, 82] Actual: 135 False  7.1215996742248535\n",
      "Predicted: [110, 82] Actual: 136 False  7.605398654937744\n",
      "Predicted: [125]   Actual: 137 False  9.602599143981934\n",
      "Predicted: [125]   Actual: 138 False  9.044990539550781\n",
      "Predicted: [125, 110] Actual: 139 False  7.118043899536133\n",
      "Predicted: [110, 82] Actual: 140 False  7.59491491317749\n",
      "Predicted: [110, 82] Actual: 141 False  8.090035438537598\n",
      "Predicted: [110, 82] Actual: 142 False  6.925765514373779\n",
      "Predicted: [110, 82] Actual: 143 False  7.079986095428467\n",
      "Predicted: [125, 110] Actual: 144 False  8.333358764648438\n",
      "Predicted: [110, 125] Actual: 145 False  7.2343525886535645\n",
      "Predicted: [110, 125] Actual: 146 False  7.692116737365723\n",
      "Predicted: [125]   Actual: 147 False  9.617730140686035\n",
      "Predicted: [110, 82] Actual: 148 False  7.380101680755615\n",
      "Predicted: [125, 110] Actual: 149 False  7.887613296508789\n",
      "Predicted: [125, 110] Actual: 150 False  7.195302963256836\n",
      "Predicted: [110, 82] Actual: 151 False  7.450214862823486\n",
      "Predicted: [125, 110] Actual: 152 False  8.19581413269043\n",
      "Predicted: [110, 125] Actual: 153 False  7.3393425941467285\n",
      "Predicted: [110, 82] Actual: 154 False  7.138408660888672\n",
      "Predicted: [125, 110] Actual: 155 False  7.842855453491211\n",
      "Predicted: [110, 82] Actual: 156 False  7.741023540496826\n",
      "Predicted: [110, 82] Actual: 157 False  6.913342475891113\n",
      "Predicted: [110, 82] Actual: 158 False  7.0765156745910645\n",
      "Predicted: [110, 82] Actual: 159 False  7.32661247253418\n",
      "Predicted: [110, 125] Actual: 160 False  7.049708843231201\n",
      "Predicted: [125, 110] Actual: 161 False  9.008111953735352\n",
      "Predicted: [125, 110] Actual: 162 False  8.39010238647461\n",
      "Predicted: [125, 110] Actual: 163 False  7.550631523132324\n",
      "Predicted: [110, 82] Actual: 164 False  7.484775543212891\n",
      "Predicted: [125, 110] Actual: 165 False  7.448634147644043\n",
      "Predicted: [125, 110] Actual: 166 False  7.641818046569824\n",
      "Predicted: [125, 110] Actual: 167 False  7.375176429748535\n",
      "Predicted: [125]   Actual: 168 False  10.092021942138672\n",
      "Predicted: [110, 82] Actual: 169 False  7.087449550628662\n",
      "Predicted: [110, 82] Actual: 170 False  7.576806545257568\n",
      "Predicted: [110, 82] Actual: 171 False  6.936870098114014\n",
      "Predicted: [110, 82] Actual: 172 False  7.454883098602295\n",
      "Predicted: [110, 82] Actual: 173 False  6.615702152252197\n",
      "Predicted: [110, 82] Actual: 174 False  7.547187328338623\n",
      "Predicted: [110, 125] Actual: 175 False  7.420892238616943\n",
      "Predicted: [125, 110] Actual: 176 False  8.089620590209961\n",
      "Predicted: [110, 82] Actual: 177 False  7.021420955657959\n",
      "Predicted: [110, 82] Actual: 178 False  7.511131286621094\n",
      "Predicted: [125, 110] Actual: 179 False  7.399627685546875\n",
      "Predicted: [125, 110] Actual: 180 False  7.477468490600586\n",
      "Predicted: [110, 82] Actual: 181 False  7.262671947479248\n",
      "Predicted: [110, 82] Actual: 182 False  7.057066917419434\n",
      "Predicted: [125, 110] Actual: 183 False  7.210965156555176\n",
      "Predicted: [110, 82] Actual: 184 False  7.513493061065674\n",
      "Predicted: [110, 82] Actual: 185 False  6.968407154083252\n",
      "Predicted: [110, 82] Actual: 186 False  7.7414116859436035\n",
      "Predicted: [110, 82] Actual: 187 False  6.921668529510498\n",
      "Predicted: [110, 82] Actual: 188 False  7.3585124015808105\n",
      "Predicted: [110, 82] Actual: 189 False  6.94852876663208\n",
      "Predicted: [125, 110] Actual: 190 False  7.633111000061035\n",
      "Predicted: [125]   Actual: 191 False  9.410965919494629\n",
      "Predicted: [110, 82] Actual: 192 False  7.42656946182251\n",
      "Predicted: [125, 110] Actual: 193 False  7.80031681060791\n",
      "Predicted: [110, 82] Actual: 194 False  7.3032307624816895\n",
      "Predicted: [110, 82] Actual: 195 False  7.554834842681885\n",
      "Predicted: [125, 110] Actual: 196 False  8.341556549072266\n",
      "Predicted: [125, 110] Actual: 197 False  8.760303497314453\n",
      "Predicted: [125, 110] Actual: 198 False  8.001306533813477\n",
      "Predicted: [125, 110] Actual: 199 False  7.264603614807129\n",
      "Predicted: [110, 82] Actual: 200 False  6.983082294464111\n",
      "Predicted: [110, 125] Actual: 201 False  7.264225482940674\n",
      "Predicted: [125, 110] Actual: 202 False  8.470817565917969\n",
      "Predicted: [110, 82] Actual: 203 False  7.1124138832092285\n",
      "Predicted: [110, 82] Actual: 204 False  7.086650371551514\n",
      "Predicted: [110, 82] Actual: 205 False  7.040140628814697\n",
      "Predicted: [125, 110] Actual: 206 False  6.832812309265137\n",
      "Predicted: [110, 82] Actual: 207 False  7.3780341148376465\n",
      "Predicted: [125, 110] Actual: 208 False  8.544346809387207\n",
      "Predicted: [110, 82] Actual: 209 False  7.360115051269531\n",
      "Predicted: [110, 125] Actual: 210 False  7.276455402374268\n",
      "Predicted: [110, 82] Actual: 211 False  7.194945812225342\n",
      "Predicted: [125, 110] Actual: 212 False  7.378425598144531\n",
      "Predicted: [110, 125] Actual: 213 False  6.942526340484619\n",
      "Predicted: [110, 82] Actual: 214 False  7.1579155921936035\n",
      "Predicted: [110, 82] Actual: 215 False  7.190669536590576\n",
      "Predicted: [110, 82] Actual: 216 False  7.126245498657227\n",
      "Predicted: [125, 110] Actual: 217 False  8.342238426208496\n",
      "Predicted: [110, 125] Actual: 218 False  7.256322383880615\n",
      "Predicted: [125, 110] Actual: 219 False  8.188286781311035\n",
      "Predicted: [110, 125] Actual: 220 False  6.995180130004883\n",
      "Predicted: [110, 125] Actual: 221 False  7.140969276428223\n",
      "Predicted: [110, 82] Actual: 222 False  7.212504863739014\n",
      "Predicted: [110, 82] Actual: 223 False  7.659448146820068\n",
      "Predicted: [110, 125] Actual: 224 False  7.201414585113525\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.241242  [   64/ 8532]\n",
      "loss: 1.522958  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3123  size: 5689  main correct/size: 0.5489541219898049\n",
      "Also correct: 1062  size: 5689  also correct/size: 0.1866760414835648\n",
      "Test Error: Accuracy: 73.6%, Avg loss: 1.972315\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.095436  [   64/ 8532]\n",
      "loss: 1.525447  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3124  size: 5689  main correct/size: 0.5491298998066444\n",
      "Also correct: 1059  size: 5689  also correct/size: 0.18614870803304623\n",
      "Test Error: Accuracy: 73.5%, Avg loss: 1.972495\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.093903  [   64/ 8532]\n",
      "loss: 1.525713  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3124  size: 5689  main correct/size: 0.5491298998066444\n",
      "Also correct: 1059  size: 5689  also correct/size: 0.18614870803304623\n",
      "Test Error: Accuracy: 73.5%, Avg loss: 1.972254\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.092222  [   64/ 8532]\n",
      "loss: 1.525435  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3124  size: 5689  main correct/size: 0.5491298998066444\n",
      "Also correct: 1059  size: 5689  also correct/size: 0.18614870803304623\n",
      "Test Error: Accuracy: 73.5%, Avg loss: 1.971861\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 2.090605  [   64/ 8532]\n",
      "loss: 1.524978  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3125  size: 5689  main correct/size: 0.5493056776234839\n",
      "Also correct: 1058  size: 5689  also correct/size: 0.18597293021620673\n",
      "Test Error: Accuracy: 73.5%, Avg loss: 1.971376\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.647293567657471\n",
      "Predicted: [110, 82] Actual: 1  False  8.025059700012207\n",
      "Predicted: [110, 82] Actual: 2  False  7.9608473777771\n",
      "Predicted: [110, 82] Actual: 3  False  7.211662292480469\n",
      "Predicted: [110, 82] Actual: 4  False  7.513509273529053\n",
      "Predicted: [110, 82] Actual: 5  False  7.4916558265686035\n",
      "Predicted: [110, 82] Actual: 6  False  7.9741034507751465\n",
      "Predicted: [110, 82] Actual: 7  False  7.897172451019287\n",
      "Predicted: [110, 82] Actual: 8  False  7.530109882354736\n",
      "Predicted: [110, 82] Actual: 9  False  7.442294597625732\n",
      "Predicted: [110, 82] Actual: 10 False  8.112813949584961\n",
      "Predicted: [110, 82] Actual: 11 False  7.771463871002197\n",
      "Predicted: [110, 82] Actual: 12 False  8.06065845489502\n",
      "Predicted: [110, 82] Actual: 13 False  7.6328816413879395\n",
      "Predicted: [110, 82] Actual: 14 False  7.592997074127197\n",
      "Predicted: [110, 82] Actual: 15 False  7.473828315734863\n",
      "Predicted: [110, 82] Actual: 16 False  7.8574090003967285\n",
      "Predicted: [110, 82] Actual: 17 False  7.427066802978516\n",
      "Predicted: [110, 82] Actual: 18 False  7.4225640296936035\n",
      "Predicted: [110, 82] Actual: 19 False  7.670999050140381\n",
      "Predicted: [110, 82] Actual: 20 False  7.880029201507568\n",
      "Predicted: [110, 82] Actual: 21 False  7.836819648742676\n",
      "Predicted: [110, 82] Actual: 22 False  7.389869213104248\n",
      "Predicted: [110, 82] Actual: 23 False  7.7080464363098145\n",
      "Predicted: [110, 82] Actual: 24 False  7.240209102630615\n",
      "Predicted: [110, 82] Actual: 25 False  7.472413539886475\n",
      "Predicted: [110, 82] Actual: 26 False  7.782732963562012\n",
      "Predicted: [110, 82] Actual: 27 False  7.69713830947876\n",
      "Predicted: [110, 82] Actual: 28 False  7.8819193840026855\n",
      "Predicted: [110, 82] Actual: 29 False  7.634826183319092\n",
      "Predicted: [110, 82] Actual: 30 False  7.2694926261901855\n",
      "Predicted: [110, 82] Actual: 31 False  7.571583271026611\n",
      "Predicted: [110, 82] Actual: 32 False  7.596926212310791\n",
      "Predicted: [110, 82] Actual: 33 False  7.826686859130859\n",
      "Predicted: [110, 82] Actual: 34 False  7.81306791305542\n",
      "Predicted: [110, 82] Actual: 35 False  7.621270179748535\n",
      "Predicted: [110, 82] Actual: 36 False  8.01237678527832\n",
      "Predicted: [110, 125] Actual: 37 False  7.45979118347168\n",
      "Predicted: [110, 82] Actual: 38 False  7.918748378753662\n",
      "Predicted: [110, 82] Actual: 39 False  8.017967224121094\n",
      "Predicted: [110, 82] Actual: 40 False  7.795506000518799\n",
      "Predicted: [110, 82] Actual: 41 False  7.932974338531494\n",
      "Predicted: [110, 82] Actual: 42 False  7.73280143737793\n",
      "Predicted: [110, 82] Actual: 43 False  7.600112438201904\n",
      "Predicted: [110, 82] Actual: 44 False  7.911076068878174\n",
      "Predicted: [110, 82] Actual: 45 False  7.690459728240967\n",
      "Predicted: [110, 82] Actual: 46 False  7.792471885681152\n",
      "Predicted: [110, 82] Actual: 47 False  7.452366352081299\n",
      "Predicted: [110, 82] Actual: 48 False  7.783618927001953\n",
      "Predicted: [110, 82] Actual: 49 False  7.875689506530762\n",
      "Predicted: [110, 82] Actual: 50 False  7.828080177307129\n",
      "Predicted: [110, 82] Actual: 51 False  8.084983825683594\n",
      "Predicted: [110, 82] Actual: 52 False  7.546963691711426\n",
      "Predicted: [110, 82] Actual: 53 False  7.635979652404785\n",
      "Predicted: [110, 82] Actual: 54 False  7.527446269989014\n",
      "Predicted: [110, 82] Actual: 55 False  7.430370807647705\n",
      "Predicted: [110, 82] Actual: 56 False  7.260193347930908\n",
      "Predicted: [110, 82] Actual: 57 False  7.55136251449585\n",
      "Predicted: [110, 82] Actual: 58 False  7.360449314117432\n",
      "Predicted: [110, 82] Actual: 59 False  7.417858123779297\n",
      "Predicted: [110, 82] Actual: 60 False  7.372976303100586\n",
      "Predicted: [110, 82] Actual: 61 False  7.937469005584717\n",
      "Predicted: [110, 82] Actual: 62 False  7.54950475692749\n",
      "Predicted: [110, 82] Actual: 63 False  7.486605644226074\n",
      "Predicted: [110, 82] Actual: 64 False  7.528111934661865\n",
      "Predicted: [110, 82] Actual: 65 False  7.739758014678955\n",
      "Predicted: [110]   Actual: 66 False  8.755531311035156\n",
      "Predicted: [110]   Actual: 67 False  8.717914581298828\n",
      "Predicted: [110, 82] Actual: 68 False  8.108573913574219\n",
      "Predicted: [110, 82] Actual: 69 False  7.475035667419434\n",
      "Predicted: [110, 82] Actual: 70 False  7.842081546783447\n",
      "Predicted: [110, 82] Actual: 71 False  7.794845104217529\n",
      "Predicted: [110, 82] Actual: 72 False  7.515307903289795\n",
      "Predicted: [110, 82] Actual: 73 False  7.623215675354004\n",
      "Predicted: [110, 82] Actual: 74 False  7.966718673706055\n",
      "Predicted: [110, 82] Actual: 75 False  7.9250969886779785\n",
      "Predicted: [110, 82] Actual: 76 False  7.302398681640625\n",
      "Predicted: [110, 82] Actual: 77 False  7.312021255493164\n",
      "Predicted: [110, 82] Actual: 78 False  7.71083402633667\n",
      "Predicted: [110, 82] Actual: 79 False  7.613100051879883\n",
      "Predicted: [110]   Actual: 80 False  9.617977142333984\n",
      "Predicted: [110]   Actual: 81 False  8.691680908203125\n",
      "Predicted: [110]   Actual: 82 False  9.47128677368164\n",
      "Predicted: [110]   Actual: 83 False  8.732048988342285\n",
      "Predicted: [110, 82] Actual: 84 False  7.7238545417785645\n",
      "Predicted: [110, 82] Actual: 85 False  6.95374059677124\n",
      "Predicted: [110, 82] Actual: 86 False  7.603135108947754\n",
      "Predicted: [110, 82] Actual: 87 False  7.462341785430908\n",
      "Predicted: [110, 82] Actual: 88 False  7.5994439125061035\n",
      "Predicted: [110, 82] Actual: 89 False  7.805633068084717\n",
      "Predicted: [110, 82] Actual: 90 False  7.6703362464904785\n",
      "Predicted: [110, 82] Actual: 91 False  7.500649452209473\n",
      "Predicted: [110, 82] Actual: 92 False  7.685220718383789\n",
      "Predicted: [110, 82] Actual: 93 False  7.989792823791504\n",
      "Predicted: [110, 82] Actual: 94 False  7.029695510864258\n",
      "Predicted: [110]   Actual: 95 False  8.935614585876465\n",
      "Predicted: [110]   Actual: 96 False  9.703287124633789\n",
      "Predicted: [110]   Actual: 97 False  8.307622909545898\n",
      "Predicted: [110, 82] Actual: 98 False  7.996353626251221\n",
      "Predicted: [110, 82] Actual: 99 False  7.572117328643799\n",
      "Predicted: [110, 82] Actual: 100 False  7.687154293060303\n",
      "Predicted: [110]   Actual: 101 False  8.534689903259277\n",
      "Predicted: [110, 82] Actual: 102 False  7.469174861907959\n",
      "Predicted: [110, 82] Actual: 103 False  7.371826648712158\n",
      "Predicted: [110, 82] Actual: 104 False  7.712918758392334\n",
      "Predicted: [110, 82] Actual: 105 False  7.316664695739746\n",
      "Predicted: [110, 82] Actual: 106 False  7.645501613616943\n",
      "Predicted: [110, 82] Actual: 107 False  7.934398174285889\n",
      "Predicted: [110, 82] Actual: 108 False  7.845889091491699\n",
      "Predicted: [110]   Actual: 109 False  7.997107982635498\n",
      "Predicted: [110]   Actual: 110 True   21.172433853149414\n",
      "Predicted: [110, 82] Actual: 111 False  7.410014629364014\n",
      "Predicted: [110, 82] Actual: 112 False  7.602061748504639\n",
      "Predicted: [110, 82] Actual: 113 False  7.516211986541748\n",
      "Predicted: [110, 82] Actual: 114 False  7.523775577545166\n",
      "Predicted: [110, 82] Actual: 115 False  7.450015068054199\n",
      "Predicted: [110, 82] Actual: 116 False  7.6166253089904785\n",
      "Predicted: [110, 82] Actual: 117 False  7.037219524383545\n",
      "Predicted: [110, 82] Actual: 118 False  7.209660053253174\n",
      "Predicted: [110, 82] Actual: 119 False  7.987257957458496\n",
      "Predicted: [110, 82] Actual: 120 False  7.898606777191162\n",
      "Predicted: [110, 82] Actual: 121 False  7.450851917266846\n",
      "Predicted: [110, 82] Actual: 122 False  7.82139253616333\n",
      "Predicted: [110, 82] Actual: 123 False  7.807575702667236\n",
      "Predicted: [110, 82] Actual: 124 False  7.303081512451172\n",
      "Predicted: [125]   Actual: 125 True   161.99191284179688\n",
      "Predicted: [110, 82] Actual: 126 False  7.007296085357666\n",
      "Predicted: [110, 82] Actual: 127 False  7.715733051300049\n",
      "Predicted: [110, 82] Actual: 128 False  7.818141460418701\n",
      "Predicted: [110, 82] Actual: 129 False  7.6616597175598145\n",
      "Predicted: [110, 82] Actual: 130 False  7.526167392730713\n",
      "Predicted: [110, 82] Actual: 131 False  7.443667888641357\n",
      "Predicted: [110, 82] Actual: 132 False  7.157400608062744\n",
      "Predicted: [110, 82] Actual: 133 False  7.299988269805908\n",
      "Predicted: [110, 82] Actual: 134 False  7.497198104858398\n",
      "Predicted: [110, 82] Actual: 135 False  7.615219593048096\n",
      "Predicted: [110, 82] Actual: 136 False  8.120892524719238\n",
      "Predicted: [110, 82] Actual: 137 False  7.265161037445068\n",
      "Predicted: [110, 82] Actual: 138 False  7.632130146026611\n",
      "Predicted: [110, 82] Actual: 139 False  7.599997520446777\n",
      "Predicted: [110, 82] Actual: 140 False  8.135126113891602\n",
      "Predicted: [110]   Actual: 141 False  8.62932014465332\n",
      "Predicted: [110, 82] Actual: 142 False  7.381518840789795\n",
      "Predicted: [110, 82] Actual: 143 False  7.586740016937256\n",
      "Predicted: [110, 82] Actual: 144 False  7.504563808441162\n",
      "Predicted: [110, 82] Actual: 145 False  7.714671611785889\n",
      "Predicted: [110, 82] Actual: 146 False  8.203669548034668\n",
      "Predicted: [110, 82] Actual: 147 False  7.671389102935791\n",
      "Predicted: [110, 82] Actual: 148 False  7.912499904632568\n",
      "Predicted: [110, 82] Actual: 149 False  7.67210054397583\n",
      "Predicted: [110, 82] Actual: 150 False  7.552785396575928\n",
      "Predicted: [110, 82] Actual: 151 False  7.955679416656494\n",
      "Predicted: [110, 82] Actual: 152 False  7.75687837600708\n",
      "Predicted: [110, 82] Actual: 153 False  7.84132719039917\n",
      "Predicted: [110, 82] Actual: 154 False  7.633346080780029\n",
      "Predicted: [110, 82] Actual: 155 False  7.346689701080322\n",
      "Predicted: [110]   Actual: 156 False  8.322000503540039\n",
      "Predicted: [110, 82] Actual: 157 False  7.376589298248291\n",
      "Predicted: [110, 82] Actual: 158 False  7.544367790222168\n",
      "Predicted: [110, 82] Actual: 159 False  7.825328826904297\n",
      "Predicted: [110, 82] Actual: 160 False  7.544219493865967\n",
      "Predicted: [110, 82] Actual: 161 False  7.770399570465088\n",
      "Predicted: [110, 82] Actual: 162 False  7.2822699546813965\n",
      "Predicted: [110, 82] Actual: 163 False  7.621871471405029\n",
      "Predicted: [110, 82] Actual: 164 False  7.990572929382324\n",
      "Predicted: [110, 82] Actual: 165 False  7.787431240081787\n",
      "Predicted: [110, 82] Actual: 166 False  7.516843318939209\n",
      "Predicted: [110, 82] Actual: 167 False  7.417799472808838\n",
      "Predicted: [110, 125] Actual: 168 False  7.4491496086120605\n",
      "Predicted: [110, 82] Actual: 169 False  7.572336673736572\n",
      "Predicted: [110, 82] Actual: 170 False  8.089835166931152\n",
      "Predicted: [110, 82] Actual: 171 False  7.381646633148193\n",
      "Predicted: [110, 82] Actual: 172 False  7.9915242195129395\n",
      "Predicted: [110, 82] Actual: 173 False  7.084110260009766\n",
      "Predicted: [110]   Actual: 174 False  8.101638793945312\n",
      "Predicted: [110, 82] Actual: 175 False  7.942309856414795\n",
      "Predicted: [110, 82] Actual: 176 False  7.554214954376221\n",
      "Predicted: [110, 82] Actual: 177 False  7.494564056396484\n",
      "Predicted: [110, 82] Actual: 178 False  8.021825790405273\n",
      "Predicted: [110, 82] Actual: 179 False  7.767517566680908\n",
      "Predicted: [110, 82] Actual: 180 False  7.481373310089111\n",
      "Predicted: [110, 82] Actual: 181 False  7.7600531578063965\n",
      "Predicted: [110, 82] Actual: 182 False  7.536219120025635\n",
      "Predicted: [110, 82] Actual: 183 False  7.135735988616943\n",
      "Predicted: [110]   Actual: 184 False  8.031904220581055\n",
      "Predicted: [110, 82] Actual: 185 False  7.440883159637451\n",
      "Predicted: [110, 82] Actual: 186 False  8.274005889892578\n",
      "Predicted: [110, 82] Actual: 187 False  7.416506290435791\n",
      "Predicted: [110, 82] Actual: 188 False  7.884990215301514\n",
      "Predicted: [110, 82] Actual: 189 False  7.412062168121338\n",
      "Predicted: [110, 82] Actual: 190 False  7.699355602264404\n",
      "Predicted: [110, 82] Actual: 191 False  7.310399532318115\n",
      "Predicted: [110, 82] Actual: 192 False  7.926458835601807\n",
      "Predicted: [110, 82] Actual: 193 False  7.500921726226807\n",
      "Predicted: [110, 82] Actual: 194 False  7.814621448516846\n",
      "Predicted: [110, 82] Actual: 195 False  8.066109657287598\n",
      "Predicted: [110, 82] Actual: 196 False  7.501558780670166\n",
      "Predicted: [110, 82] Actual: 197 False  7.866876125335693\n",
      "Predicted: [110, 82] Actual: 198 False  7.751583576202393\n",
      "Predicted: [110, 82] Actual: 199 False  7.654485702514648\n",
      "Predicted: [110, 82] Actual: 200 False  7.465717792510986\n",
      "Predicted: [110, 82] Actual: 201 False  7.765462875366211\n",
      "Predicted: [110, 82] Actual: 202 False  7.7323808670043945\n",
      "Predicted: [110, 82] Actual: 203 False  7.591603755950928\n",
      "Predicted: [110, 82] Actual: 204 False  7.577212333679199\n",
      "Predicted: [110, 82] Actual: 205 False  7.511964321136475\n",
      "Predicted: [110, 82] Actual: 206 False  7.271358966827393\n",
      "Predicted: [110, 82] Actual: 207 False  7.8778862953186035\n",
      "Predicted: [110, 82] Actual: 208 False  7.571523666381836\n",
      "Predicted: [110, 82] Actual: 209 False  7.849050998687744\n",
      "Predicted: [110, 82] Actual: 210 False  7.7665910720825195\n",
      "Predicted: [110, 82] Actual: 211 False  7.6863017082214355\n",
      "Predicted: [110, 82] Actual: 212 False  7.526432514190674\n",
      "Predicted: [110, 82] Actual: 213 False  7.420928478240967\n",
      "Predicted: [110, 82] Actual: 214 False  7.638290882110596\n",
      "Predicted: [110, 82] Actual: 215 False  7.674173831939697\n",
      "Predicted: [110, 82] Actual: 216 False  7.600903034210205\n",
      "Predicted: [110, 82] Actual: 217 False  7.670229434967041\n",
      "Predicted: [110, 82] Actual: 218 False  7.760957717895508\n",
      "Predicted: [110, 82] Actual: 219 False  7.4844183921813965\n",
      "Predicted: [110, 82] Actual: 220 False  7.474941730499268\n",
      "Predicted: [110, 82] Actual: 221 False  7.6352033615112305\n",
      "Predicted: [110, 82] Actual: 222 False  7.70204496383667\n",
      "Predicted: [110, 82] Actual: 223 False  8.192026138305664\n",
      "Predicted: [110, 82] Actual: 224 False  7.688432693481445\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n",
      "Grid size: 15\n",
      "8532\n",
      "5689\n",
      "14221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.750037  [   64/ 8532]\n",
      "loss: 1.517719  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3191  size: 5689  main correct/size: 0.5609070135348919\n",
      "Also correct: 933  size: 5689  also correct/size: 0.16400070311126735\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 1.950100\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.675320  [   64/ 8532]\n",
      "loss: 1.515109  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3190  size: 5689  main correct/size: 0.5607312357180524\n",
      "Also correct: 932  size: 5689  also correct/size: 0.16382492529442785\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 1.950317\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.674636  [   64/ 8532]\n",
      "loss: 1.513732  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3190  size: 5689  main correct/size: 0.5607312357180524\n",
      "Also correct: 932  size: 5689  also correct/size: 0.16382492529442785\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 1.950279\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.674114  [   64/ 8532]\n",
      "loss: 1.512679  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3189  size: 5689  main correct/size: 0.5605554579012129\n",
      "Also correct: 934  size: 5689  also correct/size: 0.16417648092810688\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 1.950008\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "8532\n",
      "Training model\n",
      "loss: 1.673647  [   64/ 8532]\n",
      "loss: 1.511749  [ 6464/ 8532]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 3190  size: 5689  main correct/size: 0.5607312357180524\n",
      "Also correct: 933  size: 5689  also correct/size: 0.16400070311126735\n",
      "Test Error: Accuracy: 72.5%, Avg loss: 1.949638\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.471482276916504\n",
      "Predicted: [110, 82] Actual: 1  False  7.840111255645752\n",
      "Predicted: [110, 82] Actual: 2  False  7.7461066246032715\n",
      "Predicted: [110, 82] Actual: 3  False  6.992417335510254\n",
      "Predicted: [110, 82] Actual: 4  False  7.314394950866699\n",
      "Predicted: [110, 82] Actual: 5  False  7.298052787780762\n",
      "Predicted: [110, 82] Actual: 6  False  7.790417671203613\n",
      "Predicted: [110, 82] Actual: 7  False  7.705009937286377\n",
      "Predicted: [110, 82] Actual: 8  False  7.320556640625\n",
      "Predicted: [110, 82] Actual: 9  False  7.230450630187988\n",
      "Predicted: [110, 82] Actual: 10 False  7.926949501037598\n",
      "Predicted: [110, 82] Actual: 11 False  7.562033653259277\n",
      "Predicted: [110, 82] Actual: 12 False  7.894312858581543\n",
      "Predicted: [110, 82] Actual: 13 False  7.410165786743164\n",
      "Predicted: [110, 82] Actual: 14 False  7.372433662414551\n",
      "Predicted: [110, 82] Actual: 15 False  7.263188362121582\n",
      "Predicted: [110, 82] Actual: 16 False  7.6527299880981445\n",
      "Predicted: [110, 82] Actual: 17 False  7.211942672729492\n",
      "Predicted: [110, 82] Actual: 18 False  7.2191267013549805\n",
      "Predicted: [110, 82] Actual: 19 False  7.484790325164795\n",
      "Predicted: [110, 82] Actual: 20 False  7.664877891540527\n",
      "Predicted: [110, 82] Actual: 21 False  7.6373395919799805\n",
      "Predicted: [110, 125] Actual: 22 False  7.192224502563477\n",
      "Predicted: [110, 82] Actual: 23 False  7.506081581115723\n",
      "Predicted: [110, 82] Actual: 24 False  7.047339916229248\n",
      "Predicted: [110, 125] Actual: 25 False  7.277223587036133\n",
      "Predicted: [110, 82] Actual: 26 False  7.587551116943359\n",
      "Predicted: [110, 82] Actual: 27 False  7.495397567749023\n",
      "Predicted: [110, 82] Actual: 28 False  7.689169406890869\n",
      "Predicted: [110, 82] Actual: 29 False  7.435366630554199\n",
      "Predicted: [110, 82] Actual: 30 False  7.075199604034424\n",
      "Predicted: [110, 82] Actual: 31 False  7.380809307098389\n",
      "Predicted: [110, 82] Actual: 32 False  7.409212112426758\n",
      "Predicted: [110, 125] Actual: 33 False  7.625067234039307\n",
      "Predicted: [110, 82] Actual: 34 False  7.630975723266602\n",
      "Predicted: [110, 82] Actual: 35 False  7.407287120819092\n",
      "Predicted: [110, 82] Actual: 36 False  7.779631614685059\n",
      "Predicted: [125, 110] Actual: 37 False  8.2871732711792\n",
      "Predicted: [110, 82] Actual: 38 False  7.753048896789551\n",
      "Predicted: [110, 82] Actual: 39 False  7.80093240737915\n",
      "Predicted: [110, 82] Actual: 40 False  7.605330944061279\n",
      "Predicted: [110, 82] Actual: 41 False  7.749841690063477\n",
      "Predicted: [110, 82] Actual: 42 False  7.531562328338623\n",
      "Predicted: [125, 110] Actual: 43 False  7.707667827606201\n",
      "Predicted: [110, 82] Actual: 44 False  7.722815036773682\n",
      "Predicted: [110, 82] Actual: 45 False  7.498490810394287\n",
      "Predicted: [110, 82] Actual: 46 False  7.629399299621582\n",
      "Predicted: [110, 82] Actual: 47 False  7.235907077789307\n",
      "Predicted: [110, 82] Actual: 48 False  7.590875625610352\n",
      "Predicted: [110, 82] Actual: 49 False  7.631734371185303\n",
      "Predicted: [110, 82] Actual: 50 False  7.5947418212890625\n",
      "Predicted: [110, 82] Actual: 51 False  7.841038703918457\n",
      "Predicted: [110, 82] Actual: 52 False  7.3151960372924805\n",
      "Predicted: [110, 82] Actual: 53 False  7.42264461517334\n",
      "Predicted: [110, 125] Actual: 54 False  7.332944869995117\n",
      "Predicted: [110, 82] Actual: 55 False  7.2194414138793945\n",
      "Predicted: [110, 82] Actual: 56 False  7.053477764129639\n",
      "Predicted: [110, 82] Actual: 57 False  7.349453926086426\n",
      "Predicted: [110, 82] Actual: 58 False  7.157116889953613\n",
      "Predicted: [110, 82] Actual: 59 False  7.216876983642578\n",
      "Predicted: [110, 82] Actual: 60 False  7.165454864501953\n",
      "Predicted: [110, 82] Actual: 61 False  7.738055229187012\n",
      "Predicted: [110, 82] Actual: 62 False  7.348248481750488\n",
      "Predicted: [110, 82] Actual: 63 False  7.286659240722656\n",
      "Predicted: [110, 82] Actual: 64 False  7.305516242980957\n",
      "Predicted: [110, 82] Actual: 65 False  7.520881175994873\n",
      "Predicted: [110]   Actual: 66 False  8.542231559753418\n",
      "Predicted: [110]   Actual: 67 False  8.44297981262207\n",
      "Predicted: [110, 82] Actual: 68 False  7.884839057922363\n",
      "Predicted: [110, 82] Actual: 69 False  7.224116325378418\n",
      "Predicted: [110, 82] Actual: 70 False  7.657265663146973\n",
      "Predicted: [110, 125] Actual: 71 False  7.610297203063965\n",
      "Predicted: [110, 82] Actual: 72 False  7.328881740570068\n",
      "Predicted: [110, 82] Actual: 73 False  7.403021335601807\n",
      "Predicted: [110, 82] Actual: 74 False  7.771411418914795\n",
      "Predicted: [110, 82] Actual: 75 False  7.716547966003418\n",
      "Predicted: [110, 82] Actual: 76 False  7.084956169128418\n",
      "Predicted: [110, 82] Actual: 77 False  7.093789100646973\n",
      "Predicted: [110, 82] Actual: 78 False  7.514776229858398\n",
      "Predicted: [110, 82] Actual: 79 False  7.4011945724487305\n",
      "Predicted: [110]   Actual: 80 False  9.460742950439453\n",
      "Predicted: [110]   Actual: 81 False  8.467971801757812\n",
      "Predicted: [110]   Actual: 82 False  9.256179809570312\n",
      "Predicted: [110]   Actual: 83 False  8.531157493591309\n",
      "Predicted: [110, 82] Actual: 84 False  7.509405136108398\n",
      "Predicted: [110, 82] Actual: 85 False  6.708345413208008\n",
      "Predicted: [110, 82] Actual: 86 False  7.3612565994262695\n",
      "Predicted: [110, 82] Actual: 87 False  7.211435317993164\n",
      "Predicted: [110, 82] Actual: 88 False  7.379232883453369\n",
      "Predicted: [110, 82] Actual: 89 False  7.621337890625\n",
      "Predicted: [110, 82] Actual: 90 False  7.475617408752441\n",
      "Predicted: [110, 82] Actual: 91 False  7.299376010894775\n",
      "Predicted: [110, 82] Actual: 92 False  7.485896587371826\n",
      "Predicted: [110, 82] Actual: 93 False  7.819535255432129\n",
      "Predicted: [125, 110] Actual: 94 False  7.3284831047058105\n",
      "Predicted: [110]   Actual: 95 False  8.713579177856445\n",
      "Predicted: [110]   Actual: 96 False  9.548389434814453\n",
      "Predicted: [110]   Actual: 97 False  8.10589599609375\n",
      "Predicted: [110, 82] Actual: 98 False  7.800139427185059\n",
      "Predicted: [110, 82] Actual: 99 False  7.36738920211792\n",
      "Predicted: [110, 82] Actual: 100 False  7.473299026489258\n",
      "Predicted: [110]   Actual: 101 False  8.33523941040039\n",
      "Predicted: [110, 82] Actual: 102 False  7.269277572631836\n",
      "Predicted: [110, 82] Actual: 103 False  7.169812202453613\n",
      "Predicted: [110, 82] Actual: 104 False  7.515212059020996\n",
      "Predicted: [110, 82] Actual: 105 False  7.1071882247924805\n",
      "Predicted: [110, 82] Actual: 106 False  7.452970504760742\n",
      "Predicted: [110, 82] Actual: 107 False  7.748433589935303\n",
      "Predicted: [110, 82] Actual: 108 False  7.652730941772461\n",
      "Predicted: [110, 82] Actual: 109 False  7.740475654602051\n",
      "Predicted: [110]   Actual: 110 True   21.83945655822754\n",
      "Predicted: [110, 82] Actual: 111 False  7.171701908111572\n",
      "Predicted: [110, 125] Actual: 112 False  7.415404319763184\n",
      "Predicted: [110, 82] Actual: 113 False  7.305395126342773\n",
      "Predicted: [110, 82] Actual: 114 False  7.255885124206543\n",
      "Predicted: [110, 82] Actual: 115 False  7.219021797180176\n",
      "Predicted: [110, 82] Actual: 116 False  7.386837005615234\n",
      "Predicted: [110, 82] Actual: 117 False  6.810749530792236\n",
      "Predicted: [125, 110] Actual: 118 False  7.249946117401123\n",
      "Predicted: [110, 82] Actual: 119 False  7.816417217254639\n",
      "Predicted: [110, 82] Actual: 120 False  7.708713054656982\n",
      "Predicted: [110, 82] Actual: 121 False  7.243398666381836\n",
      "Predicted: [110, 82] Actual: 122 False  7.598106384277344\n",
      "Predicted: [110, 82] Actual: 123 False  7.617984294891357\n",
      "Predicted: [110, 82] Actual: 124 False  7.072723388671875\n",
      "Predicted: [125]   Actual: 125 True   163.4137725830078\n",
      "Predicted: [110, 82] Actual: 126 False  6.788789749145508\n",
      "Predicted: [110, 82] Actual: 127 False  7.480008125305176\n",
      "Predicted: [110, 82] Actual: 128 False  7.630753993988037\n",
      "Predicted: [110, 82] Actual: 129 False  7.416135311126709\n",
      "Predicted: [110, 82] Actual: 130 False  7.315058708190918\n",
      "Predicted: [110, 82] Actual: 131 False  7.235365867614746\n",
      "Predicted: [110, 82] Actual: 132 False  6.91349983215332\n",
      "Predicted: [125, 110] Actual: 133 False  7.654973983764648\n",
      "Predicted: [110, 82] Actual: 134 False  7.308188438415527\n",
      "Predicted: [110, 82] Actual: 135 False  7.409501075744629\n",
      "Predicted: [110, 82] Actual: 136 False  7.94420051574707\n",
      "Predicted: [125, 110] Actual: 137 False  7.675883769989014\n",
      "Predicted: [110, 125] Actual: 138 False  7.4473114013671875\n",
      "Predicted: [110, 82] Actual: 139 False  7.405241966247559\n",
      "Predicted: [110, 82] Actual: 140 False  7.897141456604004\n",
      "Predicted: [110]   Actual: 141 False  8.379148483276367\n",
      "Predicted: [110, 82] Actual: 142 False  7.185877799987793\n",
      "Predicted: [110, 82] Actual: 143 False  7.39247989654541\n",
      "Predicted: [110, 82] Actual: 144 False  7.303243637084961\n",
      "Predicted: [110, 82] Actual: 145 False  7.54577112197876\n",
      "Predicted: [110, 82] Actual: 146 False  8.031972885131836\n",
      "Predicted: [125, 110] Actual: 147 False  7.831376075744629\n",
      "Predicted: [110, 82] Actual: 148 False  7.692849159240723\n",
      "Predicted: [110, 82] Actual: 149 False  7.479125022888184\n",
      "Predicted: [110, 82] Actual: 150 False  7.345813751220703\n",
      "Predicted: [110, 82] Actual: 151 False  7.758392810821533\n",
      "Predicted: [110, 82] Actual: 152 False  7.563054084777832\n",
      "Predicted: [110, 82] Actual: 153 False  7.654422760009766\n",
      "Predicted: [110, 82] Actual: 154 False  7.410182476043701\n",
      "Predicted: [110, 82] Actual: 155 False  7.130306720733643\n",
      "Predicted: [110]   Actual: 156 False  8.12484073638916\n",
      "Predicted: [110, 82] Actual: 157 False  7.1292524337768555\n",
      "Predicted: [110, 82] Actual: 158 False  7.325366973876953\n",
      "Predicted: [110, 82] Actual: 159 False  7.635134220123291\n",
      "Predicted: [110, 82] Actual: 160 False  7.347068786621094\n",
      "Predicted: [110, 125] Actual: 161 False  7.597869396209717\n",
      "Predicted: [110, 125] Actual: 162 False  7.069025993347168\n",
      "Predicted: [110, 82] Actual: 163 False  7.424587249755859\n",
      "Predicted: [110, 82] Actual: 164 False  7.802146911621094\n",
      "Predicted: [110, 82] Actual: 165 False  7.606098175048828\n",
      "Predicted: [110, 82] Actual: 166 False  7.310004234313965\n",
      "Predicted: [110, 82] Actual: 167 False  7.2154693603515625\n",
      "Predicted: [125, 110] Actual: 168 False  8.08900260925293\n",
      "Predicted: [110, 82] Actual: 169 False  7.362612247467041\n",
      "Predicted: [110, 82] Actual: 170 False  7.901384353637695\n",
      "Predicted: [110, 82] Actual: 171 False  7.176855087280273\n",
      "Predicted: [110, 82] Actual: 172 False  7.792543411254883\n",
      "Predicted: [110, 82] Actual: 173 False  6.81771183013916\n",
      "Predicted: [110]   Actual: 174 False  7.89286994934082\n",
      "Predicted: [110, 82] Actual: 175 False  7.776324272155762\n",
      "Predicted: [110, 82] Actual: 176 False  7.338157653808594\n",
      "Predicted: [110, 82] Actual: 177 False  7.2941412925720215\n",
      "Predicted: [110, 82] Actual: 178 False  7.834961891174316\n",
      "Predicted: [110, 82] Actual: 179 False  7.571829319000244\n",
      "Predicted: [110, 82] Actual: 180 False  7.278095722198486\n",
      "Predicted: [110, 82] Actual: 181 False  7.556092739105225\n",
      "Predicted: [110, 82] Actual: 182 False  7.332376003265381\n",
      "Predicted: [110, 82] Actual: 183 False  6.922471046447754\n",
      "Predicted: [110, 82] Actual: 184 False  7.846035480499268\n",
      "Predicted: [110, 82] Actual: 185 False  7.233768939971924\n",
      "Predicted: [110, 82] Actual: 186 False  8.091144561767578\n",
      "Predicted: [110, 82] Actual: 187 False  7.1383466720581055\n",
      "Predicted: [110, 82] Actual: 188 False  7.674049377441406\n",
      "Predicted: [110, 82] Actual: 189 False  7.187385559082031\n",
      "Predicted: [110, 82] Actual: 190 False  7.500994682312012\n",
      "Predicted: [125, 110] Actual: 191 False  7.4376397132873535\n",
      "Predicted: [110, 82] Actual: 192 False  7.731821060180664\n",
      "Predicted: [110, 82] Actual: 193 False  7.314807415008545\n",
      "Predicted: [110, 82] Actual: 194 False  7.59466028213501\n",
      "Predicted: [110, 82] Actual: 195 False  7.880520820617676\n",
      "Predicted: [110, 82] Actual: 196 False  7.3074750900268555\n",
      "Predicted: [110, 125] Actual: 197 False  7.6994218826293945\n",
      "Predicted: [110, 82] Actual: 198 False  7.567747592926025\n",
      "Predicted: [110, 82] Actual: 199 False  7.460953235626221\n",
      "Predicted: [110, 82] Actual: 200 False  7.245386123657227\n",
      "Predicted: [110, 82] Actual: 201 False  7.570567607879639\n",
      "Predicted: [110, 125] Actual: 202 False  7.532500743865967\n",
      "Predicted: [110, 82] Actual: 203 False  7.360074996948242\n",
      "Predicted: [110, 82] Actual: 204 False  7.386270999908447\n",
      "Predicted: [110, 82] Actual: 205 False  7.2766265869140625\n",
      "Predicted: [110, 82] Actual: 206 False  7.055939197540283\n",
      "Predicted: [110, 82] Actual: 207 False  7.690011978149414\n",
      "Predicted: [110, 125] Actual: 208 False  7.375960350036621\n",
      "Predicted: [110, 82] Actual: 209 False  7.660178184509277\n",
      "Predicted: [110, 82] Actual: 210 False  7.585050582885742\n",
      "Predicted: [110, 82] Actual: 211 False  7.484950065612793\n",
      "Predicted: [110, 82] Actual: 212 False  7.3206682205200195\n",
      "Predicted: [110, 82] Actual: 213 False  7.212421417236328\n",
      "Predicted: [110, 82] Actual: 214 False  7.4387054443359375\n",
      "Predicted: [110, 82] Actual: 215 False  7.4765191078186035\n",
      "Predicted: [110, 82] Actual: 216 False  7.407871246337891\n",
      "Predicted: [110, 82] Actual: 217 False  7.480324745178223\n",
      "Predicted: [110, 82] Actual: 218 False  7.566483497619629\n",
      "Predicted: [110, 125] Actual: 219 False  7.263313293457031\n",
      "Predicted: [110, 82] Actual: 220 False  7.276796340942383\n",
      "Predicted: [110, 82] Actual: 221 False  7.442914962768555\n",
      "Predicted: [110, 82] Actual: 222 False  7.506991386413574\n",
      "Predicted: [110, 82] Actual: 223 False  7.969651222229004\n",
      "Predicted: [110, 82] Actual: 224 False  7.493464946746826\n",
      "Edge correct: 2    Size: 225  Edge correct/Size: 0.008888888888888889\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "grid_size = 15\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "chunk_amount = 14222\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "with open('output3.txt', 'a') as f:\n",
    "    for size in range(5, 20):\n",
    "        #grid_size = size\n",
    "        print(f'Grid size: {grid_size}')\n",
    "        f.write(f'Grid size: {grid_size}\\n')\n",
    "        f.write(f'Correct Tolerance {int(max(1, np.floor(grid_size/2)))}\\n')\n",
    "        f.write(f'Chunk Amount: {chunk_amount}\\n')\n",
    "        f.write('------------------------------------------\\n')\n",
    "        class AccidentDataset(Dataset):\n",
    "            def __init__(self, transform=None):\n",
    "                self.coordinates = data\n",
    "                self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "                \n",
    "                #split into 500 chunks using numpy\n",
    "                self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "                #process each chunk and merge it back into one dataframe\n",
    "                self.grids = []\n",
    "                grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "                grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "                grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "                grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "                for i in range(len(self.coordinates)-1):\n",
    "                    grid = np.zeros((grid_size, grid_size))\n",
    "                    for index, row in self.coordinates[i].iterrows():\n",
    "                        coordinates = row['latitude'], row['longitude']\n",
    "                        for j in range(grid_size):\n",
    "                            for k in range(grid_size):\n",
    "                                lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                                lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                                long_lower = grid_lower_long + k * grid_long_step\n",
    "                                long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                                if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                                    grid[j][k] += 1\n",
    "                                    break\n",
    "                    self.grids.append(grid/chunk_size)\n",
    "                self.grids = np.array(self.grids)\n",
    "                self.transform = transform      \n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.grids)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                if torch.is_tensor(idx):\n",
    "                    idx = idx.tolist()\n",
    "\n",
    "                grid = self.grids[idx]\n",
    "                grid = torch.from_numpy(grid).float()\n",
    "\n",
    "                max_index = np.argmax(grid)\n",
    "                max_index = np.array(max_index)\n",
    "                return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "        accident_dataset = AccidentDataset()\n",
    "\n",
    "        #Create new array with 60% of the data\n",
    "        train_size = int(0.6 * len(accident_dataset))\n",
    "        test_size = len(accident_dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "        print(len(train_dataset))\n",
    "        print(len(test_dataset))\n",
    "        print(len(accident_dataset))\n",
    "\n",
    "        #Create dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        class Network(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                #x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        # building the model object\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        #device = torch.device('cpu')\n",
    "        print(f'Using {device} device')\n",
    "\n",
    "        model = Network().to(device)\n",
    "        if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "            model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "            print(f\"Loaded model from model{grid_size}.pth\")\n",
    "        else:\n",
    "            print(\"No model found, creating new model\")\n",
    "\n",
    "        # define the loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "        # define the training loop\n",
    "        def train(dataloader, model, loss_fn, optimizer):\n",
    "            size = len(dataloader.dataset)\n",
    "            print(size)\n",
    "            model.train()\n",
    "            print(\"Training model\")\n",
    "            for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                #print('pred ', pred)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"Finished training model\")\n",
    "\n",
    "        def test(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "            print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "        def logtest(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            f.write(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\\n\")\n",
    "            f.write(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\\n\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            f.write(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "        \n",
    "        epochs = 5\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        logtest(test_dataloader, model, loss_fn)\n",
    "        torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "        print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "        model.eval()\n",
    "        edge_correct = 0\n",
    "        f.write('------------------------------------------\\nEdge cases:\\n')\n",
    "        print('------------------------------------------\\nEdge cases:')\n",
    "        for i in range (grid_size ** 2):\n",
    "            randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "            edge = np.zeros(grid_size ** 2)\n",
    "            edge[i] = 1\n",
    "            x, y = torch.tensor(edge).float(), i\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model(x.to(device))\n",
    "                #print(pred)\n",
    "                predicted, actual = pred.topk(grid_size), y\n",
    "                max_value = pred.max(0)[0]\n",
    "                index = []\n",
    "                for j in range(len(predicted)):\n",
    "                    if predicted.values[j].item() >= 0.8 * max_value:\n",
    "                        index.append(predicted.indices[j].item())\n",
    "                part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "                part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "                part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "                part4 = f'{max_value}'.ljust(10, ' ')\n",
    "                print(part1, part2, part3, part4)\n",
    "                f.write(part1 + part2 + part3 + part4 + '\\n')\n",
    "                #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "                edge_correct += actual in index\n",
    "        f.write('------------------------------------------\\n')\n",
    "        edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "        edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "        edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "        print(edgestr1, edgestr2, edgestr3)\n",
    "        f.write(edgestr1 + edgestr2 + edgestr3 + '\\n')\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
