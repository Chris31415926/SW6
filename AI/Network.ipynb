{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9892de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450620000.0, '40.6720753', '-73.9113364']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "grid_size = 5\n",
    "chunk_amount = 85555\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.coordinates = data\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        \n",
    "        #split into 500 chunks using numpy\n",
    "        self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "        #process each chunk and merge it back into one dataframe\n",
    "        self.grids = []\n",
    "        grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "        grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "        grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "        grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "        for i in range(len(self.coordinates)-1):\n",
    "            grid = np.zeros((grid_size, grid_size))\n",
    "            for index, row in self.coordinates[i].iterrows():\n",
    "                coordinates = row['latitude'], row['longitude']\n",
    "                for j in range(grid_size):\n",
    "                    for k in range(grid_size):\n",
    "                        lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                        lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                        long_lower = grid_lower_long + k * grid_long_step\n",
    "                        long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                        if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                            grid[j][k] += 1\n",
    "                            break\n",
    "            self.grids.append(grid/chunk_size)\n",
    "        self.grids = np.array(self.grids)\n",
    "        self.transform = transform      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        grid = self.grids[idx]\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "\n",
    "        max_index = np.argmax(grid)\n",
    "        max_index = np.array(max_index)\n",
    "        return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "accident_dataset = AccidentDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f366a4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accident_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55240\\1389412538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create new array with 60% of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accident_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.6 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# define the class for multilinear regression\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(grid_size ** 2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, grid_size ** 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# define the class for multilinear regression\n",
    "# building the model object\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network().to(device)\n",
    "if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "    model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "    print(f\"Loaded model from model{grid_size}.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# define the training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print('pred ', pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    print(\"Testing model\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, also_correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print('y ', y)\n",
    "            #print('predition', pred.argmax(1))\n",
    "\n",
    "            #check if prediction is correct\n",
    "            predictions = torch.topk(pred, 2, dim=1).indices\n",
    "            #is_correct = (pred.argmax(1) == y or pred.argmax(1) == max_value)\n",
    "\n",
    "            for i in range (len(predictions)):\n",
    "                if y[i] in predictions[i]:\n",
    "                    if y[i] == pred.argmax(1)[i]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        also_correct += 1\n",
    "\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            #print(correct)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "    print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "    correct += also_correct\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "epochs = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "model.eval()\n",
    "edge_correct = 0\n",
    "for i in range (grid_size ** 2):\n",
    "    randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "    #randomnumber = 86903\n",
    "    #print(randomnumber)\n",
    "    #x, y = test_dataset[randomnumber][0], test_dataset[randomnumber][1]\n",
    "    edge = np.zeros(grid_size ** 2)\n",
    "    edge[i] = 1\n",
    "    x, y = torch.tensor(edge).float(), i\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.to(device))\n",
    "        #print(pred)\n",
    "        predicted, actual = pred.topk(grid_size), y\n",
    "        max_value = pred.max(0)[0]\n",
    "        index = []\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted.values[i].item() >= 0.8 * max_value:\n",
    "                index.append(predicted.indices[i].item())\n",
    "        part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "        part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "        part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "        part4 = f'{max_value}'.ljust(10, ' ')\n",
    "        print(part1, part2, part3, part4)\n",
    "        #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "        edge_correct += actual in index\n",
    "print('------------------------------------------')\n",
    "edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "print(edgestr1, edgestr2, edgestr3)\n",
    "#print(f\"Edge correct: {edge_correct}  size: {25}  edge correct/size: {edge_correct/25}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d3e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1547704800.0, '40.729034', '-73.74387']\n",
      "Grid size: 15\n",
      "6132\n",
      "4089\n",
      "10221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.608576  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2837  size: 4089  main correct/size: 0.6938126681340181\n",
      "Also correct: 518  size: 4089  also correct/size: 0.12668134018097335\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 1.353976\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.625277  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2840  size: 4089  main correct/size: 0.6945463438493519\n",
      "Also correct: 514  size: 4089  also correct/size: 0.12570310589386158\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 1.352881\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.630225  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2840  size: 4089  main correct/size: 0.6945463438493519\n",
      "Also correct: 515  size: 4089  also correct/size: 0.12594766446563951\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 1.352216\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.633582  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2842  size: 4089  main correct/size: 0.6950354609929078\n",
      "Also correct: 513  size: 4089  also correct/size: 0.12545854732208364\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 1.351633\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.635718  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2843  size: 4089  main correct/size: 0.6952800195646858\n",
      "Also correct: 512  size: 4089  also correct/size: 0.1252139887503057\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 1.351039\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.0618109703063965\n",
      "Predicted: [110, 82] Actual: 1  False  7.797226428985596\n",
      "Predicted: [110, 82] Actual: 2  False  7.282933712005615\n",
      "Predicted: [82, 96] Actual: 3  False  6.934675693511963\n",
      "Predicted: [82, 96] Actual: 4  False  6.948237895965576\n",
      "Predicted: [82, 110] Actual: 5  False  6.7610249519348145\n",
      "Predicted: [110, 82] Actual: 6  False  7.665652275085449\n",
      "Predicted: [110, 82] Actual: 7  False  7.392156600952148\n",
      "Predicted: [82, 96] Actual: 8  False  6.9851861000061035\n",
      "Predicted: [82, 96] Actual: 9  False  7.015983581542969\n",
      "Predicted: [110, 82] Actual: 10 False  7.722469806671143\n",
      "Predicted: [82, 110] Actual: 11 False  6.889134883880615\n",
      "Predicted: [110, 82] Actual: 12 False  8.077949523925781\n",
      "Predicted: [82, 141] Actual: 13 False  6.88539457321167\n",
      "Predicted: [82, 141] Actual: 14 False  6.865234851837158\n",
      "Predicted: [82, 96] Actual: 15 False  6.940520286560059\n",
      "Predicted: [110, 82] Actual: 16 False  7.317851543426514\n",
      "Predicted: [82, 96] Actual: 17 False  6.8978095054626465\n",
      "Predicted: [82, 96] Actual: 18 False  6.8255462646484375\n",
      "Predicted: [82, 110] Actual: 19 False  6.980760097503662\n",
      "Predicted: [82, 110] Actual: 20 False  6.948317050933838\n",
      "Predicted: [110, 82] Actual: 21 False  7.628875255584717\n",
      "Predicted: [125, 82] Actual: 22 False  7.741147518157959\n",
      "Predicted: [82, 110] Actual: 23 False  6.936047077178955\n",
      "Predicted: [82, 96] Actual: 24 False  6.70530891418457\n",
      "Predicted: [82, 96] Actual: 25 False  6.968207836151123\n",
      "Predicted: [110, 82] Actual: 26 False  7.156631946563721\n",
      "Predicted: [110, 82] Actual: 27 False  6.926212787628174\n",
      "Predicted: [110, 82] Actual: 28 False  7.333324909210205\n",
      "Predicted: [82, 96] Actual: 29 False  6.9679131507873535\n",
      "Predicted: [82, 141] Actual: 30 False  6.938573360443115\n",
      "Predicted: [82, 110] Actual: 31 False  6.8463544845581055\n",
      "Predicted: [82, 110] Actual: 32 False  6.8381853103637695\n",
      "Predicted: [125, 110] Actual: 33 False  7.666143894195557\n",
      "Predicted: [110, 82] Actual: 34 False  6.887296199798584\n",
      "Predicted: [82, 141] Actual: 35 False  6.784931659698486\n",
      "Predicted: [110, 82] Actual: 36 False  7.2096123695373535\n",
      "Predicted: [125, 82] Actual: 37 False  7.265554904937744\n",
      "Predicted: [110, 82] Actual: 38 False  7.661405563354492\n",
      "Predicted: [110, 82] Actual: 39 False  7.3046369552612305\n",
      "Predicted: [110, 82] Actual: 40 False  7.225451469421387\n",
      "Predicted: [110, 82] Actual: 41 False  7.789519786834717\n",
      "Predicted: [110, 82] Actual: 42 False  7.096757411956787\n",
      "Predicted: [110, 82] Actual: 43 False  7.267123699188232\n",
      "Predicted: [110, 82] Actual: 44 False  7.481500625610352\n",
      "Predicted: [82, 110] Actual: 45 False  6.9012980461120605\n",
      "Predicted: [110, 82] Actual: 46 False  7.12681770324707\n",
      "Predicted: [82, 96] Actual: 47 False  6.882089138031006\n",
      "Predicted: [82, 110] Actual: 48 False  6.904392719268799\n",
      "Predicted: [82, 141] Actual: 49 False  7.075399875640869\n",
      "Predicted: [82, 110] Actual: 50 False  6.848458766937256\n",
      "Predicted: [82, 110] Actual: 51 False  6.825586795806885\n",
      "Predicted: [82, 141] Actual: 52 False  6.896825313568115\n",
      "Predicted: [82, 110] Actual: 53 False  6.918571949005127\n",
      "Predicted: [125, 82] Actual: 54 False  7.3253278732299805\n",
      "Predicted: [82, 96] Actual: 55 False  6.904086589813232\n",
      "Predicted: [82, 96] Actual: 56 False  6.91344690322876\n",
      "Predicted: [82, 110] Actual: 57 False  6.837728977203369\n",
      "Predicted: [82, 96] Actual: 58 False  6.8114824295043945\n",
      "Predicted: [82, 96] Actual: 59 False  6.759857654571533\n",
      "Predicted: [82, 110] Actual: 60 False  6.784893989562988\n",
      "Predicted: [110, 82] Actual: 61 False  7.64475154876709\n",
      "Predicted: [82, 110] Actual: 62 False  6.913018703460693\n",
      "Predicted: [82, 96] Actual: 63 False  6.92048978805542\n",
      "Predicted: [82, 96] Actual: 64 False  6.822079181671143\n",
      "Predicted: [110, 82] Actual: 65 False  7.07832670211792\n",
      "Predicted: [110, 82] Actual: 66 False  8.334990501403809\n",
      "Predicted: [82, 110] Actual: 67 False  7.192650318145752\n",
      "Predicted: [82, 110] Actual: 68 False  6.897222518920898\n",
      "Predicted: [82, 96] Actual: 69 False  6.903470516204834\n",
      "Predicted: [110, 82] Actual: 70 False  7.323710918426514\n",
      "Predicted: [110, 82] Actual: 71 False  7.578751087188721\n",
      "Predicted: [110, 82] Actual: 72 False  6.895596027374268\n",
      "Predicted: [82, 110] Actual: 73 False  6.987939357757568\n",
      "Predicted: [110, 82] Actual: 74 False  7.482532024383545\n",
      "Predicted: [110, 82] Actual: 75 False  7.219467639923096\n",
      "Predicted: [82, 96] Actual: 76 False  6.961044788360596\n",
      "Predicted: [82, 141] Actual: 77 False  6.690330982208252\n",
      "Predicted: [110, 82] Actual: 78 False  6.8948845863342285\n",
      "Predicted: [82, 110] Actual: 79 False  6.989939212799072\n",
      "Predicted: [110]   Actual: 80 False  9.051155090332031\n",
      "Predicted: [82, 141] Actual: 81 False  7.229907989501953\n",
      "Predicted: [82, 141] Actual: 82 True   7.545736789703369\n",
      "Predicted: [110, 82] Actual: 83 False  7.348349094390869\n",
      "Predicted: [82, 110] Actual: 84 False  6.694020748138428\n",
      "Predicted: [82, 141] Actual: 85 False  6.768131732940674\n",
      "Predicted: [82, 141] Actual: 86 False  6.886441707611084\n",
      "Predicted: [82, 141] Actual: 87 False  6.981995105743408\n",
      "Predicted: [82, 110] Actual: 88 False  6.652832508087158\n",
      "Predicted: [110, 82] Actual: 89 False  7.389235019683838\n",
      "Predicted: [110, 82] Actual: 90 False  6.967556476593018\n",
      "Predicted: [82, 96] Actual: 91 False  6.867429256439209\n",
      "Predicted: [110, 82] Actual: 92 False  6.894974231719971\n",
      "Predicted: [110, 82] Actual: 93 False  7.622476100921631\n",
      "Predicted: [125]   Actual: 94 False  9.305055618286133\n",
      "Predicted: [110, 82] Actual: 95 False  7.662675380706787\n",
      "Predicted: [110, 82] Actual: 96 False  8.601916313171387\n",
      "Predicted: [82, 110] Actual: 97 False  6.6645026206970215\n",
      "Predicted: [110, 82] Actual: 98 False  7.160170078277588\n",
      "Predicted: [82, 110] Actual: 99 False  6.693052768707275\n",
      "Predicted: [82, 110] Actual: 100 False  7.056929111480713\n",
      "Predicted: [82, 141] Actual: 101 False  6.928995609283447\n",
      "Predicted: [82, 110] Actual: 102 False  6.776938438415527\n",
      "Predicted: [82, 125] Actual: 103 False  6.886234283447266\n",
      "Predicted: [125, 82] Actual: 104 False  7.448071479797363\n",
      "Predicted: [82, 96] Actual: 105 False  6.911922931671143\n",
      "Predicted: [82, 110] Actual: 106 False  6.766679286956787\n",
      "Predicted: [110, 82] Actual: 107 False  7.523386001586914\n",
      "Predicted: [110, 82] Actual: 108 False  7.221220016479492\n",
      "Predicted: [82, 141] Actual: 109 False  6.774410724639893\n",
      "Predicted: [110]   Actual: 110 True   56.62519454956055\n",
      "Predicted: [82, 96] Actual: 111 False  6.860593795776367\n",
      "Predicted: [110, 82] Actual: 112 False  7.138774394989014\n",
      "Predicted: [82, 96] Actual: 113 False  6.858664035797119\n",
      "Predicted: [82, 141] Actual: 114 False  6.762932777404785\n",
      "Predicted: [82, 141] Actual: 115 False  6.7754950523376465\n",
      "Predicted: [82, 141] Actual: 116 False  6.939483165740967\n",
      "Predicted: [82, 141] Actual: 117 False  6.903162479400635\n",
      "Predicted: [82, 125] Actual: 118 False  6.825003147125244\n",
      "Predicted: [110, 82] Actual: 119 False  7.830345630645752\n",
      "Predicted: [110, 82] Actual: 120 False  7.3193888664245605\n",
      "Predicted: [82, 96] Actual: 121 False  6.969752788543701\n",
      "Predicted: [110, 82] Actual: 122 False  7.040836811065674\n",
      "Predicted: [110, 82] Actual: 123 False  7.341972827911377\n",
      "Predicted: [82, 141] Actual: 124 False  6.864755153656006\n",
      "Predicted: [125]   Actual: 125 True   172.05873107910156\n",
      "Predicted: [82, 141] Actual: 126 False  6.8546624183654785\n",
      "Predicted: [82, 141] Actual: 127 False  6.843786716461182\n",
      "Predicted: [110, 82] Actual: 128 False  7.318049430847168\n",
      "Predicted: [82, 110] Actual: 129 False  6.908446788787842\n",
      "Predicted: [82, 96] Actual: 130 False  6.912412643432617\n",
      "Predicted: [82, 96] Actual: 131 False  6.8578009605407715\n",
      "Predicted: [82, 96] Actual: 132 False  6.864019870758057\n",
      "Predicted: [125, 82] Actual: 133 False  7.807632923126221\n",
      "Predicted: [82, 96] Actual: 134 False  6.881763935089111\n",
      "Predicted: [82, 110] Actual: 135 False  6.899289608001709\n",
      "Predicted: [110, 82] Actual: 136 False  7.977209568023682\n",
      "Predicted: [125, 82] Actual: 137 False  7.730233192443848\n",
      "Predicted: [125, 110] Actual: 138 False  7.541989803314209\n",
      "Predicted: [110, 82] Actual: 139 False  6.956238269805908\n",
      "Predicted: [82, 141] Actual: 140 False  6.999292850494385\n",
      "Predicted: [82, 141] Actual: 141 True   7.121358871459961\n",
      "Predicted: [82, 110] Actual: 142 False  6.675011157989502\n",
      "Predicted: [82, 96] Actual: 143 False  6.857690811157227\n",
      "Predicted: [82, 110] Actual: 144 False  6.772338390350342\n",
      "Predicted: [110, 82] Actual: 145 False  7.086949825286865\n",
      "Predicted: [110, 82] Actual: 146 False  8.008841514587402\n",
      "Predicted: [125]   Actual: 147 False  9.123531341552734\n",
      "Predicted: [82, 110] Actual: 148 False  6.981924533843994\n",
      "Predicted: [82, 110] Actual: 149 False  6.905301570892334\n",
      "Predicted: [82, 96] Actual: 150 False  6.927529335021973\n",
      "Predicted: [110, 82] Actual: 151 False  7.18373441696167\n",
      "Predicted: [82, 110] Actual: 152 False  7.073554039001465\n",
      "Predicted: [110, 82] Actual: 153 False  7.570945739746094\n",
      "Predicted: [82, 141] Actual: 154 False  6.9503560066223145\n",
      "Predicted: [82, 125] Actual: 155 False  6.8672709465026855\n",
      "Predicted: [82, 141] Actual: 156 False  6.975582599639893\n",
      "Predicted: [82, 141] Actual: 157 False  6.819741725921631\n",
      "Predicted: [82, 96] Actual: 158 False  6.975154876708984\n",
      "Predicted: [82, 110] Actual: 159 False  6.967996120452881\n",
      "Predicted: [82, 110] Actual: 160 False  6.753624439239502\n",
      "Predicted: [110, 125] Actual: 161 False  7.352919101715088\n",
      "Predicted: [125, 82] Actual: 162 False  7.007371425628662\n",
      "Predicted: [82, 110] Actual: 163 False  6.906095027923584\n",
      "Predicted: [110, 82] Actual: 164 False  7.524875164031982\n",
      "Predicted: [110, 82] Actual: 165 False  7.333652973175049\n",
      "Predicted: [82, 96] Actual: 166 False  6.906464099884033\n",
      "Predicted: [82, 96] Actual: 167 False  6.9693379402160645\n",
      "Predicted: [125, 82] Actual: 168 False  8.3711576461792\n",
      "Predicted: [82, 96] Actual: 169 False  6.9842023849487305\n",
      "Predicted: [110, 82] Actual: 170 False  7.733780384063721\n",
      "Predicted: [82, 141] Actual: 171 False  6.6589274406433105\n",
      "Predicted: [82, 110] Actual: 172 False  6.9948930740356445\n",
      "Predicted: [82, 141] Actual: 173 False  6.8167595863342285\n",
      "Predicted: [110, 82] Actual: 174 False  7.116441249847412\n",
      "Predicted: [110, 82] Actual: 175 False  7.734353542327881\n",
      "Predicted: [125, 82] Actual: 176 False  7.063535213470459\n",
      "Predicted: [82, 110] Actual: 177 False  6.6943230628967285\n",
      "Predicted: [110, 82] Actual: 178 False  7.579300403594971\n",
      "Predicted: [82, 110] Actual: 179 False  7.042652130126953\n",
      "Predicted: [82, 96] Actual: 180 False  6.962701320648193\n",
      "Predicted: [110, 82] Actual: 181 False  6.880581855773926\n",
      "Predicted: [82, 141] Actual: 182 False  6.821349620819092\n",
      "Predicted: [82, 96] Actual: 183 False  6.81619930267334\n",
      "Predicted: [110, 82] Actual: 184 False  7.746290683746338\n",
      "Predicted: [82, 141] Actual: 185 False  6.802866458892822\n",
      "Predicted: [110, 82] Actual: 186 False  7.8486762046813965\n",
      "Predicted: [82, 141] Actual: 187 False  6.948774814605713\n",
      "Predicted: [82, 141] Actual: 188 False  6.94926118850708\n",
      "Predicted: [82, 96] Actual: 189 False  6.8179030418396\n",
      "Predicted: [110, 82] Actual: 190 False  7.000133514404297\n",
      "Predicted: [125, 82] Actual: 191 False  8.252217292785645\n",
      "Predicted: [110, 82] Actual: 192 False  7.333850383758545\n",
      "Predicted: [82, 110] Actual: 193 False  6.768971920013428\n",
      "Predicted: [110, 82] Actual: 194 False  7.165684700012207\n",
      "Predicted: [110, 82] Actual: 195 False  7.615261554718018\n",
      "Predicted: [82, 110] Actual: 196 False  6.919738292694092\n",
      "Predicted: [110, 125] Actual: 197 False  7.8442277908325195\n",
      "Predicted: [110, 82] Actual: 198 False  7.288558483123779\n",
      "Predicted: [110, 82] Actual: 199 False  6.911214828491211\n",
      "Predicted: [82, 141] Actual: 200 False  6.745876789093018\n",
      "Predicted: [110, 82] Actual: 201 False  6.958345890045166\n",
      "Predicted: [110, 82] Actual: 202 False  7.240929126739502\n",
      "Predicted: [82, 141] Actual: 203 False  6.962105751037598\n",
      "Predicted: [125, 82] Actual: 204 False  7.216178894042969\n",
      "Predicted: [82, 96] Actual: 205 False  6.897002220153809\n",
      "Predicted: [82, 96] Actual: 206 False  6.72124719619751\n",
      "Predicted: [110, 82] Actual: 207 False  7.5349249839782715\n",
      "Predicted: [82, 110] Actual: 208 False  6.8998188972473145\n",
      "Predicted: [110, 82] Actual: 209 False  7.2391533851623535\n",
      "Predicted: [110, 82] Actual: 210 False  7.232813358306885\n",
      "Predicted: [82, 110] Actual: 211 False  6.882136821746826\n",
      "Predicted: [82, 96] Actual: 212 False  6.969438076019287\n",
      "Predicted: [82, 96] Actual: 213 False  6.8299031257629395\n",
      "Predicted: [82, 141] Actual: 214 False  6.960014343261719\n",
      "Predicted: [110, 82] Actual: 215 False  6.905964374542236\n",
      "Predicted: [82, 110] Actual: 216 False  6.922558307647705\n",
      "Predicted: [110, 125] Actual: 217 False  7.158815860748291\n",
      "Predicted: [110, 82] Actual: 218 False  6.998632431030273\n",
      "Predicted: [82, 125] Actual: 219 False  6.939300060272217\n",
      "Predicted: [82, 96] Actual: 220 False  7.0425238609313965\n",
      "Predicted: [110, 82] Actual: 221 False  6.820371627807617\n",
      "Predicted: [110, 82] Actual: 222 False  6.8020853996276855\n",
      "Predicted: [110, 82] Actual: 223 False  7.572273254394531\n",
      "Predicted: [110, 82] Actual: 224 False  6.933574199676514\n",
      "Edge correct: 4    Size: 225  Edge correct/Size: 0.017777777777777778\n",
      "Grid size: 15\n",
      "6132\n",
      "4089\n",
      "10221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.240320  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2817  size: 4089  main correct/size: 0.6889214966984593\n",
      "Also correct: 554  size: 4089  also correct/size: 0.1354854487649792\n",
      "Test Error: Accuracy: 82.4%, Avg loss: 1.381837\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.267038  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2817  size: 4089  main correct/size: 0.6889214966984593\n",
      "Also correct: 551  size: 4089  also correct/size: 0.1347517730496454\n",
      "Test Error: Accuracy: 82.4%, Avg loss: 1.382119\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.264817  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2815  size: 4089  main correct/size: 0.6884323795549034\n",
      "Also correct: 549  size: 4089  also correct/size: 0.13426265590608952\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.381939\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.262808  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2815  size: 4089  main correct/size: 0.6884323795549034\n",
      "Also correct: 551  size: 4089  also correct/size: 0.1347517730496454\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.381534\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.261088  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2815  size: 4089  main correct/size: 0.6884323795549034\n",
      "Also correct: 550  size: 4089  also correct/size: 0.13450721447786745\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.380940\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.1086931228637695\n",
      "Predicted: [110, 82] Actual: 1  False  7.880878448486328\n",
      "Predicted: [110, 82] Actual: 2  False  7.343733787536621\n",
      "Predicted: [82, 96] Actual: 3  False  6.850244998931885\n",
      "Predicted: [82, 96] Actual: 4  False  6.858169078826904\n",
      "Predicted: [82, 96] Actual: 5  False  6.673762798309326\n",
      "Predicted: [110, 82] Actual: 6  False  7.718864917755127\n",
      "Predicted: [110, 82] Actual: 7  False  7.433643817901611\n",
      "Predicted: [82, 96] Actual: 8  False  6.8940653800964355\n",
      "Predicted: [82, 96] Actual: 9  False  6.925233840942383\n",
      "Predicted: [110, 82] Actual: 10 False  7.785528659820557\n",
      "Predicted: [110, 82] Actual: 11 False  6.854188442230225\n",
      "Predicted: [110, 82] Actual: 12 False  8.1476469039917\n",
      "Predicted: [82, 96] Actual: 13 False  6.798387050628662\n",
      "Predicted: [82, 96] Actual: 14 False  6.778631687164307\n",
      "Predicted: [82, 96] Actual: 15 False  6.849524021148682\n",
      "Predicted: [110, 82] Actual: 16 False  7.356432914733887\n",
      "Predicted: [82, 96] Actual: 17 False  6.810657978057861\n",
      "Predicted: [82, 96] Actual: 18 False  6.736974239349365\n",
      "Predicted: [82, 110] Actual: 19 False  6.890368938446045\n",
      "Predicted: [110, 82] Actual: 20 False  6.9758710861206055\n",
      "Predicted: [110, 82] Actual: 21 False  7.646190166473389\n",
      "Predicted: [125, 82] Actual: 22 False  7.4865827560424805\n",
      "Predicted: [82, 110] Actual: 23 False  6.847494602203369\n",
      "Predicted: [82, 96] Actual: 24 False  6.6184983253479\n",
      "Predicted: [82, 96] Actual: 25 False  6.874878406524658\n",
      "Predicted: [110, 82] Actual: 26 False  7.186551570892334\n",
      "Predicted: [110, 82] Actual: 27 False  6.961709022521973\n",
      "Predicted: [110, 82] Actual: 28 False  7.378417491912842\n",
      "Predicted: [82, 96] Actual: 29 False  6.8761467933654785\n",
      "Predicted: [82, 96] Actual: 30 False  6.852621078491211\n",
      "Predicted: [110, 82] Actual: 31 False  6.7673563957214355\n",
      "Predicted: [110, 82] Actual: 32 False  6.785983562469482\n",
      "Predicted: [110, 125] Actual: 33 False  7.336729526519775\n",
      "Predicted: [110, 82] Actual: 34 False  6.893718242645264\n",
      "Predicted: [82, 96] Actual: 35 False  6.699916362762451\n",
      "Predicted: [110, 82] Actual: 36 False  7.253703594207764\n",
      "Predicted: [125, 82] Actual: 37 False  6.962119102478027\n",
      "Predicted: [110, 82] Actual: 38 False  7.715202808380127\n",
      "Predicted: [110, 82] Actual: 39 False  7.351016521453857\n",
      "Predicted: [110, 82] Actual: 40 False  7.270066738128662\n",
      "Predicted: [110, 82] Actual: 41 False  7.835890293121338\n",
      "Predicted: [110, 82] Actual: 42 False  7.161621570587158\n",
      "Predicted: [110, 82] Actual: 43 False  7.310520172119141\n",
      "Predicted: [110, 82] Actual: 44 False  7.53048849105835\n",
      "Predicted: [82, 110] Actual: 45 False  6.8115763664245605\n",
      "Predicted: [110, 82] Actual: 46 False  7.1583685874938965\n",
      "Predicted: [82, 96] Actual: 47 False  6.791049003601074\n",
      "Predicted: [82, 110] Actual: 48 False  6.8159308433532715\n",
      "Predicted: [82, 141] Actual: 49 False  6.987778663635254\n",
      "Predicted: [82, 110] Actual: 50 False  6.761404037475586\n",
      "Predicted: [82, 110] Actual: 51 False  6.741283893585205\n",
      "Predicted: [82, 96] Actual: 52 False  6.809667110443115\n",
      "Predicted: [82, 110] Actual: 53 False  6.8290205001831055\n",
      "Predicted: [125, 82] Actual: 54 False  7.002559661865234\n",
      "Predicted: [82, 96] Actual: 55 False  6.816385746002197\n",
      "Predicted: [82, 96] Actual: 56 False  6.826841354370117\n",
      "Predicted: [82, 110] Actual: 57 False  6.747060298919678\n",
      "Predicted: [82, 96] Actual: 58 False  6.723965644836426\n",
      "Predicted: [82, 96] Actual: 59 False  6.670681953430176\n",
      "Predicted: [82, 110] Actual: 60 False  6.694911003112793\n",
      "Predicted: [110, 82] Actual: 61 False  7.693047046661377\n",
      "Predicted: [82, 110] Actual: 62 False  6.822562217712402\n",
      "Predicted: [82, 96] Actual: 63 False  6.829555511474609\n",
      "Predicted: [82, 96] Actual: 64 False  6.7376580238342285\n",
      "Predicted: [110, 82] Actual: 65 False  7.156861782073975\n",
      "Predicted: [110, 82] Actual: 66 False  8.412009239196777\n",
      "Predicted: [110, 82] Actual: 67 False  7.112287521362305\n",
      "Predicted: [110, 82] Actual: 68 False  6.892874240875244\n",
      "Predicted: [82, 96] Actual: 69 False  6.818027496337891\n",
      "Predicted: [110, 82] Actual: 70 False  7.381157398223877\n",
      "Predicted: [110, 82] Actual: 71 False  7.63917875289917\n",
      "Predicted: [110, 82] Actual: 72 False  6.927323341369629\n",
      "Predicted: [110, 82] Actual: 73 False  6.981966495513916\n",
      "Predicted: [110, 82] Actual: 74 False  7.544068336486816\n",
      "Predicted: [110, 82] Actual: 75 False  7.255316257476807\n",
      "Predicted: [82, 96] Actual: 76 False  6.872238636016846\n",
      "Predicted: [82, 96] Actual: 77 False  6.605919361114502\n",
      "Predicted: [110, 82] Actual: 78 False  6.911183834075928\n",
      "Predicted: [82, 110] Actual: 79 False  6.898772239685059\n",
      "Predicted: [110]   Actual: 80 False  9.155792236328125\n",
      "Predicted: [82, 141] Actual: 81 False  7.144779205322266\n",
      "Predicted: [82, 141] Actual: 82 True   7.47106409072876\n",
      "Predicted: [110, 82] Actual: 83 False  7.327446460723877\n",
      "Predicted: [82, 110] Actual: 84 False  6.603298664093018\n",
      "Predicted: [82, 96] Actual: 85 False  6.68049955368042\n",
      "Predicted: [82, 96] Actual: 86 False  6.803155422210693\n",
      "Predicted: [82, 96] Actual: 87 False  6.896116256713867\n",
      "Predicted: [110, 82] Actual: 88 False  6.691943645477295\n",
      "Predicted: [110, 82] Actual: 89 False  7.433276176452637\n",
      "Predicted: [110, 82] Actual: 90 False  7.003381729125977\n",
      "Predicted: [82, 96] Actual: 91 False  6.777918815612793\n",
      "Predicted: [110, 82] Actual: 92 False  6.935085773468018\n",
      "Predicted: [110, 82] Actual: 93 False  7.668589115142822\n",
      "Predicted: [125]   Actual: 94 False  8.886287689208984\n",
      "Predicted: [110, 82] Actual: 95 False  7.692240238189697\n",
      "Predicted: [110, 82] Actual: 96 False  8.61494255065918\n",
      "Predicted: [82, 110] Actual: 97 False  6.584324836730957\n",
      "Predicted: [110, 82] Actual: 98 False  7.166436672210693\n",
      "Predicted: [82, 110] Actual: 99 False  6.606208801269531\n",
      "Predicted: [110, 82] Actual: 100 False  6.972451686859131\n",
      "Predicted: [82, 141] Actual: 101 False  6.842883110046387\n",
      "Predicted: [82, 110] Actual: 102 False  6.688590049743652\n",
      "Predicted: [82, 96] Actual: 103 False  6.7973408699035645\n",
      "Predicted: [82, 125] Actual: 104 False  7.053024768829346\n",
      "Predicted: [82, 96] Actual: 105 False  6.823898792266846\n",
      "Predicted: [110, 82] Actual: 106 False  6.758215427398682\n",
      "Predicted: [110, 82] Actual: 107 False  7.591948986053467\n",
      "Predicted: [110, 82] Actual: 108 False  7.26038122177124\n",
      "Predicted: [82, 141] Actual: 109 False  6.69436502456665\n",
      "Predicted: [110]   Actual: 110 True   59.12489318847656\n",
      "Predicted: [82, 96] Actual: 111 False  6.77567720413208\n",
      "Predicted: [110, 82] Actual: 112 False  7.141210079193115\n",
      "Predicted: [82, 96] Actual: 113 False  6.769829750061035\n",
      "Predicted: [82, 96] Actual: 114 False  6.673872947692871\n",
      "Predicted: [82, 96] Actual: 115 False  6.69016695022583\n",
      "Predicted: [82, 96] Actual: 116 False  6.852506160736084\n",
      "Predicted: [82, 96] Actual: 117 False  6.819703102111816\n",
      "Predicted: [82, 96] Actual: 118 False  6.737107276916504\n",
      "Predicted: [110, 82] Actual: 119 False  7.878643989562988\n",
      "Predicted: [110, 82] Actual: 120 False  7.368417263031006\n",
      "Predicted: [82, 96] Actual: 121 False  6.879750728607178\n",
      "Predicted: [110, 82] Actual: 122 False  7.074654579162598\n",
      "Predicted: [110, 82] Actual: 123 False  7.389857769012451\n",
      "Predicted: [82, 96] Actual: 124 False  6.780285358428955\n",
      "Predicted: [125]   Actual: 125 True   173.48553466796875\n",
      "Predicted: [82, 96] Actual: 126 False  6.76706075668335\n",
      "Predicted: [82, 141] Actual: 127 False  6.755320072174072\n",
      "Predicted: [110, 82] Actual: 128 False  7.363175868988037\n",
      "Predicted: [110, 82] Actual: 129 False  6.84027624130249\n",
      "Predicted: [82, 96] Actual: 130 False  6.825135231018066\n",
      "Predicted: [82, 96] Actual: 131 False  6.769118785858154\n",
      "Predicted: [82, 96] Actual: 132 False  6.778049945831299\n",
      "Predicted: [125, 82] Actual: 133 False  7.437355995178223\n",
      "Predicted: [82, 96] Actual: 134 False  6.791322708129883\n",
      "Predicted: [82, 110] Actual: 135 False  6.809462070465088\n",
      "Predicted: [110, 82] Actual: 136 False  8.047365188598633\n",
      "Predicted: [125, 82] Actual: 137 False  7.386446952819824\n",
      "Predicted: [125, 110] Actual: 138 False  7.205292224884033\n",
      "Predicted: [110, 82] Actual: 139 False  7.010643005371094\n",
      "Predicted: [82, 141] Actual: 140 False  6.90996789932251\n",
      "Predicted: [82, 141] Actual: 141 True   7.033297061920166\n",
      "Predicted: [82, 110] Actual: 142 False  6.592062950134277\n",
      "Predicted: [82, 96] Actual: 143 False  6.769108772277832\n",
      "Predicted: [110, 82] Actual: 144 False  6.770264625549316\n",
      "Predicted: [110, 82] Actual: 145 False  7.089016437530518\n",
      "Predicted: [110, 82] Actual: 146 False  8.058823585510254\n",
      "Predicted: [125]   Actual: 147 False  8.860017776489258\n",
      "Predicted: [110, 82] Actual: 148 False  6.985042572021484\n",
      "Predicted: [110, 82] Actual: 149 False  6.914615154266357\n",
      "Predicted: [82, 96] Actual: 150 False  6.836806297302246\n",
      "Predicted: [110, 82] Actual: 151 False  7.230870723724365\n",
      "Predicted: [110, 82] Actual: 152 False  7.090011119842529\n",
      "Predicted: [110, 82] Actual: 153 False  7.639569282531738\n",
      "Predicted: [82, 96] Actual: 154 False  6.861593723297119\n",
      "Predicted: [82, 96] Actual: 155 False  6.777244567871094\n",
      "Predicted: [82, 110] Actual: 156 False  6.883962154388428\n",
      "Predicted: [82, 96] Actual: 157 False  6.734618186950684\n",
      "Predicted: [82, 96] Actual: 158 False  6.886429309844971\n",
      "Predicted: [110, 82] Actual: 159 False  6.976468563079834\n",
      "Predicted: [110, 82] Actual: 160 False  6.714808940887451\n",
      "Predicted: [110, 125] Actual: 161 False  7.396091938018799\n",
      "Predicted: [82, 96] Actual: 162 False  6.839839458465576\n",
      "Predicted: [110, 82] Actual: 163 False  6.829087734222412\n",
      "Predicted: [110, 82] Actual: 164 False  7.569626331329346\n",
      "Predicted: [110, 82] Actual: 165 False  7.364033222198486\n",
      "Predicted: [82, 96] Actual: 166 False  6.8167500495910645\n",
      "Predicted: [82, 96] Actual: 167 False  6.8811445236206055\n",
      "Predicted: [125, 82] Actual: 168 False  8.026993751525879\n",
      "Predicted: [82, 96] Actual: 169 False  6.894510746002197\n",
      "Predicted: [110, 82] Actual: 170 False  7.784190654754639\n",
      "Predicted: [82, 96] Actual: 171 False  6.574517726898193\n",
      "Predicted: [82, 110] Actual: 172 False  6.897506237030029\n",
      "Predicted: [82, 141] Actual: 173 False  6.730635166168213\n",
      "Predicted: [110, 82] Actual: 174 False  7.1861114501953125\n",
      "Predicted: [110, 82] Actual: 175 False  7.788063049316406\n",
      "Predicted: [82, 96] Actual: 176 False  6.943474292755127\n",
      "Predicted: [82, 110] Actual: 177 False  6.609347820281982\n",
      "Predicted: [110, 82] Actual: 178 False  7.642252445220947\n",
      "Predicted: [110, 82] Actual: 179 False  7.090747356414795\n",
      "Predicted: [82, 96] Actual: 180 False  6.873200416564941\n",
      "Predicted: [110, 82] Actual: 181 False  6.921784400939941\n",
      "Predicted: [82, 96] Actual: 182 False  6.733232021331787\n",
      "Predicted: [82, 96] Actual: 183 False  6.730429649353027\n",
      "Predicted: [110, 82] Actual: 184 False  7.805269718170166\n",
      "Predicted: [82, 96] Actual: 185 False  6.71705961227417\n",
      "Predicted: [110, 82] Actual: 186 False  7.895308017730713\n",
      "Predicted: [82, 141] Actual: 187 False  6.8629631996154785\n",
      "Predicted: [82, 141] Actual: 188 False  6.862263202667236\n",
      "Predicted: [82, 96] Actual: 189 False  6.7322678565979\n",
      "Predicted: [110, 82] Actual: 190 False  7.018160343170166\n",
      "Predicted: [125, 82] Actual: 191 False  7.897604465484619\n",
      "Predicted: [110, 82] Actual: 192 False  7.378852367401123\n",
      "Predicted: [110, 82] Actual: 193 False  6.756816387176514\n",
      "Predicted: [110, 82] Actual: 194 False  7.221181869506836\n",
      "Predicted: [110, 82] Actual: 195 False  7.663059711456299\n",
      "Predicted: [82, 110] Actual: 196 False  6.827762126922607\n",
      "Predicted: [110, 82] Actual: 197 False  7.9040422439575195\n",
      "Predicted: [110, 82] Actual: 198 False  7.331925868988037\n",
      "Predicted: [110, 82] Actual: 199 False  6.924695014953613\n",
      "Predicted: [82, 96] Actual: 200 False  6.660706996917725\n",
      "Predicted: [110, 82] Actual: 201 False  6.994329929351807\n",
      "Predicted: [110, 82] Actual: 202 False  7.2696428298950195\n",
      "Predicted: [82, 96] Actual: 203 False  6.87412166595459\n",
      "Predicted: [125, 82] Actual: 204 False  6.815360069274902\n",
      "Predicted: [82, 96] Actual: 205 False  6.810954570770264\n",
      "Predicted: [82, 96] Actual: 206 False  6.636238098144531\n",
      "Predicted: [110, 82] Actual: 207 False  7.597650051116943\n",
      "Predicted: [110, 82] Actual: 208 False  6.917126178741455\n",
      "Predicted: [110, 82] Actual: 209 False  7.28747034072876\n",
      "Predicted: [110, 82] Actual: 210 False  7.261885166168213\n",
      "Predicted: [110, 82] Actual: 211 False  6.807068347930908\n",
      "Predicted: [82, 96] Actual: 212 False  6.879922866821289\n",
      "Predicted: [82, 96] Actual: 213 False  6.743288516998291\n",
      "Predicted: [82, 96] Actual: 214 False  6.870936870574951\n",
      "Predicted: [110, 82] Actual: 215 False  6.9312920570373535\n",
      "Predicted: [82, 96] Actual: 216 False  6.833648204803467\n",
      "Predicted: [110, 82] Actual: 217 False  7.199690818786621\n",
      "Predicted: [110, 82] Actual: 218 False  6.9823899269104\n",
      "Predicted: [82, 96] Actual: 219 False  6.84764289855957\n",
      "Predicted: [82, 96] Actual: 220 False  6.953746318817139\n",
      "Predicted: [110, 82] Actual: 221 False  6.8532819747924805\n",
      "Predicted: [110, 82] Actual: 222 False  6.828379154205322\n",
      "Predicted: [110, 82] Actual: 223 False  7.635677814483643\n",
      "Predicted: [110, 82] Actual: 224 False  6.963154315948486\n",
      "Edge correct: 4    Size: 225  Edge correct/Size: 0.017777777777777778\n",
      "Grid size: 15\n",
      "6132\n",
      "4089\n",
      "10221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.360301  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2800  size: 4089  main correct/size: 0.6847640009782343\n",
      "Also correct: 576  size: 4089  also correct/size: 0.1408657373440939\n",
      "Test Error: Accuracy: 82.6%, Avg loss: 1.375795\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.364661  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2801  size: 4089  main correct/size: 0.6850085595500123\n",
      "Also correct: 566  size: 4089  also correct/size: 0.1384201516263145\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.375949\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.364173  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2802  size: 4089  main correct/size: 0.6852531181217901\n",
      "Also correct: 564  size: 4089  also correct/size: 0.13793103448275862\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.375668\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.363297  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2803  size: 4089  main correct/size: 0.6854976766935681\n",
      "Also correct: 563  size: 4089  also correct/size: 0.13768647591098068\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.375348\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.362408  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2803  size: 4089  main correct/size: 0.6854976766935681\n",
      "Also correct: 564  size: 4089  also correct/size: 0.13793103448275862\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 1.374874\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.136352062225342\n",
      "Predicted: [110, 82] Actual: 1  False  7.953184604644775\n",
      "Predicted: [110, 82] Actual: 2  False  7.394071102142334\n",
      "Predicted: [82, 141] Actual: 3  False  6.914272308349609\n",
      "Predicted: [82, 96] Actual: 4  False  6.919804573059082\n",
      "Predicted: [82, 110] Actual: 5  False  6.73248291015625\n",
      "Predicted: [110, 82] Actual: 6  False  7.771378040313721\n",
      "Predicted: [110, 82] Actual: 7  False  7.479104995727539\n",
      "Predicted: [82, 141] Actual: 8  False  6.955986499786377\n",
      "Predicted: [82, 96] Actual: 9  False  6.9878950119018555\n",
      "Predicted: [110, 82] Actual: 10 False  7.8395094871521\n",
      "Predicted: [110, 82] Actual: 11 False  6.883958339691162\n",
      "Predicted: [110, 82] Actual: 12 False  8.215576171875\n",
      "Predicted: [82, 141] Actual: 13 False  6.858966827392578\n",
      "Predicted: [82, 141] Actual: 14 False  6.83939266204834\n",
      "Predicted: [82, 96] Actual: 15 False  6.909782886505127\n",
      "Predicted: [110, 82] Actual: 16 False  7.392909526824951\n",
      "Predicted: [82, 141] Actual: 17 False  6.87181282043457\n",
      "Predicted: [82, 141] Actual: 18 False  6.797155380249023\n",
      "Predicted: [82, 110] Actual: 19 False  6.951818466186523\n",
      "Predicted: [110, 82] Actual: 20 False  7.01693058013916\n",
      "Predicted: [110, 82] Actual: 21 False  7.676053047180176\n",
      "Predicted: [125, 82] Actual: 22 False  7.4139275550842285\n",
      "Predicted: [82, 110] Actual: 23 False  6.909110069274902\n",
      "Predicted: [82, 141] Actual: 24 False  6.67664909362793\n",
      "Predicted: [82, 110] Actual: 25 False  6.935643196105957\n",
      "Predicted: [110, 82] Actual: 26 False  7.2051520347595215\n",
      "Predicted: [110, 82] Actual: 27 False  7.000669956207275\n",
      "Predicted: [110, 82] Actual: 28 False  7.414055824279785\n",
      "Predicted: [82, 110] Actual: 29 False  6.937101364135742\n",
      "Predicted: [82, 141] Actual: 30 False  6.915735244750977\n",
      "Predicted: [82, 110] Actual: 31 False  6.817915916442871\n",
      "Predicted: [82, 110] Actual: 32 False  6.809784889221191\n",
      "Predicted: [110, 125] Actual: 33 False  7.398530006408691\n",
      "Predicted: [110, 82] Actual: 34 False  6.883173942565918\n",
      "Predicted: [82, 141] Actual: 35 False  6.758326530456543\n",
      "Predicted: [110, 82] Actual: 36 False  7.269811630249023\n",
      "Predicted: [125, 82] Actual: 37 False  6.935902118682861\n",
      "Predicted: [110, 82] Actual: 38 False  7.770121097564697\n",
      "Predicted: [110, 82] Actual: 39 False  7.399414539337158\n",
      "Predicted: [110, 82] Actual: 40 False  7.302692890167236\n",
      "Predicted: [110, 82] Actual: 41 False  7.902116298675537\n",
      "Predicted: [110, 82] Actual: 42 False  7.224801540374756\n",
      "Predicted: [110, 82] Actual: 43 False  7.36732816696167\n",
      "Predicted: [110, 82] Actual: 44 False  7.579463481903076\n",
      "Predicted: [82, 110] Actual: 45 False  6.872091293334961\n",
      "Predicted: [110, 82] Actual: 46 False  7.181772708892822\n",
      "Predicted: [82, 110] Actual: 47 False  6.850323677062988\n",
      "Predicted: [82, 110] Actual: 48 False  6.875651836395264\n",
      "Predicted: [82, 141] Actual: 49 False  7.045888900756836\n",
      "Predicted: [82, 110] Actual: 50 False  6.8209228515625\n",
      "Predicted: [82, 141] Actual: 51 False  6.802783966064453\n",
      "Predicted: [82, 141] Actual: 52 False  6.8696088790893555\n",
      "Predicted: [82, 110] Actual: 53 False  6.889931678771973\n",
      "Predicted: [82, 125] Actual: 54 False  6.99846887588501\n",
      "Predicted: [82, 141] Actual: 55 False  6.877373695373535\n",
      "Predicted: [82, 141] Actual: 56 False  6.889772415161133\n",
      "Predicted: [82, 110] Actual: 57 False  6.807225227355957\n",
      "Predicted: [82, 96] Actual: 58 False  6.783867359161377\n",
      "Predicted: [82, 96] Actual: 59 False  6.730139255523682\n",
      "Predicted: [82, 110] Actual: 60 False  6.7545695304870605\n",
      "Predicted: [110, 82] Actual: 61 False  7.747976303100586\n",
      "Predicted: [82, 110] Actual: 62 False  6.883149147033691\n",
      "Predicted: [82, 141] Actual: 63 False  6.8904852867126465\n",
      "Predicted: [82, 141] Actual: 64 False  6.799069404602051\n",
      "Predicted: [110, 82] Actual: 65 False  7.2534308433532715\n",
      "Predicted: [110, 82] Actual: 66 False  8.500089645385742\n",
      "Predicted: [82, 110] Actual: 67 False  7.174831390380859\n",
      "Predicted: [110, 82] Actual: 68 False  6.9689812660217285\n",
      "Predicted: [82, 141] Actual: 69 False  6.881654739379883\n",
      "Predicted: [110, 82] Actual: 70 False  7.416074752807617\n",
      "Predicted: [110, 82] Actual: 71 False  7.689253330230713\n",
      "Predicted: [110, 82] Actual: 72 False  6.971542835235596\n",
      "Predicted: [110, 82] Actual: 73 False  7.017044544219971\n",
      "Predicted: [110, 82] Actual: 74 False  7.590446949005127\n",
      "Predicted: [110, 82] Actual: 75 False  7.295542240142822\n",
      "Predicted: [82, 141] Actual: 76 False  6.935034275054932\n",
      "Predicted: [82, 141] Actual: 77 False  6.664881706237793\n",
      "Predicted: [110, 82] Actual: 78 False  6.9421772956848145\n",
      "Predicted: [82, 110] Actual: 79 False  6.9600324630737305\n",
      "Predicted: [110]   Actual: 80 False  9.28062915802002\n",
      "Predicted: [82, 141] Actual: 81 False  7.203943729400635\n",
      "Predicted: [82, 141] Actual: 82 True   7.542734146118164\n",
      "Predicted: [110, 82] Actual: 83 False  7.25941276550293\n",
      "Predicted: [82, 110] Actual: 84 False  6.658030033111572\n",
      "Predicted: [82, 141] Actual: 85 False  6.737760543823242\n",
      "Predicted: [82, 141] Actual: 86 False  6.864551067352295\n",
      "Predicted: [82, 141] Actual: 87 False  6.95971155166626\n",
      "Predicted: [110, 82] Actual: 88 False  6.744472980499268\n",
      "Predicted: [110, 82] Actual: 89 False  7.487789630889893\n",
      "Predicted: [110, 82] Actual: 90 False  7.040079116821289\n",
      "Predicted: [82, 110] Actual: 91 False  6.838552474975586\n",
      "Predicted: [110, 82] Actual: 92 False  6.971547603607178\n",
      "Predicted: [110, 82] Actual: 93 False  7.715197563171387\n",
      "Predicted: [125]   Actual: 94 False  8.606654167175293\n",
      "Predicted: [110, 82] Actual: 95 False  7.7273454666137695\n",
      "Predicted: [110, 82] Actual: 96 False  8.688549041748047\n",
      "Predicted: [82, 110] Actual: 97 False  6.640186309814453\n",
      "Predicted: [110, 82] Actual: 98 False  7.212986469268799\n",
      "Predicted: [82, 110] Actual: 99 False  6.664413928985596\n",
      "Predicted: [82, 110] Actual: 100 False  7.025707244873047\n",
      "Predicted: [82, 141] Actual: 101 False  6.9050798416137695\n",
      "Predicted: [82, 110] Actual: 102 False  6.74847936630249\n",
      "Predicted: [82, 96] Actual: 103 False  6.859235763549805\n",
      "Predicted: [82, 110] Actual: 104 False  7.115811347961426\n",
      "Predicted: [82, 141] Actual: 105 False  6.885714054107666\n",
      "Predicted: [110, 82] Actual: 106 False  6.7840142250061035\n",
      "Predicted: [110, 82] Actual: 107 False  7.6527533531188965\n",
      "Predicted: [110, 82] Actual: 108 False  7.30949592590332\n",
      "Predicted: [82, 141] Actual: 109 False  6.755681991577148\n",
      "Predicted: [110]   Actual: 110 True   61.63479232788086\n",
      "Predicted: [82, 141] Actual: 111 False  6.8359599113464355\n",
      "Predicted: [110, 82] Actual: 112 False  7.178756237030029\n",
      "Predicted: [82, 141] Actual: 113 False  6.83055305480957\n",
      "Predicted: [82, 141] Actual: 114 False  6.732470512390137\n",
      "Predicted: [82, 141] Actual: 115 False  6.749720573425293\n",
      "Predicted: [82, 141] Actual: 116 False  6.915283203125\n",
      "Predicted: [82, 141] Actual: 117 False  6.8838210105896\n",
      "Predicted: [82, 96] Actual: 118 False  6.798336982727051\n",
      "Predicted: [110, 82] Actual: 119 False  7.944910049438477\n",
      "Predicted: [110, 82] Actual: 120 False  7.4074788093566895\n",
      "Predicted: [82, 141] Actual: 121 False  6.941673278808594\n",
      "Predicted: [110, 82] Actual: 122 False  7.121682643890381\n",
      "Predicted: [110, 82] Actual: 123 False  7.4461989402771\n",
      "Predicted: [82, 141] Actual: 124 False  6.841127395629883\n",
      "Predicted: [125]   Actual: 125 True   175.3409423828125\n",
      "Predicted: [82, 141] Actual: 126 False  6.825404644012451\n",
      "Predicted: [82, 141] Actual: 127 False  6.808416843414307\n",
      "Predicted: [110, 82] Actual: 128 False  7.459596157073975\n",
      "Predicted: [82, 110] Actual: 129 False  6.8795270919799805\n",
      "Predicted: [82, 141] Actual: 130 False  6.886954307556152\n",
      "Predicted: [82, 141] Actual: 131 False  6.83135986328125\n",
      "Predicted: [82, 141] Actual: 132 False  6.839369773864746\n",
      "Predicted: [125, 82] Actual: 133 False  7.386630535125732\n",
      "Predicted: [82, 96] Actual: 134 False  6.852585792541504\n",
      "Predicted: [82, 110] Actual: 135 False  6.8705339431762695\n",
      "Predicted: [110, 82] Actual: 136 False  8.109052658081055\n",
      "Predicted: [125, 82] Actual: 137 False  7.272938251495361\n",
      "Predicted: [110, 125] Actual: 138 False  7.162811756134033\n",
      "Predicted: [110, 82] Actual: 139 False  7.047623157501221\n",
      "Predicted: [82, 141] Actual: 140 False  6.968478202819824\n",
      "Predicted: [82, 141] Actual: 141 True   7.091378211975098\n",
      "Predicted: [82, 141] Actual: 142 False  6.651703357696533\n",
      "Predicted: [82, 141] Actual: 143 False  6.829197883605957\n",
      "Predicted: [110, 82] Actual: 144 False  6.789872169494629\n",
      "Predicted: [110, 82] Actual: 145 False  7.019503593444824\n",
      "Predicted: [110, 82] Actual: 146 False  8.098163604736328\n",
      "Predicted: [125, 82] Actual: 147 False  8.80329704284668\n",
      "Predicted: [110, 82] Actual: 148 False  7.004740238189697\n",
      "Predicted: [110, 82] Actual: 149 False  6.930598735809326\n",
      "Predicted: [82, 110] Actual: 150 False  6.897816181182861\n",
      "Predicted: [110, 82] Actual: 151 False  7.277383327484131\n",
      "Predicted: [110, 82] Actual: 152 False  7.1276068687438965\n",
      "Predicted: [110, 82] Actual: 153 False  7.703524112701416\n",
      "Predicted: [82, 141] Actual: 154 False  6.923503398895264\n",
      "Predicted: [82, 96] Actual: 155 False  6.839369773864746\n",
      "Predicted: [82, 141] Actual: 156 False  6.945168495178223\n",
      "Predicted: [82, 141] Actual: 157 False  6.790264129638672\n",
      "Predicted: [82, 141] Actual: 158 False  6.948883056640625\n",
      "Predicted: [110, 82] Actual: 159 False  7.009881019592285\n",
      "Predicted: [110, 82] Actual: 160 False  6.727176189422607\n",
      "Predicted: [110, 82] Actual: 161 False  7.4298295974731445\n",
      "Predicted: [82, 96] Actual: 162 False  6.902204990386963\n",
      "Predicted: [82, 110] Actual: 163 False  6.874589443206787\n",
      "Predicted: [110, 82] Actual: 164 False  7.6207275390625\n",
      "Predicted: [110, 82] Actual: 165 False  7.396839618682861\n",
      "Predicted: [82, 96] Actual: 166 False  6.87761116027832\n",
      "Predicted: [82, 141] Actual: 167 False  6.9432477951049805\n",
      "Predicted: [125, 82] Actual: 168 False  7.899552822113037\n",
      "Predicted: [82, 141] Actual: 169 False  6.9568586349487305\n",
      "Predicted: [110, 82] Actual: 170 False  7.840771198272705\n",
      "Predicted: [82, 141] Actual: 171 False  6.633789539337158\n",
      "Predicted: [82, 110] Actual: 172 False  6.953253746032715\n",
      "Predicted: [82, 141] Actual: 173 False  6.79050350189209\n",
      "Predicted: [110, 82] Actual: 174 False  7.2079596519470215\n",
      "Predicted: [110, 82] Actual: 175 False  7.8365020751953125\n",
      "Predicted: [82, 96] Actual: 176 False  7.006906509399414\n",
      "Predicted: [82, 110] Actual: 177 False  6.6683173179626465\n",
      "Predicted: [110, 82] Actual: 178 False  7.6958465576171875\n",
      "Predicted: [110, 82] Actual: 179 False  7.122488498687744\n",
      "Predicted: [82, 141] Actual: 180 False  6.934957504272461\n",
      "Predicted: [110, 82] Actual: 181 False  6.955259799957275\n",
      "Predicted: [82, 141] Actual: 182 False  6.793581485748291\n",
      "Predicted: [82, 141] Actual: 183 False  6.791662216186523\n",
      "Predicted: [110, 82] Actual: 184 False  7.861649990081787\n",
      "Predicted: [82, 141] Actual: 185 False  6.777436256408691\n",
      "Predicted: [110, 82] Actual: 186 False  7.961514949798584\n",
      "Predicted: [82, 141] Actual: 187 False  6.921318054199219\n",
      "Predicted: [82, 141] Actual: 188 False  6.92057466506958\n",
      "Predicted: [82, 141] Actual: 189 False  6.79289436340332\n",
      "Predicted: [110, 82] Actual: 190 False  7.063395977020264\n",
      "Predicted: [125, 82] Actual: 191 False  7.822632312774658\n",
      "Predicted: [110, 82] Actual: 192 False  7.426153659820557\n",
      "Predicted: [110, 82] Actual: 193 False  6.781491756439209\n",
      "Predicted: [110, 82] Actual: 194 False  7.268377780914307\n",
      "Predicted: [110, 82] Actual: 195 False  7.705371379852295\n",
      "Predicted: [82, 110] Actual: 196 False  6.888402462005615\n",
      "Predicted: [110, 82] Actual: 197 False  7.951704502105713\n",
      "Predicted: [110, 82] Actual: 198 False  7.375101566314697\n",
      "Predicted: [110, 82] Actual: 199 False  6.950326442718506\n",
      "Predicted: [82, 141] Actual: 200 False  6.719201564788818\n",
      "Predicted: [110, 82] Actual: 201 False  7.027569770812988\n",
      "Predicted: [110, 82] Actual: 202 False  7.315804958343506\n",
      "Predicted: [82, 141] Actual: 203 False  6.933824062347412\n",
      "Predicted: [82, 125] Actual: 204 False  6.840806007385254\n",
      "Predicted: [82, 141] Actual: 205 False  6.874028205871582\n",
      "Predicted: [82, 141] Actual: 206 False  6.6958818435668945\n",
      "Predicted: [110, 82] Actual: 207 False  7.649116039276123\n",
      "Predicted: [110, 82] Actual: 208 False  6.942768573760986\n",
      "Predicted: [110, 82] Actual: 209 False  7.324193477630615\n",
      "Predicted: [110, 82] Actual: 210 False  7.29791784286499\n",
      "Predicted: [82, 110] Actual: 211 False  6.851718902587891\n",
      "Predicted: [82, 141] Actual: 212 False  6.94176721572876\n",
      "Predicted: [82, 141] Actual: 213 False  6.804018020629883\n",
      "Predicted: [82, 141] Actual: 214 False  6.933022499084473\n",
      "Predicted: [110, 82] Actual: 215 False  6.963306427001953\n",
      "Predicted: [82, 110] Actual: 216 False  6.894640922546387\n",
      "Predicted: [110, 82] Actual: 217 False  7.235723495483398\n",
      "Predicted: [110, 82] Actual: 218 False  6.985344886779785\n",
      "Predicted: [82, 96] Actual: 219 False  6.907509803771973\n",
      "Predicted: [82, 96] Actual: 220 False  7.017523288726807\n",
      "Predicted: [110, 82] Actual: 221 False  6.890921115875244\n",
      "Predicted: [110, 82] Actual: 222 False  6.856266975402832\n",
      "Predicted: [110, 82] Actual: 223 False  7.691691875457764\n",
      "Predicted: [110, 82] Actual: 224 False  6.986558437347412\n",
      "Edge correct: 4    Size: 225  Edge correct/Size: 0.017777777777777778\n",
      "Grid size: 15\n",
      "6132\n",
      "4089\n",
      "10221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.099609  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2675  size: 4089  main correct/size: 0.6541941795059917\n",
      "Also correct: 647  size: 4089  also correct/size: 0.1582293959403277\n",
      "Test Error: Accuracy: 81.2%, Avg loss: 1.461820\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.173299  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2676  size: 4089  main correct/size: 0.6544387380777696\n",
      "Also correct: 646  size: 4089  also correct/size: 0.15798483736854976\n",
      "Test Error: Accuracy: 81.2%, Avg loss: 1.461196\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.171678  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2677  size: 4089  main correct/size: 0.6546832966495476\n",
      "Also correct: 647  size: 4089  also correct/size: 0.1582293959403277\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 1.460405\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.170087  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2676  size: 4089  main correct/size: 0.6544387380777696\n",
      "Also correct: 649  size: 4089  also correct/size: 0.1587185130838836\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 1.459798\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.168906  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2677  size: 4089  main correct/size: 0.6546832966495476\n",
      "Also correct: 649  size: 4089  also correct/size: 0.1587185130838836\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 1.459002\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [110, 82] Actual: 0  False  7.358105182647705\n",
      "Predicted: [110, 82] Actual: 1  False  8.200335502624512\n",
      "Predicted: [110, 82] Actual: 2  False  7.626153945922852\n",
      "Predicted: [82, 96] Actual: 3  False  6.967156410217285\n",
      "Predicted: [82, 96] Actual: 4  False  6.9666571617126465\n",
      "Predicted: [82, 110] Actual: 5  False  6.7778096199035645\n",
      "Predicted: [110, 82] Actual: 6  False  7.999102592468262\n",
      "Predicted: [110, 82] Actual: 7  False  7.706587791442871\n",
      "Predicted: [82, 96] Actual: 8  False  7.003052234649658\n",
      "Predicted: [82, 96] Actual: 9  False  7.036874294281006\n",
      "Predicted: [110, 82] Actual: 10 False  8.086308479309082\n",
      "Predicted: [110, 82] Actual: 11 False  7.104116439819336\n",
      "Predicted: [110, 82] Actual: 12 False  8.456478118896484\n",
      "Predicted: [82, 110] Actual: 13 False  6.9051432609558105\n",
      "Predicted: [82, 110] Actual: 14 False  6.886007308959961\n",
      "Predicted: [82, 110] Actual: 15 False  6.957684516906738\n",
      "Predicted: [110, 82] Actual: 16 False  7.616044998168945\n",
      "Predicted: [82, 96] Actual: 17 False  6.9214324951171875\n",
      "Predicted: [82, 96] Actual: 18 False  6.844118595123291\n",
      "Predicted: [82, 110] Actual: 19 False  6.99860954284668\n",
      "Predicted: [110, 82] Actual: 20 False  7.230372428894043\n",
      "Predicted: [110, 82] Actual: 21 False  7.885528564453125\n",
      "Predicted: [125, 82] Actual: 22 False  6.978987693786621\n",
      "Predicted: [110, 82] Actual: 23 False  6.972056865692139\n",
      "Predicted: [82, 96] Actual: 24 False  6.721798896789551\n",
      "Predicted: [82, 110] Actual: 25 False  6.982792377471924\n",
      "Predicted: [110, 82] Actual: 26 False  7.4184794425964355\n",
      "Predicted: [110, 82] Actual: 27 False  7.212096214294434\n",
      "Predicted: [110, 82] Actual: 28 False  7.61785888671875\n",
      "Predicted: [110, 82] Actual: 29 False  6.986353874206543\n",
      "Predicted: [82, 96] Actual: 30 False  6.967726707458496\n",
      "Predicted: [110, 82] Actual: 31 False  6.948232650756836\n",
      "Predicted: [110, 82] Actual: 32 False  7.039555549621582\n",
      "Predicted: [110, 82] Actual: 33 False  7.636622428894043\n",
      "Predicted: [110, 82] Actual: 34 False  7.0994696617126465\n",
      "Predicted: [82, 110] Actual: 35 False  6.803886890411377\n",
      "Predicted: [110, 82] Actual: 36 False  7.480891227722168\n",
      "Predicted: [82, 110] Actual: 37 False  6.948742866516113\n",
      "Predicted: [110, 82] Actual: 38 False  8.001768112182617\n",
      "Predicted: [110, 82] Actual: 39 False  7.644593238830566\n",
      "Predicted: [110, 82] Actual: 40 False  7.519778251647949\n",
      "Predicted: [110, 82] Actual: 41 False  8.121794700622559\n",
      "Predicted: [110, 82] Actual: 42 False  7.457889556884766\n",
      "Predicted: [110, 82] Actual: 43 False  7.591068744659424\n",
      "Predicted: [110, 82] Actual: 44 False  7.805315017700195\n",
      "Predicted: [110, 82] Actual: 45 False  7.061569690704346\n",
      "Predicted: [110, 82] Actual: 46 False  7.402962684631348\n",
      "Predicted: [110, 82] Actual: 47 False  6.910696983337402\n",
      "Predicted: [82, 110] Actual: 48 False  6.922772407531738\n",
      "Predicted: [82, 141] Actual: 49 False  7.09789514541626\n",
      "Predicted: [82, 110] Actual: 50 False  6.868755340576172\n",
      "Predicted: [82, 110] Actual: 51 False  6.845749855041504\n",
      "Predicted: [82, 141] Actual: 52 False  6.912328243255615\n",
      "Predicted: [110, 82] Actual: 53 False  6.946694374084473\n",
      "Predicted: [82, 96] Actual: 54 False  7.047110557556152\n",
      "Predicted: [82, 96] Actual: 55 False  6.924920558929443\n",
      "Predicted: [82, 96] Actual: 56 False  6.941002368927002\n",
      "Predicted: [110, 82] Actual: 57 False  6.933455944061279\n",
      "Predicted: [82, 96] Actual: 58 False  6.830559253692627\n",
      "Predicted: [82, 110] Actual: 59 False  6.77606201171875\n",
      "Predicted: [110, 82] Actual: 60 False  6.880486488342285\n",
      "Predicted: [110, 82] Actual: 61 False  7.959221839904785\n",
      "Predicted: [82, 110] Actual: 62 False  6.931324005126953\n",
      "Predicted: [82, 110] Actual: 63 False  6.938635349273682\n",
      "Predicted: [82, 96] Actual: 64 False  6.847548007965088\n",
      "Predicted: [110, 82] Actual: 65 False  7.500859260559082\n",
      "Predicted: [110]   Actual: 66 False  8.785489082336426\n",
      "Predicted: [110, 82] Actual: 67 False  7.256247520446777\n",
      "Predicted: [110, 82] Actual: 68 False  7.302839756011963\n",
      "Predicted: [82, 96] Actual: 69 False  6.931484699249268\n",
      "Predicted: [110, 82] Actual: 70 False  7.661952495574951\n",
      "Predicted: [110, 82] Actual: 71 False  7.908933639526367\n",
      "Predicted: [110, 82] Actual: 72 False  7.1643967628479\n",
      "Predicted: [110, 82] Actual: 73 False  7.202029228210449\n",
      "Predicted: [110, 82] Actual: 74 False  7.828648090362549\n",
      "Predicted: [110, 82] Actual: 75 False  7.514230251312256\n",
      "Predicted: [82, 96] Actual: 76 False  6.98569393157959\n",
      "Predicted: [82, 96] Actual: 77 False  6.710161209106445\n",
      "Predicted: [110, 82] Actual: 78 False  7.133423805236816\n",
      "Predicted: [82, 110] Actual: 79 False  7.007661819458008\n",
      "Predicted: [110]   Actual: 80 False  9.57351016998291\n",
      "Predicted: [82, 141] Actual: 81 False  7.256817817687988\n",
      "Predicted: [82, 141] Actual: 82 True   7.610909938812256\n",
      "Predicted: [110, 82] Actual: 83 False  7.388764381408691\n",
      "Predicted: [110, 82] Actual: 84 False  6.835566520690918\n",
      "Predicted: [82, 141] Actual: 85 False  6.781255722045898\n",
      "Predicted: [82, 141] Actual: 86 False  6.916165351867676\n",
      "Predicted: [82, 141] Actual: 87 False  7.009666442871094\n",
      "Predicted: [110, 82] Actual: 88 False  6.988050937652588\n",
      "Predicted: [110, 82] Actual: 89 False  7.6936235427856445\n",
      "Predicted: [110, 82] Actual: 90 False  7.259830474853516\n",
      "Predicted: [82, 110] Actual: 91 False  6.88563346862793\n",
      "Predicted: [110, 82] Actual: 92 False  7.172268867492676\n",
      "Predicted: [110, 82] Actual: 93 False  7.957306861877441\n",
      "Predicted: [125, 82] Actual: 94 False  8.11972427368164\n",
      "Predicted: [110, 82] Actual: 95 False  7.955077171325684\n",
      "Predicted: [110, 82] Actual: 96 False  8.94407844543457\n",
      "Predicted: [82, 110] Actual: 97 False  6.6869049072265625\n",
      "Predicted: [110, 82] Actual: 98 False  7.421235084533691\n",
      "Predicted: [110, 82] Actual: 99 False  6.76126766204834\n",
      "Predicted: [110, 82] Actual: 100 False  7.166192054748535\n",
      "Predicted: [82, 141] Actual: 101 False  6.948827743530273\n",
      "Predicted: [110, 82] Actual: 102 False  6.849887847900391\n",
      "Predicted: [82, 96] Actual: 103 False  6.909134864807129\n",
      "Predicted: [110, 82] Actual: 104 False  7.232327461242676\n",
      "Predicted: [82, 96] Actual: 105 False  6.935338020324707\n",
      "Predicted: [110, 82] Actual: 106 False  6.999532222747803\n",
      "Predicted: [110, 82] Actual: 107 False  7.898342609405518\n",
      "Predicted: [110, 82] Actual: 108 False  7.5511369705200195\n",
      "Predicted: [82, 141] Actual: 109 False  6.804009914398193\n",
      "Predicted: [110]   Actual: 110 True   64.36431121826172\n",
      "Predicted: [82, 96] Actual: 111 False  6.883875846862793\n",
      "Predicted: [110, 82] Actual: 112 False  7.348234176635742\n",
      "Predicted: [82, 110] Actual: 113 False  6.878725528717041\n",
      "Predicted: [82, 141] Actual: 114 False  6.777573585510254\n",
      "Predicted: [82, 96] Actual: 115 False  6.798515796661377\n",
      "Predicted: [82, 96] Actual: 116 False  6.964684009552002\n",
      "Predicted: [82, 96] Actual: 117 False  6.937040328979492\n",
      "Predicted: [82, 96] Actual: 118 False  6.846102714538574\n",
      "Predicted: [110, 82] Actual: 119 False  8.169407844543457\n",
      "Predicted: [110, 82] Actual: 120 False  7.620530605316162\n",
      "Predicted: [82, 96] Actual: 121 False  6.9891862869262695\n",
      "Predicted: [110, 82] Actual: 122 False  7.360701084136963\n",
      "Predicted: [110, 82] Actual: 123 False  7.668747425079346\n",
      "Predicted: [82, 96] Actual: 124 False  6.890793323516846\n",
      "Predicted: [125]   Actual: 125 True   176.5942840576172\n",
      "Predicted: [82, 141] Actual: 126 False  6.8703460693359375\n",
      "Predicted: [82, 141] Actual: 127 False  6.8513288497924805\n",
      "Predicted: [110, 82] Actual: 128 False  7.691123008728027\n",
      "Predicted: [110, 82] Actual: 129 False  7.115451335906982\n",
      "Predicted: [82, 96] Actual: 130 False  6.935725212097168\n",
      "Predicted: [82, 96] Actual: 131 False  6.880474090576172\n",
      "Predicted: [82, 96] Actual: 132 False  6.888920307159424\n",
      "Predicted: [125, 82] Actual: 133 False  6.964843273162842\n",
      "Predicted: [82, 96] Actual: 134 False  6.899334907531738\n",
      "Predicted: [110, 82] Actual: 135 False  6.940408706665039\n",
      "Predicted: [110, 82] Actual: 136 False  8.354226112365723\n",
      "Predicted: [82, 125] Actual: 137 False  6.839456558227539\n",
      "Predicted: [110, 82] Actual: 138 False  7.359014511108398\n",
      "Predicted: [110, 82] Actual: 139 False  7.250802040100098\n",
      "Predicted: [82, 110] Actual: 140 False  7.016641616821289\n",
      "Predicted: [82, 141] Actual: 141 True   7.137967109680176\n",
      "Predicted: [82, 110] Actual: 142 False  6.6999969482421875\n",
      "Predicted: [82, 110] Actual: 143 False  6.8765549659729\n",
      "Predicted: [110, 82] Actual: 144 False  6.9940185546875\n",
      "Predicted: [110, 82] Actual: 145 False  7.1564435958862305\n",
      "Predicted: [110, 82] Actual: 146 False  8.363420486450195\n",
      "Predicted: [125, 82] Actual: 147 False  8.335042953491211\n",
      "Predicted: [110, 82] Actual: 148 False  7.251598358154297\n",
      "Predicted: [110, 82] Actual: 149 False  7.144845008850098\n",
      "Predicted: [82, 110] Actual: 150 False  6.9456377029418945\n",
      "Predicted: [110, 82] Actual: 151 False  7.518716335296631\n",
      "Predicted: [110, 82] Actual: 152 False  7.338857173919678\n",
      "Predicted: [110, 82] Actual: 153 False  7.923068046569824\n",
      "Predicted: [82, 110] Actual: 154 False  6.971810340881348\n",
      "Predicted: [82, 96] Actual: 155 False  6.887312889099121\n",
      "Predicted: [82, 110] Actual: 156 False  6.991542816162109\n",
      "Predicted: [82, 141] Actual: 157 False  6.834541320800781\n",
      "Predicted: [82, 110] Actual: 158 False  6.998180866241455\n",
      "Predicted: [110, 82] Actual: 159 False  7.223724842071533\n",
      "Predicted: [110, 82] Actual: 160 False  6.897930145263672\n",
      "Predicted: [110, 82] Actual: 161 False  7.660162925720215\n",
      "Predicted: [82, 96] Actual: 162 False  6.9512128829956055\n",
      "Predicted: [110, 82] Actual: 163 False  7.069335460662842\n",
      "Predicted: [110, 82] Actual: 164 False  7.859707355499268\n",
      "Predicted: [110, 82] Actual: 165 False  7.593691825866699\n",
      "Predicted: [82, 96] Actual: 166 False  6.923901557922363\n",
      "Predicted: [82, 96] Actual: 167 False  6.993735313415527\n",
      "Predicted: [125, 110] Actual: 168 False  7.3860015869140625\n",
      "Predicted: [82, 110] Actual: 169 False  7.005186557769775\n",
      "Predicted: [110, 82] Actual: 170 False  8.083623886108398\n",
      "Predicted: [82, 141] Actual: 171 False  6.679007530212402\n",
      "Predicted: [110, 82] Actual: 172 False  7.183343887329102\n",
      "Predicted: [82, 141] Actual: 173 False  6.842184066772461\n",
      "Predicted: [110, 82] Actual: 174 False  7.486629962921143\n",
      "Predicted: [110, 82] Actual: 175 False  8.065686225891113\n",
      "Predicted: [82, 110] Actual: 176 False  7.054636001586914\n",
      "Predicted: [82, 110] Actual: 177 False  6.714171409606934\n",
      "Predicted: [110, 82] Actual: 178 False  7.9454121589660645\n",
      "Predicted: [110, 82] Actual: 179 False  7.341011047363281\n",
      "Predicted: [82, 96] Actual: 180 False  6.983070373535156\n",
      "Predicted: [110, 82] Actual: 181 False  7.163571834564209\n",
      "Predicted: [82, 110] Actual: 182 False  6.840295791625977\n",
      "Predicted: [82, 96] Actual: 183 False  6.841615676879883\n",
      "Predicted: [110, 82] Actual: 184 False  8.114386558532715\n",
      "Predicted: [82, 141] Actual: 185 False  6.823955535888672\n",
      "Predicted: [110, 82] Actual: 186 False  8.19632339477539\n",
      "Predicted: [82, 141] Actual: 187 False  6.969814300537109\n",
      "Predicted: [82, 141] Actual: 188 False  6.967350959777832\n",
      "Predicted: [82, 96] Actual: 189 False  6.842041015625\n",
      "Predicted: [110, 82] Actual: 190 False  7.325990676879883\n",
      "Predicted: [125, 82] Actual: 191 False  7.402796745300293\n",
      "Predicted: [110, 82] Actual: 192 False  7.658649444580078\n",
      "Predicted: [110, 82] Actual: 193 False  6.978820323944092\n",
      "Predicted: [110, 82] Actual: 194 False  7.487705230712891\n",
      "Predicted: [110, 82] Actual: 195 False  7.932976722717285\n",
      "Predicted: [110, 82] Actual: 196 False  6.980279445648193\n",
      "Predicted: [110, 82] Actual: 197 False  8.174121856689453\n",
      "Predicted: [110, 82] Actual: 198 False  7.589022636413574\n",
      "Predicted: [110, 82] Actual: 199 False  7.1403656005859375\n",
      "Predicted: [82, 141] Actual: 200 False  6.765218257904053\n",
      "Predicted: [110, 82] Actual: 201 False  7.230551719665527\n",
      "Predicted: [110, 82] Actual: 202 False  7.536162376403809\n",
      "Predicted: [82, 141] Actual: 203 False  6.980470657348633\n",
      "Predicted: [82, 96] Actual: 204 False  6.889646530151367\n",
      "Predicted: [82, 96] Actual: 205 False  6.9248762130737305\n",
      "Predicted: [82, 96] Actual: 206 False  6.7433953285217285\n",
      "Predicted: [110, 82] Actual: 207 False  7.867930889129639\n",
      "Predicted: [110, 82] Actual: 208 False  7.150215148925781\n",
      "Predicted: [110, 82] Actual: 209 False  7.548250675201416\n",
      "Predicted: [110, 82] Actual: 210 False  7.506626129150391\n",
      "Predicted: [110, 82] Actual: 211 False  7.053062438964844\n",
      "Predicted: [82, 96] Actual: 212 False  6.990612983703613\n",
      "Predicted: [82, 96] Actual: 213 False  6.851343154907227\n",
      "Predicted: [82, 110] Actual: 214 False  6.981267929077148\n",
      "Predicted: [110, 82] Actual: 215 False  7.1706767082214355\n",
      "Predicted: [82, 110] Actual: 216 False  6.941829681396484\n",
      "Predicted: [110, 82] Actual: 217 False  7.443175792694092\n",
      "Predicted: [110, 82] Actual: 218 False  7.182041168212891\n",
      "Predicted: [82, 110] Actual: 219 False  6.952988147735596\n",
      "Predicted: [82, 96] Actual: 220 False  7.067814350128174\n",
      "Predicted: [110, 82] Actual: 221 False  7.090423583984375\n",
      "Predicted: [110, 82] Actual: 222 False  7.072843551635742\n",
      "Predicted: [110, 82] Actual: 223 False  7.941185474395752\n",
      "Predicted: [110, 82] Actual: 224 False  7.1773881912231445\n",
      "Edge correct: 4    Size: 225  Edge correct/Size: 0.017777777777777778\n",
      "Grid size: 15\n",
      "6132\n",
      "4089\n",
      "10221\n",
      "Using cuda device\n",
      "Loaded model from model15.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.404878  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2908  size: 4089  main correct/size: 0.7111763267302519\n",
      "Also correct: 503  size: 4089  also correct/size: 0.12301296160430424\n",
      "Test Error: Accuracy: 83.4%, Avg loss: 1.305600\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.323482  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2909  size: 4089  main correct/size: 0.7114208853020298\n",
      "Also correct: 499  size: 4089  also correct/size: 0.12203472731719246\n",
      "Test Error: Accuracy: 83.3%, Avg loss: 1.305602\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.321894  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2913  size: 4089  main correct/size: 0.7123991195891416\n",
      "Also correct: 495  size: 4089  also correct/size: 0.1210564930300807\n",
      "Test Error: Accuracy: 83.3%, Avg loss: 1.305224\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.319823  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2914  size: 4089  main correct/size: 0.7126436781609196\n",
      "Also correct: 493  size: 4089  also correct/size: 0.12056737588652482\n",
      "Test Error: Accuracy: 83.3%, Avg loss: 1.304790\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "6132\n",
      "Training model\n",
      "loss: 1.317948  [   64/ 6132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 2914  size: 4089  main correct/size: 0.7126436781609196\n",
      "Also correct: 494  size: 4089  also correct/size: 0.12081193445830277\n",
      "Test Error: Accuracy: 83.3%, Avg loss: 1.304262\n",
      "Testing model\n",
      "Saved PyTorch Model State to model15.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [82, 110] Actual: 0  False  6.85887336730957\n",
      "Predicted: [110, 82] Actual: 1  False  7.697678565979004\n",
      "Predicted: [110, 82] Actual: 2  False  7.091064453125\n",
      "Predicted: [82, 141] Actual: 3  False  7.007668495178223\n",
      "Predicted: [82, 96] Actual: 4  False  7.006475448608398\n",
      "Predicted: [82, 141] Actual: 5  False  6.819049835205078\n",
      "Predicted: [110, 82] Actual: 6  False  7.478142261505127\n",
      "Predicted: [110, 82] Actual: 7  False  7.14641809463501\n",
      "Predicted: [82, 96] Actual: 8  False  7.0463738441467285\n",
      "Predicted: [82, 96] Actual: 9  False  7.079484462738037\n",
      "Predicted: [110, 82] Actual: 10 False  7.540985584259033\n",
      "Predicted: [82, 141] Actual: 11 False  6.953860759735107\n",
      "Predicted: [110, 82] Actual: 12 False  7.966108322143555\n",
      "Predicted: [82, 141] Actual: 13 False  6.949519634246826\n",
      "Predicted: [82, 141] Actual: 14 False  6.92987585067749\n",
      "Predicted: [82, 96] Actual: 15 False  6.9981160163879395\n",
      "Predicted: [110, 82] Actual: 16 False  7.028714656829834\n",
      "Predicted: [82, 141] Actual: 17 False  6.962976455688477\n",
      "Predicted: [82, 96] Actual: 18 False  6.8850884437561035\n",
      "Predicted: [82, 141] Actual: 19 False  7.04074239730835\n",
      "Predicted: [82, 110] Actual: 20 False  7.0100884437561035\n",
      "Predicted: [110, 82] Actual: 21 False  7.297548294067383\n",
      "Predicted: [125, 82] Actual: 22 False  7.782600402832031\n",
      "Predicted: [82, 141] Actual: 23 False  7.000203609466553\n",
      "Predicted: [82, 96] Actual: 24 False  6.7619547843933105\n",
      "Predicted: [82, 96] Actual: 25 False  7.020447254180908\n",
      "Predicted: [110, 82] Actual: 26 False  6.878848075866699\n",
      "Predicted: [82, 110] Actual: 27 False  6.877446174621582\n",
      "Predicted: [82, 110] Actual: 28 False  7.158066272735596\n",
      "Predicted: [82, 96] Actual: 29 False  7.0243144035339355\n",
      "Predicted: [82, 141] Actual: 30 False  7.011143207550049\n",
      "Predicted: [82, 141] Actual: 31 False  6.90769624710083\n",
      "Predicted: [82, 141] Actual: 32 False  6.895949840545654\n",
      "Predicted: [125, 110] Actual: 33 False  7.382519245147705\n",
      "Predicted: [82, 141] Actual: 34 False  6.900007724761963\n",
      "Predicted: [82, 141] Actual: 35 False  6.849161148071289\n",
      "Predicted: [82, 110] Actual: 36 False  6.9345622062683105\n",
      "Predicted: [125, 82] Actual: 37 False  7.285246849060059\n",
      "Predicted: [110, 82] Actual: 38 False  7.498885631561279\n",
      "Predicted: [110, 82] Actual: 39 False  7.086636543273926\n",
      "Predicted: [110, 82] Actual: 40 False  6.979772567749023\n",
      "Predicted: [110, 82] Actual: 41 False  7.6179656982421875\n",
      "Predicted: [110, 82] Actual: 42 False  6.942626953125\n",
      "Predicted: [110, 82] Actual: 43 False  7.059355735778809\n",
      "Predicted: [110, 82] Actual: 44 False  7.288090705871582\n",
      "Predicted: [82, 141] Actual: 45 False  6.959866046905518\n",
      "Predicted: [82, 110] Actual: 46 False  6.870884895324707\n",
      "Predicted: [82, 96] Actual: 47 False  6.935775279998779\n",
      "Predicted: [82, 141] Actual: 48 False  6.964613437652588\n",
      "Predicted: [82, 141] Actual: 49 False  7.152414798736572\n",
      "Predicted: [82, 141] Actual: 50 False  6.917609691619873\n",
      "Predicted: [82, 141] Actual: 51 False  6.891791820526123\n",
      "Predicted: [82, 141] Actual: 52 False  6.959178447723389\n",
      "Predicted: [82, 96] Actual: 53 False  6.97756814956665\n",
      "Predicted: [125, 82] Actual: 54 False  7.123317718505859\n",
      "Predicted: [82, 141] Actual: 55 False  6.965952396392822\n",
      "Predicted: [82, 141] Actual: 56 False  6.980222225189209\n",
      "Predicted: [82, 96] Actual: 57 False  6.892439365386963\n",
      "Predicted: [82, 96] Actual: 58 False  6.8715643882751465\n",
      "Predicted: [82, 96] Actual: 59 False  6.815558433532715\n",
      "Predicted: [82, 96] Actual: 60 False  6.83971643447876\n",
      "Predicted: [110, 82] Actual: 61 False  7.4341816902160645\n",
      "Predicted: [82, 141] Actual: 62 False  6.97196102142334\n",
      "Predicted: [82, 141] Actual: 63 False  6.978396892547607\n",
      "Predicted: [82, 141] Actual: 64 False  6.887244701385498\n",
      "Predicted: [82, 110] Actual: 65 False  7.0679168701171875\n",
      "Predicted: [110, 82] Actual: 66 False  8.183889389038086\n",
      "Predicted: [82, 141] Actual: 67 False  7.285233974456787\n",
      "Predicted: [82, 110] Actual: 68 False  6.946322917938232\n",
      "Predicted: [82, 141] Actual: 69 False  6.976102828979492\n",
      "Predicted: [110, 82] Actual: 70 False  7.122009754180908\n",
      "Predicted: [110, 82] Actual: 71 False  7.40629768371582\n",
      "Predicted: [82, 110] Actual: 72 False  6.9519267082214355\n",
      "Predicted: [82, 96] Actual: 73 False  7.04206657409668\n",
      "Predicted: [110, 82] Actual: 74 False  7.282425880432129\n",
      "Predicted: [110, 82] Actual: 75 False  6.97065544128418\n",
      "Predicted: [82, 141] Actual: 76 False  7.023737907409668\n",
      "Predicted: [82, 141] Actual: 77 False  6.753777027130127\n",
      "Predicted: [82, 110] Actual: 78 False  6.950577259063721\n",
      "Predicted: [82, 141] Actual: 79 False  7.048672199249268\n",
      "Predicted: [110]   Actual: 80 False  9.00273323059082\n",
      "Predicted: [82, 141] Actual: 81 False  7.313169002532959\n",
      "Predicted: [82, 141] Actual: 82 True   7.6715240478515625\n",
      "Predicted: [82, 141] Actual: 83 False  6.949068546295166\n",
      "Predicted: [82, 141] Actual: 84 False  6.743040084838867\n",
      "Predicted: [82, 141] Actual: 85 False  6.8271565437316895\n",
      "Predicted: [82, 141] Actual: 86 False  6.96257209777832\n",
      "Predicted: [82, 141] Actual: 87 False  7.055549621582031\n",
      "Predicted: [82, 110] Actual: 88 False  6.71373176574707\n",
      "Predicted: [110, 82] Actual: 89 False  7.186002731323242\n",
      "Predicted: [82, 110] Actual: 90 False  6.873532772064209\n",
      "Predicted: [82, 96] Actual: 91 False  6.926196098327637\n",
      "Predicted: [82, 110] Actual: 92 False  6.845508098602295\n",
      "Predicted: [110, 82] Actual: 93 False  7.412500858306885\n",
      "Predicted: [125]   Actual: 94 False  8.671649932861328\n",
      "Predicted: [110, 82] Actual: 95 False  7.277959823608398\n",
      "Predicted: [110, 82] Actual: 96 False  8.263497352600098\n",
      "Predicted: [82, 141] Actual: 97 False  6.734020709991455\n",
      "Predicted: [110, 82] Actual: 98 False  6.868473052978516\n",
      "Predicted: [82, 141] Actual: 99 False  6.746761322021484\n",
      "Predicted: [82, 96] Actual: 100 False  7.1141557693481445\n",
      "Predicted: [82, 141] Actual: 101 False  7.002262592315674\n",
      "Predicted: [82, 141] Actual: 102 False  6.833618640899658\n",
      "Predicted: [82, 96] Actual: 103 False  6.9459309577941895\n",
      "Predicted: [82, 125] Actual: 104 False  7.203203201293945\n",
      "Predicted: [82, 96] Actual: 105 False  6.976060390472412\n",
      "Predicted: [82, 141] Actual: 106 False  6.825634479522705\n",
      "Predicted: [110, 82] Actual: 107 False  7.372657775878906\n",
      "Predicted: [110, 82] Actual: 108 False  6.991458892822266\n",
      "Predicted: [82, 141] Actual: 109 False  6.854615688323975\n",
      "Predicted: [110]   Actual: 110 True   66.63524627685547\n",
      "Predicted: [82, 141] Actual: 111 False  6.925283908843994\n",
      "Predicted: [82, 110] Actual: 112 False  6.941823959350586\n",
      "Predicted: [82, 141] Actual: 113 False  6.919655799865723\n",
      "Predicted: [82, 141] Actual: 114 False  6.825319766998291\n",
      "Predicted: [82, 141] Actual: 115 False  6.842563152313232\n",
      "Predicted: [82, 141] Actual: 116 False  7.0069708824157715\n",
      "Predicted: [82, 141] Actual: 117 False  6.978847503662109\n",
      "Predicted: [82, 96] Actual: 118 False  6.882889270782471\n",
      "Predicted: [110, 82] Actual: 119 False  7.648751258850098\n",
      "Predicted: [110, 82] Actual: 120 False  7.084211349487305\n",
      "Predicted: [82, 141] Actual: 121 False  7.03232479095459\n",
      "Predicted: [82, 110] Actual: 122 False  6.8226423263549805\n",
      "Predicted: [110, 82] Actual: 123 False  7.162454605102539\n",
      "Predicted: [82, 141] Actual: 124 False  6.934563159942627\n",
      "Predicted: [125]   Actual: 125 True   178.30996704101562\n",
      "Predicted: [82, 141] Actual: 126 False  6.913349628448486\n",
      "Predicted: [82, 141] Actual: 127 False  6.896884918212891\n",
      "Predicted: [110, 82] Actual: 128 False  7.114650249481201\n",
      "Predicted: [82, 141] Actual: 129 False  6.966993808746338\n",
      "Predicted: [82, 141] Actual: 130 False  6.977148532867432\n",
      "Predicted: [82, 125] Actual: 131 False  6.918184757232666\n",
      "Predicted: [82, 141] Actual: 132 False  6.928770542144775\n",
      "Predicted: [125, 82] Actual: 133 False  7.606746673583984\n",
      "Predicted: [82, 96] Actual: 134 False  6.93928861618042\n",
      "Predicted: [82, 96] Actual: 135 False  6.959970951080322\n",
      "Predicted: [110, 82] Actual: 136 False  7.854263782501221\n",
      "Predicted: [125, 82] Actual: 137 False  7.497740745544434\n",
      "Predicted: [125, 82] Actual: 138 False  7.332962512969971\n",
      "Predicted: [82, 110] Actual: 139 False  6.833073139190674\n",
      "Predicted: [82, 141] Actual: 140 False  7.068272113800049\n",
      "Predicted: [82, 141] Actual: 141 True   7.191247463226318\n",
      "Predicted: [82, 141] Actual: 142 False  6.742029666900635\n",
      "Predicted: [82, 96] Actual: 143 False  6.916722297668457\n",
      "Predicted: [82, 96] Actual: 144 False  6.8253865242004395\n",
      "Predicted: [82, 110] Actual: 145 False  6.847458362579346\n",
      "Predicted: [110, 82] Actual: 146 False  7.841315746307373\n",
      "Predicted: [125]   Actual: 147 False  9.097277641296387\n",
      "Predicted: [82, 110] Actual: 148 False  7.040973663330078\n",
      "Predicted: [82, 96] Actual: 149 False  6.958425045013428\n",
      "Predicted: [82, 96] Actual: 150 False  6.985908508300781\n",
      "Predicted: [82, 110] Actual: 151 False  7.07030725479126\n",
      "Predicted: [82, 96] Actual: 152 False  7.127790927886963\n",
      "Predicted: [110, 82] Actual: 153 False  7.420750617980957\n",
      "Predicted: [82, 141] Actual: 154 False  7.016151428222656\n",
      "Predicted: [82, 96] Actual: 155 False  6.925323009490967\n",
      "Predicted: [82, 141] Actual: 156 False  7.04513692855835\n",
      "Predicted: [82, 141] Actual: 157 False  6.884932041168213\n",
      "Predicted: [82, 141] Actual: 158 False  7.040040493011475\n",
      "Predicted: [82, 96] Actual: 159 False  7.028595924377441\n",
      "Predicted: [82, 96] Actual: 160 False  6.809765338897705\n",
      "Predicted: [110, 125] Actual: 161 False  7.10620641708374\n",
      "Predicted: [82, 125] Actual: 162 False  6.988749980926514\n",
      "Predicted: [82, 96] Actual: 163 False  6.960394382476807\n",
      "Predicted: [110, 82] Actual: 164 False  7.317691802978516\n",
      "Predicted: [110, 82] Actual: 165 False  7.068251132965088\n",
      "Predicted: [82, 96] Actual: 166 False  6.964747428894043\n",
      "Predicted: [82, 141] Actual: 167 False  7.033760070800781\n",
      "Predicted: [125, 82] Actual: 168 False  8.144418716430664\n",
      "Predicted: [82, 96] Actual: 169 False  7.0484843254089355\n",
      "Predicted: [110, 82] Actual: 170 False  7.5510430335998535\n",
      "Predicted: [82, 141] Actual: 171 False  6.722503185272217\n",
      "Predicted: [82, 141] Actual: 172 False  7.03401517868042\n",
      "Predicted: [82, 141] Actual: 173 False  6.887364864349365\n",
      "Predicted: [110, 82] Actual: 174 False  6.909875869750977\n",
      "Predicted: [110, 82] Actual: 175 False  7.496306419372559\n",
      "Predicted: [82, 125] Actual: 176 False  7.095284938812256\n",
      "Predicted: [82, 141] Actual: 177 False  6.756717205047607\n",
      "Predicted: [110, 82] Actual: 178 False  7.39865779876709\n",
      "Predicted: [82, 96] Actual: 179 False  7.097242832183838\n",
      "Predicted: [82, 141] Actual: 180 False  7.024781227111816\n",
      "Predicted: [82, 110] Actual: 181 False  6.93304967880249\n",
      "Predicted: [82, 141] Actual: 182 False  6.881940841674805\n",
      "Predicted: [82, 141] Actual: 183 False  6.879579544067383\n",
      "Predicted: [110, 82] Actual: 184 False  7.583889961242676\n",
      "Predicted: [82, 141] Actual: 185 False  6.866226673126221\n",
      "Predicted: [110, 82] Actual: 186 False  7.652978420257568\n",
      "Predicted: [82, 141] Actual: 187 False  7.016388416290283\n",
      "Predicted: [82, 141] Actual: 188 False  7.019338130950928\n",
      "Predicted: [82, 141] Actual: 189 False  6.882214069366455\n",
      "Predicted: [82, 110] Actual: 190 False  6.975857257843018\n",
      "Predicted: [125, 82] Actual: 191 False  8.146926879882812\n",
      "Predicted: [110, 82] Actual: 192 False  7.11285400390625\n",
      "Predicted: [82, 96] Actual: 193 False  6.821835041046143\n",
      "Predicted: [110, 82] Actual: 194 False  6.96751594543457\n",
      "Predicted: [110, 82] Actual: 195 False  7.395904064178467\n",
      "Predicted: [82, 96] Actual: 196 False  6.973965167999268\n",
      "Predicted: [110, 82] Actual: 197 False  7.672754764556885\n",
      "Predicted: [110, 82] Actual: 198 False  7.0570878982543945\n",
      "Predicted: [82, 96] Actual: 199 False  6.9396772384643555\n",
      "Predicted: [82, 141] Actual: 200 False  6.808211803436279\n",
      "Predicted: [82, 110] Actual: 201 False  6.968878746032715\n",
      "Predicted: [110, 82] Actual: 202 False  7.0002946853637695\n",
      "Predicted: [82, 141] Actual: 203 False  7.024010181427002\n",
      "Predicted: [82, 125] Actual: 204 False  6.92419958114624\n",
      "Predicted: [82, 141] Actual: 205 False  6.964404582977295\n",
      "Predicted: [82, 141] Actual: 206 False  6.784687519073486\n",
      "Predicted: [110, 82] Actual: 207 False  7.365691661834717\n",
      "Predicted: [82, 125] Actual: 208 False  6.949338436126709\n",
      "Predicted: [82, 110] Actual: 209 False  7.034365177154541\n",
      "Predicted: [110, 82] Actual: 210 False  6.9729766845703125\n",
      "Predicted: [82, 141] Actual: 211 False  6.938699245452881\n",
      "Predicted: [82, 141] Actual: 212 False  7.032020092010498\n",
      "Predicted: [82, 141] Actual: 213 False  6.893805027008057\n",
      "Predicted: [82, 141] Actual: 214 False  7.023641586303711\n",
      "Predicted: [82, 110] Actual: 215 False  6.896725177764893\n",
      "Predicted: [82, 141] Actual: 216 False  6.983463764190674\n",
      "Predicted: [110, 82] Actual: 217 False  6.929242134094238\n",
      "Predicted: [82, 110] Actual: 218 False  6.940145015716553\n",
      "Predicted: [82, 96] Actual: 219 False  6.990931987762451\n",
      "Predicted: [82, 96] Actual: 220 False  7.107873439788818\n",
      "Predicted: [82, 110] Actual: 221 False  6.7953972816467285\n",
      "Predicted: [82, 141] Actual: 222 False  6.849477291107178\n",
      "Predicted: [110, 82] Actual: 223 False  7.382151126861572\n",
      "Predicted: [82, 110] Actual: 224 False  6.964661121368408\n",
      "Edge correct: 4    Size: 225  Edge correct/Size: 0.017777777777777778\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "grid_size = 15\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "chunk_amount = 10222\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "with open('output3.txt', 'a') as f:\n",
    "    for size in range(5, 10):\n",
    "        #grid_size = size\n",
    "        print(f'Grid size: {grid_size}')\n",
    "        f.write(f'Grid size: {grid_size}\\n')\n",
    "        f.write(f'Correct Tolerance {int(max(1, np.floor(grid_size/2)))}\\n')\n",
    "        f.write(f'Chunk Amount: {chunk_amount}\\n')\n",
    "        f.write('------------------------------------------\\n')\n",
    "        class AccidentDataset(Dataset):\n",
    "            def __init__(self, transform=None):\n",
    "                self.coordinates = data\n",
    "                self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "                \n",
    "                #split into 500 chunks using numpy\n",
    "                self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "                #process each chunk and merge it back into one dataframe\n",
    "                self.grids = []\n",
    "                grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "                grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "                grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "                grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "                for i in range(len(self.coordinates)-1):\n",
    "                    grid = np.zeros((grid_size, grid_size))\n",
    "                    for index, row in self.coordinates[i].iterrows():\n",
    "                        coordinates = row['latitude'], row['longitude']\n",
    "                        for j in range(grid_size):\n",
    "                            for k in range(grid_size):\n",
    "                                lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                                lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                                long_lower = grid_lower_long + k * grid_long_step\n",
    "                                long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                                if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                                    grid[j][k] += 1\n",
    "                                    break\n",
    "                    self.grids.append(grid/chunk_size)\n",
    "                self.grids = np.array(self.grids)\n",
    "                self.transform = transform      \n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.grids)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                if torch.is_tensor(idx):\n",
    "                    idx = idx.tolist()\n",
    "\n",
    "                grid = self.grids[idx]\n",
    "                grid = torch.from_numpy(grid).float()\n",
    "\n",
    "                max_index = np.argmax(grid)\n",
    "                max_index = np.array(max_index)\n",
    "                return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "        accident_dataset = AccidentDataset()\n",
    "\n",
    "        #Create new array with 60% of the data\n",
    "        train_size = int(0.6 * len(accident_dataset))\n",
    "        test_size = len(accident_dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "        print(len(train_dataset))\n",
    "        print(len(test_dataset))\n",
    "        print(len(accident_dataset))\n",
    "\n",
    "        #Create dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        class Network(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                #x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        # building the model object\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        #device = torch.device('cpu')\n",
    "        print(f'Using {device} device')\n",
    "\n",
    "        model = Network().to(device)\n",
    "        if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "            model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "            print(f\"Loaded model from model{grid_size}.pth\")\n",
    "        else:\n",
    "            print(\"No model found, creating new model\")\n",
    "\n",
    "        # define the loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "        # define the training loop\n",
    "        def train(dataloader, model, loss_fn, optimizer):\n",
    "            size = len(dataloader.dataset)\n",
    "            print(size)\n",
    "            model.train()\n",
    "            print(\"Training model\")\n",
    "            for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                #print('pred ', pred)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"Finished training model\")\n",
    "\n",
    "        def test(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "            print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "        def logtest(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            f.write(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\\n\")\n",
    "            f.write(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\\n\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            f.write(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "        \n",
    "        epochs = 5\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        logtest(test_dataloader, model, loss_fn)\n",
    "        torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "        print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "        model.eval()\n",
    "        edge_correct = 0\n",
    "        f.write('------------------------------------------\\nEdge cases:\\n')\n",
    "        print('------------------------------------------\\nEdge cases:')\n",
    "        for i in range (grid_size ** 2):\n",
    "            randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "            edge = np.zeros(grid_size ** 2)\n",
    "            edge[i] = 1\n",
    "            x, y = torch.tensor(edge).float(), i\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model(x.to(device))\n",
    "                #print(pred)\n",
    "                predicted, actual = pred.topk(grid_size), y\n",
    "                max_value = pred.max(0)[0]\n",
    "                index = []\n",
    "                for j in range(len(predicted)):\n",
    "                    if predicted.values[j].item() >= 0.8 * max_value:\n",
    "                        index.append(predicted.indices[j].item())\n",
    "                part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "                part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "                part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "                part4 = f'{max_value}'.ljust(10, ' ')\n",
    "                print(part1, part2, part3, part4)\n",
    "                f.write(part1 + part2 + part3 + part4 + '\\n')\n",
    "                #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "                edge_correct += actual in index\n",
    "        f.write('------------------------------------------\\n')\n",
    "        edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "        edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "        edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "        print(edgestr1, edgestr2, edgestr3)\n",
    "        f.write(edgestr1 + edgestr2 + edgestr3 + '\\n')\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
