{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    print(\"Loaded model from model.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x.to(device))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "dbPath = r'Data\\datasetNY.db'\n",
    "dbConnection = sqlite3.connect(dbPath)\n",
    "\n",
    "dbData = []\n",
    "\n",
    "#Retrieve the data from the database\n",
    "try:\n",
    "    dbData = dbConnection.execute('SELECT * FROM Motor_Vehicle_Collisions_Crashes').fetchall()\n",
    "except:\n",
    "    print('Error retrieving the data from the database')\n",
    "else:\n",
    "    print('Successfully retrieved the data from the databse')\n",
    "\n",
    "first = int(float(dbData[1][2]))\n",
    "\n",
    "n_input = first\n",
    "n_hidden = 15\n",
    "n_out = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "data_x = torch.randn(batch_size, n_input)\n",
    "data_y = (torch.rand(size=(batch_size, 1)) < 0.5).float()\n",
    "\n",
    "print(data_x.size())\n",
    "print(data_y.size())\n",
    "\n",
    "model = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_hidden, n_out),\n",
    "                      nn.Sigmoid())\n",
    "print(model)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(5000):\n",
    "    pred_y = model(data_x)\n",
    "    loss = loss_function(pred_y, data_y)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Learning rate %f\"%(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "dbConnection.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9552a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1631345700.0, '40.667202', '-73.8665']\n",
      "{'datetime': tensor(1.6313e+09), 'coordinates': tensor([ 40.6672, -73.8665])}\n",
      "tensor(40.6672)\n",
      "tensor(1.6313e+09)\n",
      "17415\n",
      "1724172\n",
      "1741587\n",
      "Using cuda device\n",
      "No model found, creating new model\n",
      "Network(\n",
      "  (fclayer1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (fclayer2): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "17415\n",
      "Training model\n",
      "tensor([1.4393e+09, 1.5375e+09, 1.4409e+09, 1.6534e+09, 1.3740e+09, 1.4931e+09,\n",
      "        1.6136e+09, 1.5694e+09, 1.4135e+09, 1.4345e+09]) tensor([[ 40.6960, -73.9435],\n",
      "        [ 40.8538, -73.9073],\n",
      "        [ 40.5684, -74.1413],\n",
      "        [ 40.6642, -73.9455],\n",
      "        [ 40.7675, -73.8819],\n",
      "        [ 40.7030, -73.9443],\n",
      "        [ 40.7162, -74.0026],\n",
      "        [ 40.6573, -73.9741],\n",
      "        [ 40.7453, -73.9985],\n",
      "        [ 40.8283, -73.8829]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programmer\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([10, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22368\\65222559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22368\\65222559.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "dbPath = r'Data\\datasetNY.db'\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, db_path, transform=None):\n",
    "        self.coordinates = dbHandler.get_all_data_datetime_converted(db_path)\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coordinates)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        datetime = self.coordinates.iloc[idx, 0:1]\n",
    "        datetime = np.array([datetime]).squeeze()\n",
    "        datetime = datetime.astype('float')\n",
    "        datetime = torch.from_numpy(datetime).float()\n",
    "\n",
    "        coordinates = self.coordinates.iloc[idx, 1:3]\n",
    "        coordinates = np.array([coordinates]).squeeze()\n",
    "        coordinates = coordinates.astype('float')\n",
    "        coordinates = torch.from_numpy(coordinates).float()\n",
    "        sample = {'datetime' : datetime, 'coordinates': coordinates}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "#     #Making constructor\n",
    "#     def __init__(self, dbData, root_dir, transform_none):\n",
    "#         self.coordinates = dbData\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform_none\n",
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "# load data from database and split into train and test\n",
    "\n",
    "\n",
    "accident_dataset = AccidentDataset(dbPath)\n",
    "\n",
    "print(accident_dataset[0])\n",
    "print(accident_dataset[0]['coordinates'][0])\n",
    "print(accident_dataset[0]['datetime'])\n",
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.01 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "#Creating Network class\n",
    "class Network(nn.Module):\n",
    "\n",
    "    #Making constructor\n",
    "    def __init__(self, input_size, number_of_classes):\n",
    "        super(Network, self).__init__()\n",
    "        #Creating fully connected layers\n",
    "        self.fclayer1 = nn.Linear(input_size, 50)\n",
    "        self.fclayer2 = nn.Linear(50, number_of_classes)\n",
    "    \n",
    "    #Creating forward method to do forward propagation\n",
    "    def forward(self, input):\n",
    "        input = nn.functional.relu(self.fclayer1(input))\n",
    "        input = self.fclayer2(input)\n",
    "        return input\n",
    "    \n",
    "\n",
    "#Get cpu or gpu device for training.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network(10, 2).to(device)\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    print(\"Loaded model from model.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        X, y = batch['datetime'], batch['coordinates']\n",
    "        print(X, y)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\") \n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
