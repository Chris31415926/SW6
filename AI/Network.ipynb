{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f366a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1565614800.0, '40.74885', '-73.98158']\n",
      "599\n",
      "400\n",
      "999\n",
      "あいうえお\n",
      "らりるれろ\n",
      "かきくけこ\n",
      "さしすせそ\n",
      "たちつてと\n",
      "なにぬねの\n",
      "はひふへほ\n",
      "まみむめも\n",
      "やゆよ\n",
      "わをん\n",
      "がぎぐげご\n",
      "ざじずぜぞ\n",
      "だぢづでど\n",
      "ばびぶべぼ\n",
      "ぱぴぷぺぽ\n",
      "っ\n",
      "アイウエオ\n",
      "ラリルレロ\n",
      "カキクケコ\n",
      "サシスセソ\n",
      "タチツテト\n",
      "ナニヌネノ\n",
      "ハヒフヘホ\n",
      "マミムメモ\n",
      "ヤユヨ\n",
      "ワヲン\n",
      "ガギグゲゴ\n",
      "ザジズゼゾ\n",
      "ダヂヅデド\n",
      "バビブベボ\n",
      "パピプペポ\n",
      "ッ\n",
      "日本語\n",
      "漢字\n",
      "ひらがな\n",
      "カタカナ\n",
      "アルファベット\n",
      "数字\n",
      "記号\n",
      "英語\n",
      "中国語\n",
      "韓国語\n",
      "MILF\n",
      "BOOBA\n",
      "YEEEHHHAAAWWW\n",
      "To fly is to controllably float using air as leverage, despite the gravitational pull of some giant mass\n",
      "Using cuda device\n",
      "Loaded model from model.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.216669  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.482037\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.160789  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.481331\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.140466  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.482588\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.127109  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.483557\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.117067  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.484281\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.109239  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.484875\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.102994  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.485380\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.097894  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.485836\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.093525  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.486246\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.089695  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.486615\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.086259  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.486953\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.083102  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.487272\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.080100  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.487560\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.077289  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.487826\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.074635  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.488088\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.072035  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.488345\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.069456  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.488583\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.066987  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.488817\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.064575  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.489046\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.062216  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.489273\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.059899  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.489497\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.057628  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.489721\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.055401  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.489945\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.053211  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.490171\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.051065  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.490400\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.048959  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.490630\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.046891  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.490861\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.044869  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.491101\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.042879  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.491340\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.040935  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.491584\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.039028  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.491838\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.037151  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.492091\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.035322  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.492357\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.033517  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.492623\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.031758  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.492895\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.030036  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.493174\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.028342  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.493454\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.026691  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.493750\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.025057  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.494041\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.023476  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.494345\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.021912  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.494653\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.020388  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.494967\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.018891  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.495286\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.017424  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.495610\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.015993  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.495940\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.014585  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.496272\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.013216  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.496612\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.011866  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.496957\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.010545  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.497304\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "599\n",
      "Training model\n",
      "loss: 23.009260  [   25/  599]\n",
      "Finished training model\n",
      "Testing model\n",
      "Test Error: Accuracy: 335.2%, Avg loss: 20.497659\n",
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "dataAmount = 200000\n",
    "dbPath = r'Data\\datasetNY.db'\n",
    "gridSize = 5\n",
    "chunkAmount = 1000\n",
    "chunkSize = dataAmount / chunkAmount\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, db_path, transform=None):\n",
    "        self.coordinates = dbHandler.get_n_data_datetime_converted(db_path, dataAmount)\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        \n",
    "        #split into 500 chunks using numpy\n",
    "        self.coordinates = np.array_split(self.coordinates, chunkAmount)\n",
    "\n",
    "        #process each chunk and merge it back into one dataframe\n",
    "        self.grids = []\n",
    "        grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "        grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "        grid_lat_step = (grid_upper_lat - grid_lower_lat) / gridSize\n",
    "        grid_long_step = (grid_upper_long - grid_lower_long) / gridSize\n",
    "        for i in range(len(self.coordinates)-1):\n",
    "            grid = np.zeros((gridSize, gridSize))\n",
    "            for index, row in self.coordinates[i].iterrows():\n",
    "                coordinates = row['latitude'], row['longitude']\n",
    "                for j in range(gridSize):\n",
    "                    for k in range(gridSize):\n",
    "                        lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                        lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                        long_lower = grid_lower_long + k * grid_long_step\n",
    "                        long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                        if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                            grid[j][k] += 1\n",
    "                            break\n",
    "            self.grids.append(grid/chunkSize)\n",
    "        self.grids = np.array(self.grids)\n",
    "        self.transform = transform      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        grid = self.grids[idx]\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "\n",
    "        max_index = np.argmax(grid)\n",
    "        max_index = np.array(max_index)\n",
    "        #get indicies of the highest value and nearest neighbours that are within 10% of the highest value\n",
    "        #max_index = np.unravel_index(max_index, grid.shape)\n",
    "        #max_index = np.array(max_index)\n",
    "        #max_index = max_index.flatten()\n",
    "        Jonasu_wa_kanji_o_motte_imasu = max_index.item() // gridSize, max_index.item() % gridSize\n",
    "        max_value = grid[Jonasu_wa_kanji_o_motte_imasu[0]][Jonasu_wa_kanji_o_motte_imasu[1]].item()\n",
    "        indicies = np.empty((0,2), float)\n",
    "        for i in range(gridSize):\n",
    "            for j in range(gridSize):\n",
    "                if grid[i][j].item() >= max_value * 0.9:\n",
    "                    indicies = np.append(indicies, i * gridSize + j)\n",
    "\n",
    "        indicies = torch.from_numpy(indicies).reshape(-1, 1).flatten()\n",
    "        indicies = torch.nn.functional.pad(indicies, (0, gridSize - len(indicies)), value=0)\n",
    "        return grid, indicies\n",
    "\n",
    "accident_dataset = AccidentDataset(dbPath)\n",
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.6 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "print('あいうえお') #aiueo\n",
    "print('らりるれろ') #rarirurero\n",
    "print('かきくけこ') #kakikukeko\n",
    "print('さしすせそ') #sashisuseso\n",
    "print('たちつてと') #tachitsuteto\n",
    "print('なにぬねの') #naninuneno\n",
    "print('はひふへほ') #hahifuheho\n",
    "print('まみむめも') #mamimumemo\n",
    "print('やゆよ') #yayuyo\n",
    "print('わをん') #wawon\n",
    "print('がぎぐげご') #gagigugego\n",
    "print('ざじずぜぞ') #zazizuzezo\n",
    "print('だぢづでど') #dazidizudezo\n",
    "print('ばびぶべぼ') #babibubebo\n",
    "print('ぱぴぷぺぽ') #papipupepo\n",
    "print('っ') #small tsu\n",
    "\n",
    "#now in katakana\n",
    "print('アイウエオ') #aiueo\n",
    "print('ラリルレロ') #rarirurero\n",
    "print('カキクケコ') #kakikukeko\n",
    "print('サシスセソ') #sashisuseso\n",
    "print('タチツテト') #tachitsuteto\n",
    "print('ナニヌネノ') #naninuneno\n",
    "print('ハヒフヘホ') #hahifuheho\n",
    "print('マミムメモ') #mamimumemo\n",
    "print('ヤユヨ') #yayuyo\n",
    "print('ワヲン') #wawon\n",
    "print('ガギグゲゴ') #gagigugego\n",
    "print('ザジズゼゾ') #zazizuzezo\n",
    "print('ダヂヅデド') #dazidizudezo\n",
    "print('バビブベボ') #babibubebo\n",
    "print('パピプペポ') #papipupepo\n",
    "print('ッ') #small tsu\n",
    "\n",
    "#now in kanji\n",
    "print('日本語') #nihongo\n",
    "print('漢字') #kanji\n",
    "print('ひらがな') #hiragana\n",
    "print('カタカナ') #katakana\n",
    "print('アルファベット') #alphabet\n",
    "print('数字') #number\n",
    "print('記号') #symbol\n",
    "print('英語') #english\n",
    "print('中国語') #chinese\n",
    "print('韓国語') #korean\n",
    "\n",
    "#Now in your mom\n",
    "print('MILF') #Jonas\n",
    "print('BOOBA') #NotJonas\n",
    "print('YEEEHHHAAAWWW') #Jonasu\n",
    "\n",
    "print('To fly is to controllably float using air as leverage, despite the gravitational pull of some giant mass') #JonasDescription\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=gridSize*gridSize, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=gridSize, shuffle=False)\n",
    "\n",
    "# define the class for multilinear regression\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(gridSize*gridSize, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, gridSize),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# define the class for multilinear regression\n",
    "# building the model object\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network().to(device)\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    print(\"Loaded model from model.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# define the training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        #print(X)\n",
    "        #print(y)\n",
    "        pred = model(X)\n",
    "        #print('pred: ', pred)\n",
    "        #print('y: ', y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    print(\"Testing model\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
