{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9892de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450620000.0, '40.6720753', '-73.9113364']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "grid_size = 5\n",
    "chunk_amount = 85555\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "class AccidentDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.coordinates = data\n",
    "        self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "        \n",
    "        #split into 500 chunks using numpy\n",
    "        self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "        #process each chunk and merge it back into one dataframe\n",
    "        self.grids = []\n",
    "        grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "        grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "        grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "        grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "        for i in range(len(self.coordinates)-1):\n",
    "            grid = np.zeros((grid_size, grid_size))\n",
    "            for index, row in self.coordinates[i].iterrows():\n",
    "                coordinates = row['latitude'], row['longitude']\n",
    "                for j in range(grid_size):\n",
    "                    for k in range(grid_size):\n",
    "                        lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                        lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                        long_lower = grid_lower_long + k * grid_long_step\n",
    "                        long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                        if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                            grid[j][k] += 1\n",
    "                            break\n",
    "            self.grids.append(grid/chunk_size)\n",
    "        self.grids = np.array(self.grids)\n",
    "        self.transform = transform      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        grid = self.grids[idx]\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "\n",
    "        max_index = np.argmax(grid)\n",
    "        max_index = np.array(max_index)\n",
    "        return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "accident_dataset = AccidentDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f366a4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accident_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55240\\1389412538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create new array with 60% of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccident_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accident_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create new array with 60% of the data\n",
    "train_size = int(0.6 * len(accident_dataset))\n",
    "test_size = len(accident_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(accident_dataset))\n",
    "\n",
    "#Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# define the class for multilinear regression\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(grid_size ** 2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, grid_size ** 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# define the class for multilinear regression\n",
    "# building the model object\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = Network().to(device)\n",
    "if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "    model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "    print(f\"Loaded model from model{grid_size}.pth\")\n",
    "else:\n",
    "    print(\"No model found, creating new model\")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# define the training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    print(\"Training model\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print('pred ', pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(\"Finished training model\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    print(\"Testing model\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, also_correct = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print('y ', y)\n",
    "            #print('predition', pred.argmax(1))\n",
    "\n",
    "            #check if prediction is correct\n",
    "            predictions = torch.topk(pred, 2, dim=1).indices\n",
    "            #is_correct = (pred.argmax(1) == y or pred.argmax(1) == max_value)\n",
    "\n",
    "            for i in range (len(predictions)):\n",
    "                if y[i] in predictions[i]:\n",
    "                    if y[i] == pred.argmax(1)[i]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        also_correct += 1\n",
    "\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            #print(correct)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "    print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "    correct += also_correct\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "epochs = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "model.eval()\n",
    "edge_correct = 0\n",
    "for i in range (grid_size ** 2):\n",
    "    randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "    #randomnumber = 86903\n",
    "    #print(randomnumber)\n",
    "    #x, y = test_dataset[randomnumber][0], test_dataset[randomnumber][1]\n",
    "    edge = np.zeros(grid_size ** 2)\n",
    "    edge[i] = 1\n",
    "    x, y = torch.tensor(edge).float(), i\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.to(device))\n",
    "        #print(pred)\n",
    "        predicted, actual = pred.topk(grid_size), y\n",
    "        max_value = pred.max(0)[0]\n",
    "        index = []\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted.values[i].item() >= 0.8 * max_value:\n",
    "                index.append(predicted.indices[i].item())\n",
    "        part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "        part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "        part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "        part4 = f'{max_value}'.ljust(10, ' ')\n",
    "        print(part1, part2, part3, part4)\n",
    "        #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "        edge_correct += actual in index\n",
    "print('------------------------------------------')\n",
    "edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "print(edgestr1, edgestr2, edgestr3)\n",
    "#print(f\"Edge correct: {edge_correct}  size: {25}  edge correct/size: {edge_correct/25}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d3e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1363023000.0, '40.6878706', '-73.9783472']\n",
      "Grid size: 5\n",
      "54132\n",
      "36089\n",
      "90221\n",
      "Using cuda device\n",
      "Loaded model from model5.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.528412  [   64/54132]\n",
      "loss: 1.613947  [ 6464/54132]\n",
      "loss: 1.753047  [12864/54132]\n",
      "loss: 1.831680  [19264/54132]\n",
      "loss: 1.598437  [25664/54132]\n",
      "loss: 1.857554  [32064/54132]\n",
      "loss: 1.485568  [38464/54132]\n",
      "loss: 1.494555  [44864/54132]\n",
      "loss: 1.585292  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 20125  size: 36089  main correct/size: 0.557649145168888\n",
      "Also correct: 4583  size: 36089  also correct/size: 0.12699160408988888\n",
      "Test Error: Accuracy: 68.5%, Avg loss: 1.624158\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.512246  [   64/54132]\n",
      "loss: 1.595876  [ 6464/54132]\n",
      "loss: 1.738345  [12864/54132]\n",
      "loss: 1.818458  [19264/54132]\n",
      "loss: 1.581211  [25664/54132]\n",
      "loss: 1.840489  [32064/54132]\n",
      "loss: 1.467422  [38464/54132]\n",
      "loss: 1.476030  [44864/54132]\n",
      "loss: 1.568944  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 20344  size: 36089  main correct/size: 0.5637174762392972\n",
      "Also correct: 4498  size: 36089  also correct/size: 0.12463631577488986\n",
      "Test Error: Accuracy: 68.8%, Avg loss: 1.607605\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.496021  [   64/54132]\n",
      "loss: 1.578453  [ 6464/54132]\n",
      "loss: 1.723667  [12864/54132]\n",
      "loss: 1.805489  [19264/54132]\n",
      "loss: 1.563946  [25664/54132]\n",
      "loss: 1.824090  [32064/54132]\n",
      "loss: 1.449541  [38464/54132]\n",
      "loss: 1.457767  [44864/54132]\n",
      "loss: 1.553005  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 20537  size: 36089  main correct/size: 0.5690653661780598\n",
      "Also correct: 4431  size: 36089  also correct/size: 0.12277979439718474\n",
      "Test Error: Accuracy: 69.2%, Avg loss: 1.591333\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.480181  [   64/54132]\n",
      "loss: 1.561283  [ 6464/54132]\n",
      "loss: 1.709446  [12864/54132]\n",
      "loss: 1.792770  [19264/54132]\n",
      "loss: 1.547031  [25664/54132]\n",
      "loss: 1.808101  [32064/54132]\n",
      "loss: 1.432053  [38464/54132]\n",
      "loss: 1.439839  [44864/54132]\n",
      "loss: 1.537494  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 20746  size: 36089  main correct/size: 0.574856604505528\n",
      "Also correct: 4394  size: 36089  also correct/size: 0.12175455124830281\n",
      "Test Error: Accuracy: 69.7%, Avg loss: 1.575372\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.464729  [   64/54132]\n",
      "loss: 1.544396  [ 6464/54132]\n",
      "loss: 1.695679  [12864/54132]\n",
      "loss: 1.780358  [19264/54132]\n",
      "loss: 1.530500  [25664/54132]\n",
      "loss: 1.792481  [32064/54132]\n",
      "loss: 1.414967  [38464/54132]\n",
      "loss: 1.422310  [44864/54132]\n",
      "loss: 1.522431  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 20926  size: 36089  main correct/size: 0.5798442738784672\n",
      "Also correct: 4376  size: 36089  also correct/size: 0.12125578431100889\n",
      "Test Error: Accuracy: 70.1%, Avg loss: 1.559752\n",
      "Testing model\n",
      "Saved PyTorch Model State to model5.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [11, 7] Actual: 0  False  3.706974983215332\n",
      "Predicted: [11, 17] Actual: 1  False  3.760068893432617\n",
      "Predicted: [12, 17] Actual: 2  False  3.515373706817627\n",
      "Predicted: [12, 17] Actual: 3  False  3.5270371437072754\n",
      "Predicted: [7, 17] Actual: 4  False  4.023290634155273\n",
      "Predicted: [11, 12] Actual: 5  False  3.8104968070983887\n",
      "Predicted: [11, 12] Actual: 6  False  3.90775203704834\n",
      "Predicted: [7]     Actual: 7  True   11.055034637451172\n",
      "Predicted: [11, 17] Actual: 8  False  3.456341505050659\n",
      "Predicted: [7, 17] Actual: 9  False  3.895200490951538\n",
      "Predicted: [7]     Actual: 10 False  4.303494453430176\n",
      "Predicted: [11]    Actual: 11 True   8.936853408813477\n",
      "Predicted: [12]    Actual: 12 True   7.032068252563477\n",
      "Predicted: [11, 12] Actual: 13 False  4.101828575134277\n",
      "Predicted: [12, 11] Actual: 14 False  3.6298646926879883\n",
      "Predicted: [12, 17] Actual: 15 False  3.7204041481018066\n",
      "Predicted: [11, 12] Actual: 16 False  3.679816484451294\n",
      "Predicted: [17, 12] Actual: 17 True   4.792053699493408\n",
      "Predicted: [12, 11] Actual: 18 False  3.8574023246765137\n",
      "Predicted: [12, 17] Actual: 19 False  3.574368476867676\n",
      "Predicted: [7, 17] Actual: 20 False  3.8413069248199463\n",
      "Predicted: [11, 7] Actual: 21 False  3.8539845943450928\n",
      "Predicted: [11]    Actual: 22 False  4.046654224395752\n",
      "Predicted: [11, 12] Actual: 23 False  3.6319613456726074\n",
      "Predicted: [11, 12] Actual: 24 False  4.40569543838501\n",
      "Edge correct: 4    Size: 25   Edge correct/Size: 0.16\n",
      "Grid size: 5\n",
      "54132\n",
      "36089\n",
      "90221\n",
      "Using cuda device\n",
      "Loaded model from model5.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.440678  [   64/54132]\n",
      "loss: 1.283160  [ 6464/54132]\n",
      "loss: 1.367852  [12864/54132]\n",
      "loss: 1.593871  [19264/54132]\n",
      "loss: 1.819786  [25664/54132]\n",
      "loss: 1.392270  [32064/54132]\n",
      "loss: 1.162227  [38464/54132]\n",
      "loss: 1.444656  [44864/54132]\n",
      "loss: 1.502302  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21039  size: 36089  main correct/size: 0.5829754218737011\n",
      "Also correct: 4356  size: 36089  also correct/size: 0.12070159882512677\n",
      "Test Error: Accuracy: 70.4%, Avg loss: 1.548276\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.425944  [   64/54132]\n",
      "loss: 1.267690  [ 6464/54132]\n",
      "loss: 1.350934  [12864/54132]\n",
      "loss: 1.578788  [19264/54132]\n",
      "loss: 1.805112  [25664/54132]\n",
      "loss: 1.376263  [32064/54132]\n",
      "loss: 1.147163  [38464/54132]\n",
      "loss: 1.426522  [44864/54132]\n",
      "loss: 1.487130  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21185  size: 36089  main correct/size: 0.5870209759206406\n",
      "Also correct: 4289  size: 36089  also correct/size: 0.11884507744742165\n",
      "Test Error: Accuracy: 70.6%, Avg loss: 1.533440\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.409510  [   64/54132]\n",
      "loss: 1.252723  [ 6464/54132]\n",
      "loss: 1.334879  [12864/54132]\n",
      "loss: 1.563642  [19264/54132]\n",
      "loss: 1.790989  [25664/54132]\n",
      "loss: 1.361101  [32064/54132]\n",
      "loss: 1.132546  [38464/54132]\n",
      "loss: 1.409090  [44864/54132]\n",
      "loss: 1.472475  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21322  size: 36089  main correct/size: 0.5908171464989332\n",
      "Also correct: 4241  size: 36089  also correct/size: 0.11751503228130455\n",
      "Test Error: Accuracy: 70.8%, Avg loss: 1.519018\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.393590  [   64/54132]\n",
      "loss: 1.238321  [ 6464/54132]\n",
      "loss: 1.319295  [12864/54132]\n",
      "loss: 1.548730  [19264/54132]\n",
      "loss: 1.777256  [25664/54132]\n",
      "loss: 1.346450  [32064/54132]\n",
      "loss: 1.118422  [38464/54132]\n",
      "loss: 1.392272  [44864/54132]\n",
      "loss: 1.458233  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21415  size: 36089  main correct/size: 0.593394109008285\n",
      "Also correct: 4271  size: 36089  also correct/size: 0.11834631051012774\n",
      "Test Error: Accuracy: 71.2%, Avg loss: 1.505022\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.378242  [   64/54132]\n",
      "loss: 1.224479  [ 6464/54132]\n",
      "loss: 1.304143  [12864/54132]\n",
      "loss: 1.534127  [19264/54132]\n",
      "loss: 1.763878  [25664/54132]\n",
      "loss: 1.332215  [32064/54132]\n",
      "loss: 1.104815  [38464/54132]\n",
      "loss: 1.376015  [44864/54132]\n",
      "loss: 1.444378  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21506  size: 36089  main correct/size: 0.5959156529690487\n",
      "Also correct: 4262  size: 36089  also correct/size: 0.11809692704148078\n",
      "Test Error: Accuracy: 71.4%, Avg loss: 1.491464\n",
      "Testing model\n",
      "Saved PyTorch Model State to model5.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [11, 7] Actual: 0  False  3.681056022644043\n",
      "Predicted: [11, 17] Actual: 1  False  3.6955618858337402\n",
      "Predicted: [12, 17] Actual: 2  False  3.571903944015503\n",
      "Predicted: [17, 12] Actual: 3  False  3.589388132095337\n",
      "Predicted: [7, 17] Actual: 4  False  3.9403088092803955\n",
      "Predicted: [11, 12] Actual: 5  False  3.74129581451416\n",
      "Predicted: [11, 12] Actual: 6  False  3.8986639976501465\n",
      "Predicted: [7]     Actual: 7  True   12.214347839355469\n",
      "Predicted: [17, 12] Actual: 8  False  3.3777308464050293\n",
      "Predicted: [7, 17] Actual: 9  False  3.8049192428588867\n",
      "Predicted: [7]     Actual: 10 False  4.326709270477295\n",
      "Predicted: [11]    Actual: 11 True   10.478025436401367\n",
      "Predicted: [12]    Actual: 12 True   7.839744567871094\n",
      "Predicted: [11, 12] Actual: 13 False  4.157036304473877\n",
      "Predicted: [12, 17] Actual: 14 False  3.6574490070343018\n",
      "Predicted: [12, 17] Actual: 15 False  3.809405565261841\n",
      "Predicted: [11, 12] Actual: 16 False  3.5985593795776367\n",
      "Predicted: [17, 12] Actual: 17 True   5.121552467346191\n",
      "Predicted: [12, 17] Actual: 18 False  3.9069221019744873\n",
      "Predicted: [12, 17] Actual: 19 False  3.651350736618042\n",
      "Predicted: [7, 17] Actual: 20 False  3.7370975017547607\n",
      "Predicted: [11, 17] Actual: 21 False  3.7725188732147217\n",
      "Predicted: [11]    Actual: 22 False  4.084856986999512\n",
      "Predicted: [11, 12] Actual: 23 False  3.5384397506713867\n",
      "Predicted: [11, 12] Actual: 24 False  4.462034702301025\n",
      "Edge correct: 4    Size: 25   Edge correct/Size: 0.16\n",
      "Grid size: 5\n",
      "54132\n",
      "36089\n",
      "90221\n",
      "Using cuda device\n",
      "Loaded model from model5.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.507064  [   64/54132]\n",
      "loss: 1.376291  [ 6464/54132]\n",
      "loss: 1.586116  [12864/54132]\n",
      "loss: 1.663040  [19264/54132]\n",
      "loss: 1.255054  [25664/54132]\n",
      "loss: 1.526605  [32064/54132]\n",
      "loss: 1.324896  [38464/54132]\n",
      "loss: 1.825890  [44864/54132]\n",
      "loss: 1.348480  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21545  size: 36089  main correct/size: 0.5969963146665189\n",
      "Also correct: 4356  size: 36089  also correct/size: 0.12070159882512677\n",
      "Test Error: Accuracy: 71.8%, Avg loss: 1.473874\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.492374  [   64/54132]\n",
      "loss: 1.362494  [ 6464/54132]\n",
      "loss: 1.570981  [12864/54132]\n",
      "loss: 1.650215  [19264/54132]\n",
      "loss: 1.243329  [25664/54132]\n",
      "loss: 1.512909  [32064/54132]\n",
      "loss: 1.309073  [38464/54132]\n",
      "loss: 1.813955  [44864/54132]\n",
      "loss: 1.336453  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21602  size: 36089  main correct/size: 0.5985757433012829\n",
      "Also correct: 4394  size: 36089  also correct/size: 0.12175455124830281\n",
      "Test Error: Accuracy: 72.0%, Avg loss: 1.461392\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.479379  [   64/54132]\n",
      "loss: 1.348782  [ 6464/54132]\n",
      "loss: 1.556761  [12864/54132]\n",
      "loss: 1.637891  [19264/54132]\n",
      "loss: 1.232201  [25664/54132]\n",
      "loss: 1.499926  [32064/54132]\n",
      "loss: 1.293993  [38464/54132]\n",
      "loss: 1.802560  [44864/54132]\n",
      "loss: 1.324964  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21658  size: 36089  main correct/size: 0.6001274626617529\n",
      "Also correct: 4417  size: 36089  also correct/size: 0.12239186455706726\n",
      "Test Error: Accuracy: 72.3%, Avg loss: 1.449469\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.466953  [   64/54132]\n",
      "loss: 1.335635  [ 6464/54132]\n",
      "loss: 1.543135  [12864/54132]\n",
      "loss: 1.626065  [19264/54132]\n",
      "loss: 1.221598  [25664/54132]\n",
      "loss: 1.487555  [32064/54132]\n",
      "loss: 1.279540  [38464/54132]\n",
      "loss: 1.791776  [44864/54132]\n",
      "loss: 1.313972  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21731  size: 36089  main correct/size: 0.6021502396852226\n",
      "Also correct: 4413  size: 36089  also correct/size: 0.12228102745989082\n",
      "Test Error: Accuracy: 72.4%, Avg loss: 1.438100\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.455094  [   64/54132]\n",
      "loss: 1.323081  [ 6464/54132]\n",
      "loss: 1.530087  [12864/54132]\n",
      "loss: 1.614693  [19264/54132]\n",
      "loss: 1.211456  [25664/54132]\n",
      "loss: 1.475783  [32064/54132]\n",
      "loss: 1.265694  [38464/54132]\n",
      "loss: 1.781597  [44864/54132]\n",
      "loss: 1.303441  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21808  size: 36089  main correct/size: 0.6042838538058688\n",
      "Also correct: 4428  size: 36089  also correct/size: 0.12269666657430242\n",
      "Test Error: Accuracy: 72.7%, Avg loss: 1.427282\n",
      "Testing model\n",
      "Saved PyTorch Model State to model5.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [11, 7] Actual: 0  False  3.649561643600464\n",
      "Predicted: [11, 17] Actual: 1  False  3.6271746158599854\n",
      "Predicted: [12, 17] Actual: 2  False  3.571589231491089\n",
      "Predicted: [17, 12] Actual: 3  False  3.672229290008545\n",
      "Predicted: [7, 17] Actual: 4  False  3.89521861076355\n",
      "Predicted: [11, 12] Actual: 5  False  3.654250383377075\n",
      "Predicted: [11, 12] Actual: 6  False  3.8480405807495117\n",
      "Predicted: [7]     Actual: 7  True   13.189483642578125\n",
      "Predicted: [17, 12] Actual: 8  False  3.4151649475097656\n",
      "Predicted: [7, 17] Actual: 9  False  3.7503480911254883\n",
      "Predicted: [7]     Actual: 10 False  4.369971752166748\n",
      "Predicted: [11]    Actual: 11 True   12.117229461669922\n",
      "Predicted: [12]    Actual: 12 True   8.615994453430176\n",
      "Predicted: [11, 12] Actual: 13 False  4.162005424499512\n",
      "Predicted: [12, 17] Actual: 14 False  3.6109817028045654\n",
      "Predicted: [12, 17] Actual: 15 False  3.843196153640747\n",
      "Predicted: [11, 17] Actual: 16 False  3.508026361465454\n",
      "Predicted: [17, 12] Actual: 17 True   5.489720821380615\n",
      "Predicted: [12, 17] Actual: 18 False  3.885146379470825\n",
      "Predicted: [12, 17] Actual: 19 False  3.66723895072937\n",
      "Predicted: [7, 17] Actual: 20 False  3.668308734893799\n",
      "Predicted: [11, 17] Actual: 21 False  3.683389902114868\n",
      "Predicted: [11]    Actual: 22 False  4.09032678604126\n",
      "Predicted: [11, 17] Actual: 23 False  3.4219164848327637\n",
      "Predicted: [11, 12] Actual: 24 False  4.4994611740112305\n",
      "Edge correct: 4    Size: 25   Edge correct/Size: 0.16\n",
      "Grid size: 5\n",
      "54132\n",
      "36089\n",
      "90221\n",
      "Using cuda device\n",
      "Loaded model from model5.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.439801  [   64/54132]\n",
      "loss: 1.548048  [ 6464/54132]\n",
      "loss: 1.196927  [12864/54132]\n",
      "loss: 1.418609  [19264/54132]\n",
      "loss: 1.375678  [25664/54132]\n",
      "loss: 1.513678  [32064/54132]\n",
      "loss: 1.456711  [38464/54132]\n",
      "loss: 1.256960  [44864/54132]\n",
      "loss: 1.461294  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21849  size: 36089  main correct/size: 0.6054199340519272\n",
      "Also correct: 4491  size: 36089  also correct/size: 0.12444235085483112\n",
      "Test Error: Accuracy: 73.0%, Avg loss: 1.420308\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.429751  [   64/54132]\n",
      "loss: 1.540294  [ 6464/54132]\n",
      "loss: 1.185581  [12864/54132]\n",
      "loss: 1.407064  [19264/54132]\n",
      "loss: 1.366425  [25664/54132]\n",
      "loss: 1.503587  [32064/54132]\n",
      "loss: 1.446306  [38464/54132]\n",
      "loss: 1.247651  [44864/54132]\n",
      "loss: 1.450597  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21910  size: 36089  main correct/size: 0.6071101997838677\n",
      "Also correct: 4487  size: 36089  also correct/size: 0.1243315137576547\n",
      "Test Error: Accuracy: 73.1%, Avg loss: 1.410587\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.420106  [   64/54132]\n",
      "loss: 1.532660  [ 6464/54132]\n",
      "loss: 1.174732  [12864/54132]\n",
      "loss: 1.396094  [19264/54132]\n",
      "loss: 1.357761  [25664/54132]\n",
      "loss: 1.494026  [32064/54132]\n",
      "loss: 1.436483  [38464/54132]\n",
      "loss: 1.238867  [44864/54132]\n",
      "loss: 1.440529  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 21973  size: 36089  main correct/size: 0.6088558840643964\n",
      "Also correct: 4479  size: 36089  also correct/size: 0.12410983956330184\n",
      "Test Error: Accuracy: 73.3%, Avg loss: 1.401385\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.410906  [   64/54132]\n",
      "loss: 1.525318  [ 6464/54132]\n",
      "loss: 1.164447  [12864/54132]\n",
      "loss: 1.385694  [19264/54132]\n",
      "loss: 1.349537  [25664/54132]\n",
      "loss: 1.484910  [32064/54132]\n",
      "loss: 1.427148  [38464/54132]\n",
      "loss: 1.230568  [44864/54132]\n",
      "loss: 1.430950  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22007  size: 36089  main correct/size: 0.6097979993903959\n",
      "Also correct: 4515  size: 36089  also correct/size: 0.12510737343788966\n",
      "Test Error: Accuracy: 73.5%, Avg loss: 1.392676\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.402195  [   64/54132]\n",
      "loss: 1.518262  [ 6464/54132]\n",
      "loss: 1.154804  [12864/54132]\n",
      "loss: 1.375819  [19264/54132]\n",
      "loss: 1.341712  [25664/54132]\n",
      "loss: 1.476241  [32064/54132]\n",
      "loss: 1.418263  [38464/54132]\n",
      "loss: 1.222755  [44864/54132]\n",
      "loss: 1.421862  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22056  size: 36089  main correct/size: 0.6111557538308072\n",
      "Also correct: 4540  size: 36089  also correct/size: 0.12580010529524233\n",
      "Test Error: Accuracy: 73.7%, Avg loss: 1.384434\n",
      "Testing model\n",
      "Saved PyTorch Model State to model5.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [11, 7] Actual: 0  False  3.5797183513641357\n",
      "Predicted: [11, 17] Actual: 1  False  3.5224215984344482\n",
      "Predicted: [12, 17] Actual: 2  False  3.5603091716766357\n",
      "Predicted: [17, 12] Actual: 3  False  3.7459845542907715\n",
      "Predicted: [7, 17] Actual: 4  False  3.808365821838379\n",
      "Predicted: [12, 11] Actual: 5  False  3.5945851802825928\n",
      "Predicted: [11, 12] Actual: 6  False  3.7602832317352295\n",
      "Predicted: [7]     Actual: 7  True   14.005973815917969\n",
      "Predicted: [17, 12] Actual: 8  False  3.444446086883545\n",
      "Predicted: [7, 17] Actual: 9  False  3.665511131286621\n",
      "Predicted: [7]     Actual: 10 False  4.378375053405762\n",
      "Predicted: [11]    Actual: 11 True   13.696329116821289\n",
      "Predicted: [12]    Actual: 12 True   9.395212173461914\n",
      "Predicted: [11, 12] Actual: 13 False  4.1265363693237305\n",
      "Predicted: [12, 17] Actual: 14 False  3.561819314956665\n",
      "Predicted: [12, 17] Actual: 15 False  3.893007278442383\n",
      "Predicted: [11, 17] Actual: 16 False  3.3774917125701904\n",
      "Predicted: [17, 12] Actual: 17 True   5.864521026611328\n",
      "Predicted: [12, 17] Actual: 18 False  3.8712856769561768\n",
      "Predicted: [12, 17] Actual: 19 False  3.6944375038146973\n",
      "Predicted: [17, 7] Actual: 20 False  3.664736747741699\n",
      "Predicted: [11, 17] Actual: 21 False  3.5665037631988525\n",
      "Predicted: [11]    Actual: 22 False  4.021439075469971\n",
      "Predicted: [11, 17] Actual: 23 False  3.26041579246521\n",
      "Predicted: [11, 12] Actual: 24 False  4.491110801696777\n",
      "Edge correct: 4    Size: 25   Edge correct/Size: 0.16\n",
      "Grid size: 5\n",
      "54132\n",
      "36089\n",
      "90221\n",
      "Using cuda device\n",
      "Loaded model from model5.pth\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.437206  [   64/54132]\n",
      "loss: 1.391833  [ 6464/54132]\n",
      "loss: 1.301289  [12864/54132]\n",
      "loss: 1.244663  [19264/54132]\n",
      "loss: 1.307272  [25664/54132]\n",
      "loss: 1.340117  [32064/54132]\n",
      "loss: 1.151576  [38464/54132]\n",
      "loss: 1.694056  [44864/54132]\n",
      "loss: 1.683361  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22155  size: 36089  main correct/size: 0.6138989719859237\n",
      "Also correct: 4502  size: 36089  also correct/size: 0.12474715287206628\n",
      "Test Error: Accuracy: 73.9%, Avg loss: 1.367494\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.428890  [   64/54132]\n",
      "loss: 1.383279  [ 6464/54132]\n",
      "loss: 1.294193  [12864/54132]\n",
      "loss: 1.238155  [19264/54132]\n",
      "loss: 1.299210  [25664/54132]\n",
      "loss: 1.332878  [32064/54132]\n",
      "loss: 1.142429  [38464/54132]\n",
      "loss: 1.688669  [44864/54132]\n",
      "loss: 1.675760  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22205  size: 36089  main correct/size: 0.615284435700629\n",
      "Also correct: 4503  size: 36089  also correct/size: 0.12477486214636038\n",
      "Test Error: Accuracy: 74.0%, Avg loss: 1.360070\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.420803  [   64/54132]\n",
      "loss: 1.375110  [ 6464/54132]\n",
      "loss: 1.287477  [12864/54132]\n",
      "loss: 1.232022  [19264/54132]\n",
      "loss: 1.291868  [25664/54132]\n",
      "loss: 1.326269  [32064/54132]\n",
      "loss: 1.133741  [38464/54132]\n",
      "loss: 1.683513  [44864/54132]\n",
      "loss: 1.668712  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22222  size: 36089  main correct/size: 0.6157554933636288\n",
      "Also correct: 4534  size: 36089  also correct/size: 0.12563384964947769\n",
      "Test Error: Accuracy: 74.1%, Avg loss: 1.353013\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.413375  [   64/54132]\n",
      "loss: 1.367358  [ 6464/54132]\n",
      "loss: 1.281077  [12864/54132]\n",
      "loss: 1.226288  [19264/54132]\n",
      "loss: 1.284977  [25664/54132]\n",
      "loss: 1.320081  [32064/54132]\n",
      "loss: 1.125472  [38464/54132]\n",
      "loss: 1.678479  [44864/54132]\n",
      "loss: 1.662096  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22244  size: 36089  main correct/size: 0.6163650973980992\n",
      "Also correct: 4550  size: 36089  also correct/size: 0.12607719803818337\n",
      "Test Error: Accuracy: 74.2%, Avg loss: 1.346298\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "54132\n",
      "Training model\n",
      "loss: 1.406259  [   64/54132]\n",
      "loss: 1.360070  [ 6464/54132]\n",
      "loss: 1.274988  [12864/54132]\n",
      "loss: 1.220786  [19264/54132]\n",
      "loss: 1.278527  [25664/54132]\n",
      "loss: 1.314199  [32064/54132]\n",
      "loss: 1.117472  [38464/54132]\n",
      "loss: 1.673698  [44864/54132]\n",
      "loss: 1.655755  [51264/54132]\n",
      "Finished training model\n",
      "Testing model\n",
      "Main correct: 22260  size: 36089  main correct/size: 0.6168084457868048\n",
      "Also correct: 4583  size: 36089  also correct/size: 0.12699160408988888\n",
      "Test Error: Accuracy: 74.4%, Avg loss: 1.339895\n",
      "Testing model\n",
      "Saved PyTorch Model State to model5.pth\n",
      "------------------------------------------\n",
      "Edge cases:\n",
      "Predicted: [11, 7] Actual: 0  False  3.4832239151000977\n",
      "Predicted: [11, 17] Actual: 1  False  3.389000415802002\n",
      "Predicted: [12, 17] Actual: 2  False  3.493614435195923\n",
      "Predicted: [17, 12] Actual: 3  False  3.7967801094055176\n",
      "Predicted: [7, 17] Actual: 4  False  3.7908899784088135\n",
      "Predicted: [12, 11] Actual: 5  False  3.51711106300354\n",
      "Predicted: [11, 12] Actual: 6  False  3.6272082328796387\n",
      "Predicted: [7]     Actual: 7  True   14.704874992370605\n",
      "Predicted: [17, 12] Actual: 8  False  3.4646401405334473\n",
      "Predicted: [7, 17] Actual: 9  False  3.645573139190674\n",
      "Predicted: [7]     Actual: 10 False  4.435893535614014\n",
      "Predicted: [11]    Actual: 11 True   15.122130393981934\n",
      "Predicted: [12]    Actual: 12 True   10.1133451461792\n",
      "Predicted: [11, 12] Actual: 13 False  4.0331926345825195\n",
      "Predicted: [12, 17] Actual: 14 False  3.4480156898498535\n",
      "Predicted: [12, 17] Actual: 15 False  3.8908870220184326\n",
      "Predicted: [17, 11] Actual: 16 False  3.30153751373291\n",
      "Predicted: [17, 12] Actual: 17 True   6.236247539520264\n",
      "Predicted: [12, 17] Actual: 18 False  3.8063533306121826\n",
      "Predicted: [12, 17] Actual: 19 False  3.66524600982666\n",
      "Predicted: [17, 7] Actual: 20 False  3.680713176727295\n",
      "Predicted: [11, 17] Actual: 21 False  3.4492688179016113\n",
      "Predicted: [11]    Actual: 22 False  3.9265685081481934\n",
      "Predicted: [17, 11] Actual: 23 False  3.1296536922454834\n",
      "Predicted: [11]    Actual: 24 False  4.442279815673828\n",
      "Edge correct: 4    Size: 25   Edge correct/Size: 0.16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "import Data.database_handler as dbHandler\n",
    "from torchvision import transforms, utils\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "sys.path.append('..')\n",
    "#%run Map_grid/map.ipynb import CalculateGrid\n",
    "\n",
    "#Connecting to the SQLite database\n",
    "grid_size = 5\n",
    "data_amount = 1600000\n",
    "db_path = r'Data\\datasetNY.db'\n",
    "chunk_amount = 90222\n",
    "chunk_size = data_amount / chunk_amount\n",
    "data = dbHandler.get_n_data_datetime_converted(db_path, data_amount)\n",
    "\n",
    "with open('output2.txt', 'a') as f:\n",
    "    for size in range(5, 10):\n",
    "        #grid_size = size\n",
    "        print(f'Grid size: {grid_size}')\n",
    "        f.write(f'Grid size: {grid_size}\\n')\n",
    "        f.write(f'Correct Tolerance {int(max(1, np.floor(grid_size/2)))}\\n')\n",
    "        f.write('------------------------------------------\\n')\n",
    "        class AccidentDataset(Dataset):\n",
    "            def __init__(self, transform=None):\n",
    "                self.coordinates = data\n",
    "                self.coordinates = pd.DataFrame(self.coordinates, columns=['datetime', 'latitude', 'longitude'])\n",
    "                \n",
    "                #split into 500 chunks using numpy\n",
    "                self.coordinates = np.array_split(self.coordinates, chunk_amount)\n",
    "\n",
    "                #process each chunk and merge it back into one dataframe\n",
    "                self.grids = []\n",
    "                grid_lower_lat, grid_lower_long = 40.54, -74.15\n",
    "                grid_upper_lat, grid_upper_long = 40.91, -73.70\n",
    "                grid_lat_step = (grid_upper_lat - grid_lower_lat) / grid_size\n",
    "                grid_long_step = (grid_upper_long - grid_lower_long) / grid_size\n",
    "                for i in range(len(self.coordinates)-1):\n",
    "                    grid = np.zeros((grid_size, grid_size))\n",
    "                    for index, row in self.coordinates[i].iterrows():\n",
    "                        coordinates = row['latitude'], row['longitude']\n",
    "                        for j in range(grid_size):\n",
    "                            for k in range(grid_size):\n",
    "                                lat_lower = grid_lower_lat + j * grid_lat_step\n",
    "                                lat_upper = grid_lower_lat + (j + 1) * grid_lat_step\n",
    "                                long_lower = grid_lower_long + k * grid_long_step\n",
    "                                long_upper = grid_lower_long + (k + 1) * grid_long_step\n",
    "                                if lat_lower <= float(coordinates[0]) < lat_upper and long_lower <= float(coordinates[1]) < long_upper:\n",
    "                                    grid[j][k] += 1\n",
    "                                    break\n",
    "                    self.grids.append(grid/chunk_size)\n",
    "                self.grids = np.array(self.grids)\n",
    "                self.transform = transform      \n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.grids)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                if torch.is_tensor(idx):\n",
    "                    idx = idx.tolist()\n",
    "\n",
    "                grid = self.grids[idx]\n",
    "                grid = torch.from_numpy(grid).float()\n",
    "\n",
    "                max_index = np.argmax(grid)\n",
    "                max_index = np.array(max_index)\n",
    "                return grid.flatten(), torch.tensor(max_index.item()).long()\n",
    "\n",
    "        accident_dataset = AccidentDataset()\n",
    "\n",
    "        #Create new array with 60% of the data\n",
    "        train_size = int(0.6 * len(accident_dataset))\n",
    "        test_size = len(accident_dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(accident_dataset, [train_size, test_size])\n",
    "\n",
    "        print(len(train_dataset))\n",
    "        print(len(test_dataset))\n",
    "        print(len(accident_dataset))\n",
    "\n",
    "        #Create dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        class Network(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(grid_size ** 2, grid_size ** 2),\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                #x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "\n",
    "\n",
    "        # define the class for multilinear regression\n",
    "        # building the model object\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        #device = torch.device('cpu')\n",
    "        print(f'Using {device} device')\n",
    "\n",
    "        model = Network().to(device)\n",
    "        if os.path.exists(f\"model{grid_size}.pth\"):\n",
    "            model.load_state_dict(torch.load(f\"model{grid_size}.pth\"))\n",
    "            print(f\"Loaded model from model{grid_size}.pth\")\n",
    "        else:\n",
    "            print(\"No model found, creating new model\")\n",
    "\n",
    "        # define the loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "        # define the training loop\n",
    "        def train(dataloader, model, loss_fn, optimizer):\n",
    "            size = len(dataloader.dataset)\n",
    "            print(size)\n",
    "            model.train()\n",
    "            print(\"Training model\")\n",
    "            for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                #print('pred ', pred)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"Finished training model\")\n",
    "\n",
    "        def test(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            print(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\")\n",
    "            print(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "        def logtest(dataloader, model, loss_fn):\n",
    "            print(\"Testing model\")\n",
    "            size = len(dataloader.dataset)\n",
    "            num_batches = len(dataloader)\n",
    "            model.eval()\n",
    "            test_loss, correct, also_correct = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in dataloader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    #check if prediction is correct\n",
    "                    predictions = torch.topk(pred, int(max(1, np.floor(grid_size/2))), dim=1).indices\n",
    "\n",
    "                    for i in range (len(predictions)):\n",
    "                        if y[i] in predictions[i]:\n",
    "                            if y[i] == pred.argmax(1)[i]:\n",
    "                                correct += 1\n",
    "                            else:\n",
    "                                also_correct += 1\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            f.write(f\"Main correct: {correct}  size: {size}  main correct/size: {correct/size}\\n\")\n",
    "            f.write(f\"Also correct: {also_correct}  size: {size}  also correct/size: {also_correct/size}\\n\")\n",
    "            correct += also_correct\n",
    "            correct /= size\n",
    "            f.write(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "        \n",
    "        epochs = 5\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        logtest(test_dataloader, model, loss_fn)\n",
    "        torch.save(model.state_dict(), f\"model{grid_size}.pth\")\n",
    "        print(f\"Saved PyTorch Model State to model{grid_size}.pth\")\n",
    "\n",
    "        model.eval()\n",
    "        edge_correct = 0\n",
    "        f.write('------------------------------------------\\nEdge cases:\\n')\n",
    "        print('------------------------------------------\\nEdge cases:')\n",
    "        for i in range (grid_size ** 2):\n",
    "            randomnumber = rand.randint(0, len(test_dataset) - 1)\n",
    "            edge = np.zeros(grid_size ** 2)\n",
    "            edge[i] = 1\n",
    "            x, y = torch.tensor(edge).float(), i\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model(x.to(device))\n",
    "                #print(pred)\n",
    "                predicted, actual = pred.topk(grid_size), y\n",
    "                max_value = pred.max(0)[0]\n",
    "                index = []\n",
    "                for j in range(len(predicted)):\n",
    "                    if predicted.values[j].item() >= 0.8 * max_value:\n",
    "                        index.append(predicted.indices[j].item())\n",
    "                part1 = f'Predicted: {index}'.ljust(18, ' ')\n",
    "                part2 = f'Actual: {actual}'.ljust(10, ' ')\n",
    "                part3 = f'{actual in index}'.ljust(6, ' ')\n",
    "                part4 = f'{max_value}'.ljust(10, ' ')\n",
    "                print(part1, part2, part3, part4)\n",
    "                f.write(part1 + part2 + part3 + part4 + '\\n')\n",
    "                #print(f'Predicted: \"{index}\", Actual: \"{actual}\" {actual in index} {max_value}')\n",
    "                edge_correct += actual in index\n",
    "        f.write('------------------------------------------\\n')\n",
    "        edgestr1 = f\"Edge correct: {edge_correct}\".ljust(18, ' ')\n",
    "        edgestr2 = f\"Size: {grid_size ** 2}\".ljust(10, ' ')\n",
    "        edgestr3 = f\"Edge correct/Size: {edge_correct/(grid_size ** 2)}\".ljust(20, ' ')\n",
    "        print(edgestr1, edgestr2, edgestr3)\n",
    "        f.write(edgestr1 + edgestr2 + edgestr3 + '\\n')\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570189b94c8be545687b2cc37d4a9df3fcede358db47b55e6620cb36780e1fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
